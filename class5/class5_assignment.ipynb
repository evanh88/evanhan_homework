{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88facc79",
   "metadata": {},
   "source": [
    "# Assignment for week 5 - Hybrid Search evaluation notebook\n",
    "\n",
    "This notebook presents the steps for evaluating the code of vector-only, keyword-only, and hybrid (Weighted summary) search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28344524",
   "metadata": {},
   "source": [
    "### *) To install necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6386709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 1)) (0.0.1.dev2)\n",
      "Requirement already satisfied: langchain_core in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 2)) (0.3.74)\n",
      "Requirement already satisfied: sentence_transformers in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 3)) (5.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 4)) (0.116.1)\n",
      "Requirement already satisfied: pydantic in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 5)) (2.11.7)\n",
      "Requirement already satisfied: uvicorn in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 6)) (0.35.0)\n",
      "Requirement already satisfied: configobj in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (5.0.9)\n",
      "Requirement already satisfied: configparser in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: nibabel in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (5.3.2)\n",
      "Requirement already satisfied: nipype in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: pandas in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: pyxnat in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: scipy in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.16.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (4.55.2)\n",
      "Requirement already satisfied: tqdm in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fastapi->-r ./src/requirements.txt (line 4)) (0.47.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from uvicorn->-r ./src/requirements.txt (line 6)) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from uvicorn->-r ./src/requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: filelock in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2025.7.0)\n",
      "Requirement already satisfied: requests in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.1.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r ./src/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (4.10.0)\n",
      "Requirement already satisfied: setuptools in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httplib2->fitz->-r ./src/requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: prov>=1.5.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (7.0.2)\n",
      "Requirement already satisfied: acres in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: puremagic in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (1.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pandas->fitz->-r ./src/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pandas->fitz->-r ./src/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pyxnat->fitz->-r ./src/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: pathlib>=1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pyxnat->fitz->-r ./src/requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from etelemetry>=0.3.1->nipype->fitz->-r ./src/requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: certifi in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from python-dateutil>=2.2->nipype->fitz->-r ./src/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r ./src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9c34",
   "metadata": {},
   "source": [
    "### 1) To extract and split the text from the PDF files stored at ./pdfs, build sqlite3 database and FAISS index for keyword/vector search, run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f166146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehan/venv/venv_class4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf chunk file saved!\n",
      "Sqlite3 database file saved!\n",
      "Number of vectors in the FAISS index: 8390\n",
      "FAISS index created, populated, and saved!\n"
     ]
    }
   ],
   "source": [
    "from src.build_sqlite3_db_and_faiss_index import build\n",
    "build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b11a8",
   "metadata": {},
   "source": [
    "### 2) To load the document chunks, FAISS index, then execute vector search on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed369be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and documents files loaded\n",
      "query = \" Normative LLMs Profiling \"\n",
      "\n",
      "Vector Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    5434     0.565    2508.15361v1.pdf   25        \n",
      "2    1682     0.553    2508.15250v1.pdf   1         \n",
      "3    5542     0.543    2508.15361v1.pdf   34        \n",
      "4    5169     0.539    2508.15361v1.pdf   4         \n",
      "5    174      0.532    2508.15396v1.pdf   8         \n",
      "6    1775     0.530    2508.15250v1.pdf   10        \n",
      "7    1691     0.530    2508.15250v1.pdf   2         \n",
      "8    6183     0.529    2508.15283v1.pdf   11        \n",
      "9    4215     0.528    2508.15746v1.pdf   14        \n",
      "10   7347     0.526    2508.15648v1.pdf   3         \n",
      "\n",
      "\n",
      "query = \" Automatic Mixed Precision \"\n",
      "\n",
      "Vector Search Results, for query: 'Automatic Mixed Precision'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1417     0.485    2508.15637v1.pdf   31        \n",
      "2    5697     0.482    2508.15361v1.pdf   48        \n",
      "3    5448     0.476    2508.15361v1.pdf   26        \n",
      "4    4851     0.469    2508.15418v1.pdf   11        \n",
      "5    1313     0.465    2508.15637v1.pdf   15        \n",
      "6    5298     0.458    2508.15361v1.pdf   15        \n",
      "7    5297     0.457    2508.15361v1.pdf   15        \n",
      "8    274      0.456    2508.15396v1.pdf   18        \n",
      "9    7091     0.456    2508.15229v1.pdf   7         \n",
      "10   4181     0.455    2508.15746v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" Sampling Number \"\n",
      "\n",
      "Vector Search Results, for query: 'Sampling Number'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    7398     0.469    2508.15648v1.pdf   8         \n",
      "2    7397     0.448    2508.15648v1.pdf   8         \n",
      "3    8238     0.441    2508.15475v1.pdf   23        \n",
      "4    3977     0.440    2508.15483v1.pdf   2         \n",
      "5    3976     0.437    2508.15483v1.pdf   2         \n",
      "6    1333     0.429    2508.15637v1.pdf   18        \n",
      "7    5976     0.427    2508.15760v1.pdf   6         \n",
      "8    944      0.425    2508.15316v1.pdf   2         \n",
      "9    3216     0.420    2508.15411v1.pdf   6         \n",
      "10   2942     0.420    2508.15754v1.pdf   15        \n",
      "\n",
      "\n",
      "query = \" knowledge distillation \"\n",
      "\n",
      "Vector Search Results, for query: 'knowledge distillation'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2105     0.633    2508.15617v1.pdf   1         \n",
      "2    2104     0.544    2508.15617v1.pdf   1         \n",
      "3    7551     0.540    2508.15709v1.pdf   3         \n",
      "4    7534     0.521    2508.15709v1.pdf   2         \n",
      "5    7552     0.519    2508.15709v1.pdf   3         \n",
      "6    1575     0.511    2508.15253v1.pdf   5         \n",
      "7    8174     0.500    2508.15475v1.pdf   11        \n",
      "8    1201     0.498    2508.15357v1.pdf   8         \n",
      "9    6300     0.496    2508.15478v1.pdf   12        \n",
      "10   7631     0.495    2508.15709v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" Knowledge Graph Completion Models \"\n",
      "\n",
      "Vector Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1103     0.706    2508.15357v1.pdf   1         \n",
      "2    1206     0.631    2508.15357v1.pdf   9         \n",
      "3    1205     0.620    2508.15357v1.pdf   9         \n",
      "4    1194     0.611    2508.15357v1.pdf   8         \n",
      "5    1189     0.593    2508.15357v1.pdf   8         \n",
      "6    1197     0.592    2508.15357v1.pdf   8         \n",
      "7    1204     0.583    2508.15357v1.pdf   9         \n",
      "8    1199     0.580    2508.15357v1.pdf   8         \n",
      "9    1104     0.566    2508.15357v1.pdf   1         \n",
      "10   3848     0.563    2508.15291v1.pdf   8         \n",
      "\n",
      "\n",
      "query = \" contextless speech processing \"\n",
      "\n",
      "Vector Search Results, for query: 'contextless speech processing'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1000     0.597    2508.15316v1.pdf   7         \n",
      "2    929      0.589    2508.15316v1.pdf   1         \n",
      "3    1017     0.587    2508.15316v1.pdf   10        \n",
      "4    925      0.581    2508.15316v1.pdf   1         \n",
      "5    4898     0.547    2508.15418v1.pdf   15        \n",
      "6    927      0.545    2508.15316v1.pdf   1         \n",
      "7    937      0.544    2508.15316v1.pdf   2         \n",
      "8    985      0.540    2508.15316v1.pdf   6         \n",
      "9    942      0.526    2508.15316v1.pdf   2         \n",
      "10   1279     0.522    2508.15637v1.pdf   11        \n",
      "\n",
      "\n",
      "query = \" Elastic Weight Consolidation algorithm \"\n",
      "\n",
      "Vector Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2643     0.519    2508.15294v1.pdf   8         \n",
      "2    2560     0.467    2508.15294v1.pdf   1         \n",
      "3    7995     0.464    2508.15757v1.pdf   4         \n",
      "4    2446     0.452    2508.15464v1.pdf   5         \n",
      "5    8019     0.436    2508.15757v1.pdf   6         \n",
      "6    8028     0.431    2508.15757v1.pdf   7         \n",
      "7    2444     0.430    2508.15464v1.pdf   5         \n",
      "8    2943     0.430    2508.15754v1.pdf   16        \n",
      "9    6625     0.429    2508.15763v1.pdf   29        \n",
      "10   2964     0.427    2508.15754v1.pdf   17        \n",
      "\n",
      "\n",
      "query = \" Neural Ranking Models \"\n",
      "\n",
      "Vector Search Results, for query: 'Neural Ranking Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    6113     0.558    2508.15283v1.pdf   5         \n",
      "2    6049     0.537    2508.15283v1.pdf   1         \n",
      "3    6180     0.536    2508.15283v1.pdf   11        \n",
      "4    6162     0.529    2508.15283v1.pdf   10        \n",
      "5    6073     0.523    2508.15283v1.pdf   3         \n",
      "6    6163     0.512    2508.15283v1.pdf   10        \n",
      "7    1143     0.511    2508.15357v1.pdf   4         \n",
      "8    6033     0.511    2508.15760v1.pdf   12        \n",
      "9    6164     0.509    2508.15283v1.pdf   10        \n",
      "10   6111     0.508    2508.15283v1.pdf   5         \n",
      "\n",
      "\n",
      "query = \" Contrastive Learning Based Fine Tuning \"\n",
      "\n",
      "Vector Search Results, for query: 'Contrastive Learning Based Fine Tuning'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    7473     0.543    2508.15471v1.pdf   2         \n",
      "2    744      0.537    2508.15392v1.pdf   11        \n",
      "3    7494     0.530    2508.15471v1.pdf   6         \n",
      "4    7475     0.511    2508.15471v1.pdf   2         \n",
      "5    3138     0.505    2508.15371v1.pdf   10        \n",
      "6    7474     0.494    2508.15471v1.pdf   2         \n",
      "7    7726     0.492    2508.15370v1.pdf   3         \n",
      "8    6482     0.490    2508.15763v1.pdf   13        \n",
      "9    7484     0.489    2508.15471v1.pdf   3         \n",
      "10   7949     0.486    2508.15757v1.pdf   1         \n",
      "\n",
      "\n",
      "query = \" Conflict Aware Soft Prompting \"\n",
      "\n",
      "Vector Search Results, for query: 'Conflict Aware Soft Prompting'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1533     0.573    2508.15253v1.pdf   1         \n",
      "2    1540     0.546    2508.15253v1.pdf   1         \n",
      "3    148      0.517    2508.15396v1.pdf   6         \n",
      "4    1534     0.516    2508.15253v1.pdf   1         \n",
      "5    1544     0.511    2508.15253v1.pdf   2         \n",
      "6    1569     0.510    2508.15253v1.pdf   4         \n",
      "7    1579     0.510    2508.15253v1.pdf   5         \n",
      "8    7987     0.509    2508.15757v1.pdf   4         \n",
      "9    1567     0.504    2508.15253v1.pdf   4         \n",
      "10   1543     0.497    2508.15253v1.pdf   2         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.hybrid_search import connect_to_database, load_documents_and_faiss_index, sqlite_keyword_search, faiss_search, hybrid_search\n",
    "import pprint\n",
    "\n",
    "# Define a list of queries\n",
    "queries = [\n",
    "    \"Normative LLMs Profiling\", # 1674, 1675, 1682\n",
    "    \"Automatic Mixed Precision\", # 2147, other chunk in same page\n",
    "    \"Sampling Number\", #7397, 7398\n",
    "    \"knowledge distillation\", # 1571, 1572, 2104, 2730, 3126, 6206, 6274, 6300, 7522, 7523, 7534, 7630, 8173, 8174  (13)\n",
    "    \"Knowledge Graph Completion Models\", # 1103/04, 1184, 1189, 1197, 1199, 1205/06, 3846/48 (7)  \n",
    "    \"contextless speech processing\", # 925, 929/930, 985, 1017 (4)\n",
    "    \"Elastic Weight Consolidation algorithm\", # 2560, 2643 (2)\n",
    "    \"Neural Ranking Models\", # 6044, 6047/48/49, 6070, 6072/73, 6084, 6099, 6112/13, 6016, 6125, 6128, 6131, 6139, 6146, 6158/59, 6162/3/4, 6171/2/3/5, 6180/81 (20) \n",
    "    \"Contrastive Learning Based Fine Tuning\", # 840, 4275, 6299, 7465, 7469/71/3/4/5, 7480, 7483/4, 7490-4, 7507/09, 7512/14/16/20 (15)\n",
    "    \"Conflict Aware Soft Prompting\" # 1533/34/35, 1544/45, 1568/69, 1611, (6)\n",
    "]\n",
    "\n",
    "load_documents_and_faiss_index()\n",
    "\n",
    "for query in queries:\n",
    "    print(\"query = \\\"\", query, \"\\\"\")\n",
    "    result = faiss_search(query, 10, verbose=True)\n",
    "    print(\"\\n\")\n",
    "    # pprint.pprint(result, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05058930",
   "metadata": {},
   "source": [
    "### 3) To perform keywork search using Sqlite3 FTS for the queries, ran the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9d2452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened the database\n",
      "\n",
      "Keyword Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1682     0.724      2508.15250v1.pdf   1         \n",
      "2    1674     0.673      2508.15250v1.pdf   1         \n",
      "3    1675     0.156      2508.15250v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'Automatic Mixed Precision'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2153     0.740      2508.15617v1.pdf   5         \n",
      "2    2147     0.260      2508.15617v1.pdf   5         \n",
      "\n",
      "Keyword Search Results, for query: 'Sampling Number'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    8294     0.797      2508.15244v1.pdf   6         \n",
      "2    8270     0.720      2508.15244v1.pdf   4         \n",
      "3    3015     0.701      2508.15371v1.pdf   3         \n",
      "4    7398     0.173      2508.15648v1.pdf   8         \n",
      "5    7397     0.168      2508.15648v1.pdf   8         \n",
      "\n",
      "Keyword Search Results, for query: 'knowledge distillation'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    6206     0.546      2508.15478v1.pdf   3         \n",
      "2    1572     0.526      2508.15253v1.pdf   5         \n",
      "3    3126     0.506      2508.15371v1.pdf   10        \n",
      "4    4195     0.495      2508.15746v1.pdf   12        \n",
      "5    6300     0.474      2508.15478v1.pdf   12        \n",
      "6    2730     0.453      2508.15274v1.pdf   5         \n",
      "\n",
      "Keyword Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1184     0.784      2508.15357v1.pdf   7         \n",
      "2    1197     0.732      2508.15357v1.pdf   8         \n",
      "3    1103     0.092      2508.15357v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'contextless speech processing'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    925      0.550      2508.15316v1.pdf   1         \n",
      "2    929      0.450      2508.15316v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "\n",
      "Keyword Search Results, for query: 'Neural Ranking Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    6139     0.550      2508.15283v1.pdf   8         \n",
      "2    6116     0.539      2508.15283v1.pdf   6         \n",
      "3    6112     0.517      2508.15283v1.pdf   5         \n",
      "4    6099     0.484      2508.15283v1.pdf   5         \n",
      "5    6128     0.461      2508.15283v1.pdf   7         \n",
      "6    6131     0.449      2508.15283v1.pdf   7         \n",
      "\n",
      "Keyword Search Results, for query: 'Contrastive Learning Based Fine Tuning'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    7471     0.951      2508.15471v1.pdf   2         \n",
      "2    7465     0.834      2508.15471v1.pdf   1         \n",
      "3    7474     0.742      2508.15471v1.pdf   2         \n",
      "4    7514     0.238      2508.15471v1.pdf   10        \n",
      "5    7473     0.124      2508.15471v1.pdf   2         \n",
      "6    7494     0.074      2508.15471v1.pdf   6         \n",
      "\n",
      "Keyword Search Results, for query: 'Conflict Aware Soft Prompting'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1611     0.922      2508.15253v1.pdf   9         \n",
      "2    1544     0.578      2508.15253v1.pdf   2         \n",
      "3    1533     0.453      2508.15253v1.pdf   1         \n",
      "4    1534     0.284      2508.15253v1.pdf   1         \n",
      "5    1563     0.159      2508.15253v1.pdf   4         \n"
     ]
    }
   ],
   "source": [
    "connect_to_database()\n",
    "\n",
    "for query in queries:\n",
    "    result = sqlite_keyword_search(query, 6, verbose=True)\n",
    "    # pprint.pprint(result, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea8bf1",
   "metadata": {},
   "source": [
    "### 4) Execute hybrid search (vector + keyword) for the queries, apply the weight-summary merge logic and get the top 3 matches\n",
    "\n",
    "The search results show that the hrbrid method yields more accurate results over using vector or keyword method alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87980fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Search Results for query: 'Normative LLMs Profiling'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1682   0.621    0.553    0.724    2508.15250v1.p     1         \n",
      "2    5434   0.339    0.565    0.000    2508.15361v1.p     25        \n",
      "3    5542   0.326    0.543    0.000    2508.15361v1.p     34        \n",
      "4    5169   0.323    0.539    0.000    2508.15361v1.p     4         \n",
      "5    174    0.319    0.532    0.000    2508.15396v1.p     8         \n",
      "6    1775   0.318    0.530    0.000    2508.15250v1.p     10        \n",
      "\n",
      "[{'doc_idx': 1682,\n",
      "  'filename': '2508.15250v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 't measurements often focus solely on eth-\\n'\n",
      "             'ical judgments, without considering how factors\\n'\n",
      "             'like professional background, language environ-\\n'\n",
      "             'ment (Changjiang et al., 2024), and model param-\\n'\n",
      "             'eters (Achiam et al., 2023) interact. To fill this gap,\\n'\n",
      "             'we propose the EMNLP (Educator-role Moral and\\n'\n",
      "             'Normative LLMs Profiling) framework for compre-\\n'\n",
      "             'hensive testing and analysis of LLMs’ personality\\n'\n",
      "             'traits and ethical risks in educational contexts.\\n'\n",
      "             'Our EMNLP framework conducts a moral and\\n'\n",
      "             'ethical evaluation of LLMs in the ',\n",
      "  'combined_score': 0.6210238823608489,\n",
      "  'vector_score': 0.5525643229484558,\n",
      "  'keyword_score': 0.7237132214794385},\n",
      " {'doc_idx': 5434,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 25,\n",
      "  'content': ' outputs, adversarial susceptibility, and\\n'\n",
      "             'privacy violations are no longer theoretical, they have tangible '\n",
      "             'consequences for users, organizations,\\n'\n",
      "             'and society at large.\\n'\n",
      "             'Consequently, Risk & Reliability assessment has evolved into a '\n",
      "             'central pillar of modern LLM\\n'\n",
      "             'benchmarking frameworks, rather than a peripheral addition. Its '\n",
      "             'core motivations are:\\n'\n",
      "             '1. Identification and Quantification: To systematically probe '\n",
      "             'LLMs for various negative impact\\n'\n",
      "             'patterns (e.g., generating harmful content[317], hallucinating '\n",
      "             'facts[31',\n",
      "  'combined_score': 0.33929035663604734,\n",
      "  'vector_score': 0.5654839277267456,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5542,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 34,\n",
      "  'content': 'ssessments risk over-specialization;\\n'\n",
      "             'and target-specific metrics struggle to balance technical rigor '\n",
      "             'with real-world relevance. These\\n'\n",
      "             'challenges intensify as LLMs operate in dynamic, multi-agent, '\n",
      "             'high-stakes environments, where\\n'\n",
      "             'static datasets and single-turn metrics fail to capture emergent '\n",
      "             'behaviors or societal impacts. As\\n'\n",
      "             'LLMs integrate into sociotechnical systems, evaluation must '\n",
      "             'shift from measuring \"what models can\\n'\n",
      "             'do\" to \"how they should perform responsibly.\" Future benchmarks '\n",
      "             'require dynamism (to ma',\n",
      "  'combined_score': 0.3256558656692505,\n",
      "  'vector_score': 0.5427597761154175,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5169,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': 'pabilities of LLMs, and key requirements such as detection\\n'\n",
      "             'of bias and security loopholes and systematic evaluation of '\n",
      "             'instruction compliance have not yet\\n'\n",
      "             'been effectively met. In addition, the high cost of arithmetic '\n",
      "             'and manpower required for large-scale\\n'\n",
      "             'evaluation, and the difficulty of task design to cover the '\n",
      "             'complexity of the real world are serious\\n'\n",
      "             'constraints to the healthy development of LLMs. Figure 1 shows a '\n",
      "             'timeline of representative LLM\\n'\n",
      "             'benchmarks, illustrating this rapid evolution.\\n'\n",
      "             '4',\n",
      "  'combined_score': 0.32333550453186033,\n",
      "  'vector_score': 0.5388925075531006,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 174,\n",
      "  'filename': '2508.15396v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'e (ground truth). LLM-as-a-judge metrics\\n'\n",
      "             'use LLMs to automatically evaluate the quality\\n'\n",
      "             'of texts generated by other LLMs, thereby elim-\\n'\n",
      "             'inating the need for human judges. Typically, the\\n'\n",
      "             'LLM acting as a judge produces numerical scores,\\n'\n",
      "             'often normalized to a 0–1 scale. Retrieval-based\\n'\n",
      "             'metrics quantitatively evaluate how effectively an\\n'\n",
      "             'approach incorporates relevant evidence by com-\\n'\n",
      "             'paring the retrieved or integrated evidence with\\n'\n",
      "             'a ground truth. This method is commonly used\\n'\n",
      "             'to assess whether the correct sourc',\n",
      "  'combined_score': 0.319476056098938,\n",
      "  'vector_score': 0.53246009349823,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1775,\n",
      "  'filename': '2508.15250v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'g moral beliefs\\n'\n",
      "             'across llms through a pluralistic framework. In Find-\\n'\n",
      "             'ings of the Association for Computational Linguistics:\\n'\n",
      "             'EMNLP 2024, pages 4740–4760.\\n'\n",
      "             'Giovanni Marraffini, Andrés Cotton, Noe Hsueh, Axel\\n'\n",
      "             'Fridman, Juan Wisznia, and Luciano Corro. 2024. The\\n'\n",
      "             'greatest good benchmark: Measuring llms’ alignment\\n'\n",
      "             'with utilitarian moral dilemmas. In Proceedings of the\\n'\n",
      "             '2024 Conference on Empirical Methods in Natural Lan-\\n'\n",
      "             'guage Processing, pages 21950–21959.\\n'\n",
      "             'Lennart Meincke and Andrew Carton. 2024. Beyond\\n'\n",
      "             'multiple c',\n",
      "  'combined_score': 0.3180772304534912,\n",
      "  'vector_score': 0.5301287174224854,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Automatic Mixed Precision'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2153   0.296    0.000    0.740    2508.15617v1.p     5         \n",
      "2    1417   0.291    0.485    0.000    2508.15637v1.p     31        \n",
      "3    5697   0.289    0.482    0.000    2508.15361v1.p     48        \n",
      "4    5448   0.286    0.476    0.000    2508.15361v1.p     26        \n",
      "5    4851   0.281    0.469    0.000    2508.15418v1.p     11        \n",
      "6    1313   0.279    0.465    0.000    2508.15637v1.p     15        \n",
      "\n",
      "[{'doc_idx': 2153,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'compared to our\\n'\n",
      "             'LoRA approach.\\n'\n",
      "             'Memory Optimization Techniques\\n'\n",
      "             'Due to the memory constraints from updating all parameters\\n'\n",
      "             'in full fine-tuning, we employed several advanced techniques:\\n'\n",
      "             '• Automatic\\n'\n",
      "             'Mixed\\n'\n",
      "             'Precision\\n'\n",
      "             '(AMP):\\n'\n",
      "             'Utilizing\\n'\n",
      "             'FP16/BF16\\n'\n",
      "             '(Micikevicius\\n'\n",
      "             'et\\n'\n",
      "             'al.,\\n'\n",
      "             '2017)\\n'\n",
      "             'to\\n'\n",
      "             'reduce\\n'\n",
      "             'memory consumption and accelerate training.\\n'\n",
      "             '• Gradient Checkpointing: Recomputing activations dur-\\n'\n",
      "             'ing the backward pass to reduce memory footprint (Chen\\n'\n",
      "             'et al., 2016).\\n'\n",
      "             '• ZeRO Sharding: Employed for our larger 14B param-\\n'\n",
      "             'eter models to ',\n",
      "  'combined_score': 0.2961242451252006,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7403106128130015},\n",
      " {'doc_idx': 1417,\n",
      "  'filename': '2508.15637v1.pdf',\n",
      "  'page': 31,\n",
      "  'content': ' optimal balance of recall and precision might depend on\\n'\n",
      "             'the task at hand, and the relative harm of false positive versus '\n",
      "             'false negatives (Silva Filho\\n'\n",
      "             'et al., 2023). We suggest that computer scientists allow the '\n",
      "             'users of their algorithms to\\n'\n",
      "             're-adjust the recall/precision trade-off according to their '\n",
      "             'need, based on the confidence\\n'\n",
      "             'scores of the predictions14. More interestingly, confidence '\n",
      "             'scores15 could also be used\\n'\n",
      "             'as covariates in our calibration model, reducing the uncertainty '\n",
      "             'in posterior statistical\\n'\n",
      "             'est',\n",
      "  'combined_score': 0.29081872701644895,\n",
      "  'vector_score': 0.4846978783607483,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5697,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 48,\n",
      "  'content': 'er, and Hannaneh Hajishirzi. Factscore: Fine-grained atomic '\n",
      "             'evaluation of factual precision in\\n'\n",
      "             'long form text generation, 2023.\\n'\n",
      "             '48',\n",
      "  'combined_score': 0.28918608427047726,\n",
      "  'vector_score': 0.48197680711746216,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5448,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 26,\n",
      "  'content': 'ng the highest accuracy.\\n26',\n",
      "  'combined_score': 0.2858834981918335,\n",
      "  'vector_score': 0.47647249698638916,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 4851,\n",
      "  'filename': '2508.15418v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': ' to 127. Specifically, our extraction\\n'\n",
      "             'function sequentially attempts integer conversion,\\n'\n",
      "             'rounded float conversion, and finally, averaging\\n'\n",
      "             'numeric ranges. Strings containing pitch-related\\n'\n",
      "             'keywords (e.g., \"midi\", \"pitch\", \"hz\") but lacking\\n'\n",
      "             'numeric values are marked as invalid predictions.\\n'\n",
      "             'Only predictions within the MIDI range of 0 to 127\\n'\n",
      "             'are considered valid for metric computation. In all\\n'\n",
      "             'cases, if a valid numeric value cannot be extracted\\n'\n",
      "             'from either the model’s prediction, that instance\\n'\n",
      "             'is omitted from the',\n",
      "  'combined_score': 0.28140015006065366,\n",
      "  'vector_score': 0.4690002501010895,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1313,\n",
      "  'filename': '2508.15637v1.pdf',\n",
      "  'page': 15,\n",
      "  'content': 'e algorithms is highly stochastic (i.e., confusion rates may\\n'\n",
      "             'vary a lot across recordings). We also found that the '\n",
      "             'calibration procedure improved the\\n'\n",
      "             '8The\\n'\n",
      "             'F-score\\n'\n",
      "             'is\\n'\n",
      "             'the\\n'\n",
      "             'harmonic\\n'\n",
      "             'mean\\n'\n",
      "             'of\\n'\n",
      "             'precision\\n'\n",
      "             '(\\n'\n",
      "             'true positives\\n'\n",
      "             'true positives+false positives)\\n'\n",
      "             'and\\n'\n",
      "             'recall\\n'\n",
      "             '(\\n'\n",
      "             'true positives\\n'\n",
      "             'true positives+false negatives).\\n'\n",
      "             '9These results correspond to frame-level accuracy metrics, which '\n",
      "             'depend also on the annotators’\\n'\n",
      "             'ability to precisely locate the onset/offset of a vocalization. '\n",
      "             'This is a more difficult task compared to\\n'\n",
      "             'mer',\n",
      "  'combined_score': 0.2792592108249664,\n",
      "  'vector_score': 0.4654320180416107,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Sampling Number'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    7398   0.351    0.469    0.173    2508.15648v1.p     8         \n",
      "2    7397   0.336    0.448    0.168    2508.15648v1.p     8         \n",
      "3    8294   0.319    0.000    0.797    2508.15244v1.p     6         \n",
      "4    8270   0.288    0.000    0.720    2508.15244v1.p     4         \n",
      "5    3015   0.280    0.000    0.701    2508.15371v1.p     3         \n",
      "6    8238   0.265    0.441    0.000    2508.15475v1.p     23        \n",
      "\n",
      "[{'doc_idx': 7398,\n",
      "  'filename': '2508.15648v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': ' prompt\\n'\n",
      "             'We\\n'\n",
      "             'analyze the effect of the number of responses sam-\\n'\n",
      "             'pled for each prompt. Our choice of sampling num-\\n'\n",
      "             'ber is based on balancing diversity and efficiency,\\n'\n",
      "             'optimizing the policy model by generating multi-\\n'\n",
      "             'ple completions and calculating their rewards. We\\n'\n",
      "             'select four different sampling numbers: 2, 4, 8, 16,\\n'\n",
      "             'each paired with different temperature parameters,\\n'\n",
      "             'detailed in Table 6. As shown in Figure 4, sampling\\n'\n",
      "             'reaches a plateau at 8, with further increases not\\n'\n",
      "             'leading to improvements in performance.\\n'\n",
      "             'Im',\n",
      "  'combined_score': 0.3505808699439198,\n",
      "  'vector_score': 0.4688315987586975,\n",
      "  'keyword_score': 0.17320477672175333},\n",
      " {'doc_idx': 7397,\n",
      "  'filename': '2508.15648v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'sults in Figure 4 (left) show that the\\n'\n",
      "             'model reaches a relatively low safety gap by the\\n'\n",
      "             'third step, with the gap decreasing progressively\\n'\n",
      "             'over the three rounds. This also demonstrates the\\n'\n",
      "             'effectiveness of SDGO’s online data sampling, al-\\n'\n",
      "             'lowing the model to iteratively update itself on its\\n'\n",
      "             'own generated data to achieve a new balance be-\\n'\n",
      "             'tween discrimination and generation safety.\\n'\n",
      "             'Impact of Sampling Number per prompt\\n'\n",
      "             'We\\n'\n",
      "             'analyze the effect of the number of responses sam-\\n'\n",
      "             'pled for each prompt. Our choice of sa',\n",
      "  'combined_score': 0.3358257712587238,\n",
      "  'vector_score': 0.4479081332683563,\n",
      "  'keyword_score': 0.16770222824427516},\n",
      " {'doc_idx': 8294,\n",
      "  'filename': '2508.15244v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'h the matrix language in italics and code-switched\\n'\n",
      "             '(or embedded language) segments highlighted in red.\\n'\n",
      "             '4.3\\n'\n",
      "             'Source Mixing\\n'\n",
      "             'In Sec. 3.2.2, we demonstrated that UniCoM can\\n'\n",
      "             'substitute various POS and adjust the number of\\n'\n",
      "             'word pairs as needed. However, excessive word\\n'\n",
      "             'substitution can lead to unnatural results, deviating\\n'\n",
      "             'from real-world CS scenarios. To maintain natu-\\n'\n",
      "             'ralness and ensure the generated speech reflects\\n'\n",
      "             'authentic CS patterns, we limited sampling to a\\n'\n",
      "             'maximum of three word pairs and restricted POS\\n'\n",
      "             'cate',\n",
      "  'combined_score': 0.31890004075124245,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7972501018781061},\n",
      " {'doc_idx': 8270,\n",
      "  'filename': '2508.15244v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': 'meaning. We thus adopted word- or POS-level sub-\\n'\n",
      "             'stitutions with a flexible number of substitutions,\\n'\n",
      "             'allowing natural CS sentence generation while pre-\\n'\n",
      "             'serving semantics and syntactic structure.\\n'\n",
      "             '3.2.2\\n'\n",
      "             'SWORDS Algorithm\\n'\n",
      "             'In this context, we propose the Substituting\\n'\n",
      "             'WORDs with Synonym (SWORDS) algorithm.\\n'\n",
      "             'SWORDS is composed of four steps: (1) Sampling\\n'\n",
      "             'of equivalent sentence pairs, (2) Wordpair mapping\\n'\n",
      "             'generation, (3) Segmentation using forced align-\\n'\n",
      "             'ment, (4) Completion through recombination.\\n'\n",
      "             'This approach intro',\n",
      "  'combined_score': 0.2879062728703903,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7197656821759757},\n",
      " {'doc_idx': 3015,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 3,\n",
      "  'content': 'y on a fixed number of drafted \\n'\n",
      "             'tokens per iteration and a strict binary verification scheme. \\n'\n",
      "             'While effective in reducing latency, its dependence on a \\n'\n",
      "             'model size hierarchy introduces additional memory overhead \\n'\n",
      "             'during inference. Moreover, the method does not incorporate \\n'\n",
      "             'entropy-based or token-based confidence signals, thus lacking \\n'\n",
      "             'the adaptivity necessary for optimizing decoding in variable \\n'\n",
      "             'or uncertain generation contexts.    \\n'\n",
      "             'Chen et al. introduced speculative sampling for large \\n'\n",
      "             'models like Chinchil',\n",
      "  'combined_score': 0.2804438957484629,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7011097393711572},\n",
      " {'doc_idx': 8238,\n",
      "  'filename': '2508.15475v1.pdf',\n",
      "  'page': 23,\n",
      "  'content': 'aluation set by sampling the\\n'\n",
      "             '100M word 2024 BabyLM dataset (D2024 is the 10M version; Choshen '\n",
      "             'et al., 2024). |Deval| = 0.05 · |D2024|.\\n'\n",
      "             '23',\n",
      "  'combined_score': 0.2647353708744049,\n",
      "  'vector_score': 0.4412256181240082,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'knowledge distillation'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    6300   0.503    0.496    0.515    2508.15478v1.p     12        \n",
      "2    2730   0.491    0.489    0.493    2508.15274v1.p     5         \n",
      "3    7631   0.481    0.495    0.460    2508.15709v1.p     10        \n",
      "4    8174   0.479    0.500    0.449    2508.15475v1.p     11        \n",
      "5    2105   0.380    0.633    0.000    2508.15617v1.p     1         \n",
      "6    2104   0.327    0.544    0.000    2508.15617v1.p     1         \n",
      "\n",
      "[{'doc_idx': 6300,\n",
      "  'filename': '2508.15478v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'e on Neu-\\n'\n",
      "             'ral Information Processing (ICONIP), pages 27–38.\\n'\n",
      "             'Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng\\n'\n",
      "             'Chen, and Jinan Xu. 2024a. Dual-space knowledge\\n'\n",
      "             'distillation for large language models. In Proceed-\\n'\n",
      "             'ings of the Conference on Empirical Methods in Nat-\\n'\n",
      "             'ural Language Processing (EMNLP), pages 18164–\\n'\n",
      "             '18181.\\n'\n",
      "             'Yingtao Zhang, Haoli Bai, Haokun Lin, Jialin Zhao,\\n'\n",
      "             'Lu Hou, and Carlo Vittorio Cannistraci. 2024b.\\n'\n",
      "             'Plug-and-play: An efficient post-training pruning\\n'\n",
      "             'method for large language models. In Proceedings\\n'\n",
      "             'of',\n",
      "  'combined_score': 0.5033888432528759,\n",
      "  'vector_score': 0.4959339201450348,\n",
      "  'keyword_score': 0.5145712279146375},\n",
      " {'doc_idx': 2730,\n",
      "  'filename': '2508.15274v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': '321–324.\\n'\n",
      "             '[20] Niket Tandon, Gerard de Melo, and Gerhard Weikum. 2017. '\n",
      "             'WebChild 2.0 : Fine-\\n'\n",
      "             'Grained Commonsense Knowledge Distillation. In Proceedings of '\n",
      "             'the 55th Annual\\n'\n",
      "             'Meeting of the Association for Computational Linguistics, ACL '\n",
      "             '2017, Vancouver,\\n'\n",
      "             'Canada, July 30 - August 4, System Demonstrations, Mohit Bansal '\n",
      "             'and Heng Ji\\n'\n",
      "             '(Eds.). Association for Computational Linguistics, 115–120.\\n'\n",
      "             '[21] Hugo Touvron et al. 2023. Llama 2: Open Foundation and '\n",
      "             'Fine-Tuned Chat\\n'\n",
      "             'Models. CoRR abs/2307.09288 (2023).\\n'\n",
      "             '[22] Alakananda ',\n",
      "  'combined_score': 0.49061670252132805,\n",
      "  'vector_score': 0.4890536367893219,\n",
      "  'keyword_score': 0.4929613011193372},\n",
      " {'doc_idx': 7631,\n",
      "  'filename': '2508.15709v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': ' Rush. 2016. Sequence-\\n'\n",
      "             'level knowledge distillation.\\n'\n",
      "             'Solomon Kullback and Richard A. Leibler. 1951. On\\n'\n",
      "             'information and sufficiency. Annals of Mathematical\\n'\n",
      "             'Statistics, 22(1):79–86.\\n'\n",
      "             'Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Ivan Rod-\\n'\n",
      "             'kin, Dmitry Igorevich Sorokin, Artyom Sorokin, and\\n'\n",
      "             'Mikhail Burtsev. 2024.\\n'\n",
      "             'BABILong: Testing the\\n'\n",
      "             'limits of LLMs with long context reasoning-in-a-\\n'\n",
      "             'haystack. In The Thirty-eight Conference on Neural\\n'\n",
      "             'Information Processing Systems Datasets and Bench-\\n'\n",
      "             'marks Track.\\n'\n",
      "             'Tom Kwiatkowski, Je',\n",
      "  'combined_score': 0.48084253897093465,\n",
      "  'vector_score': 0.4948987364768982,\n",
      "  'keyword_score': 0.4597582427119894},\n",
      " {'doc_idx': 8174,\n",
      "  'filename': '2508.15475v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': 'ryasov and Jean-Loup Tastet. 2023. Baby\\n'\n",
      "             'Llama: knowledge distillation from an ensemble of\\n'\n",
      "             'teachers trained on a small dataset with no perfor-\\n'\n",
      "             'mance penalty. In Proceedings of the BabyLM Chal-\\n'\n",
      "             'lenge at the 27th Conference on Computational Nat-\\n'\n",
      "             'ural Language Learning, pages 279–289, Singapore.\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\\n'\n",
      "             'Martinet, Marie-Anne Lachaux, Timothée Lacroix,\\n'\n",
      "             'Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal\\n'\n",
      "             'Azhar, Aurelien Rodrigu',\n",
      "  'combined_score': 0.47944915158689216,\n",
      "  'vector_score': 0.5000695586204529,\n",
      "  'keyword_score': 0.44851854103655114},\n",
      " {'doc_idx': 2105,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'nowledge distillation (Hinton et al., 2015)[4]. Tra-\\n'\n",
      "             'ditional distillation is a difficult process that attempts to '\n",
      "             'project\\n'\n",
      "             'a “teacher” model’s whole knowledge base onto a “student”\\n'\n",
      "             'model. This is typically done by training the student to mimic\\n'\n",
      "             'the teacher’s internal output probability distributions (the '\n",
      "             '“soft\\n'\n",
      "             'targets” or logits) over the entire vocabulary. The goal is to\\n'\n",
      "             'compress the student’s internal computational process into a\\n'\n",
      "             'compact representation of the teacher’s. Our “Trained Minia-\\n'\n",
      "             'tures” method, i',\n",
      "  'combined_score': 0.37967580556869507,\n",
      "  'vector_score': 0.6327930092811584,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2104,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'here domain experts curate and refine the outputs,\\n'\n",
      "             'filtering for strategic relevance, quality, and precision. This\\n'\n",
      "             'results in a “gold standard” training dataset of thousands of\\n'\n",
      "             'flawless input-output pairs. This refined dataset is then used '\n",
      "             'to\\n'\n",
      "             'fine-tune an order-of-magnitude smaller, more efficient open-\\n'\n",
      "             'source Small Language Model (SLM).\\n'\n",
      "             'It is essential to make a clear technical distinction from\\n'\n",
      "             'traditional knowledge distillation (Hinton et al., 2015)[4]. '\n",
      "             'Tra-\\n'\n",
      "             'ditional distillation is a difficult process th',\n",
      "  'combined_score': 0.32662507295608517,\n",
      "  'vector_score': 0.5443751215934753,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Knowledge Graph Completion Models'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1197   0.648    0.592    0.732    2508.15357v1.p     8         \n",
      "2    1103   0.460    0.706    0.092    2508.15357v1.p     1         \n",
      "3    1206   0.379    0.631    0.000    2508.15357v1.p     9         \n",
      "4    1205   0.372    0.620    0.000    2508.15357v1.p     9         \n",
      "5    1194   0.367    0.611    0.000    2508.15357v1.p     8         \n",
      "6    1189   0.356    0.593    0.000    2508.15357v1.p     8         \n",
      "\n",
      "[{'doc_idx': 1197,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'emi, S. M.; and Poole, D. 2018. Simple Embedding for\\n'\n",
      "             'Link Prediction in Knowledge Graphs. In Advances in Neu-\\n'\n",
      "             'ral Information Processing Systems, volume 31.\\n'\n",
      "             'Kim, B.; Hong, T.; Ko, Y.; and Seo, J. 2020.\\n'\n",
      "             'Multi-\\n'\n",
      "             'Task Learning for Knowledge Graph Completion with Pre-\\n'\n",
      "             'trained Language Models. In Scott, D.; Bel, N.; and Zong,\\n'\n",
      "             'C., eds., Proceedings of the 28th International Conference\\n'\n",
      "             'on Computational Linguistics, 1737–1743.Barcelona, Spain\\n'\n",
      "             '(Online): International Committee on Computational Lin-\\n'\n",
      "             'guistics.\\n'\n",
      "             'Lin, X.;',\n",
      "  'combined_score': 0.6480273692011436,\n",
      "  'vector_score': 0.5918718576431274,\n",
      "  'keyword_score': 0.7322606365381678},\n",
      " {'doc_idx': 1103,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph\\n'\n",
      "             'Completion Models\\n'\n",
      "             'Haji Gul1, Abul Ghani Naim1, Ajaz Ahmad Bhat1 ∗\\n'\n",
      "             '1School of Digital Science, Universiti Brunei Darussalam\\n'\n",
      "             '(23h1710, ghani.naim, ajaz.bhat∗)@ubd.edu.bn\\n'\n",
      "             'Abstract\\n'\n",
      "             'Knowledge Graphs (KGs) enable applications in various do-\\n'\n",
      "             'mains such as semantic search, recommendation systems,\\n'\n",
      "             'and natural language processing. KGs are often incomplete,\\n'\n",
      "             'missing entities and relations, an issue addressed by Knowl-\\n'\n",
      "             'edge Graph Completion (KGC) methods th',\n",
      "  'combined_score': 0.46009505576096776,\n",
      "  'vector_score': 0.7056922316551208,\n",
      "  'keyword_score': 0.09169929191973826},\n",
      " {'doc_idx': 1206,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ', J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In Bouamor, H.; Pino, J.;\\n'\n",
      "             'and Bali, K., eds., Findings of the Association for Compu-\\n'\n",
      "             'tational Linguistics: EMNLP 2023, 8667–8683. Singapore:\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2015.\\n'\n",
      "             'Embedding entities and relations for learning and inference\\n'\n",
      "             'in knowledge bases. arXiv preprint arXiv:1412.6575.\\n'\n",
      "             'Zhang, W.; Paudel, B.; Zhang, W.; Bernstein, A.; and Chen,\\n'\n",
      "             'H',\n",
      "  'combined_score': 0.37882543802261354,\n",
      "  'vector_score': 0.6313757300376892,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1205,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': 'guage Mod-\\n'\n",
      "             'els. In Proc. of ACL.\\n'\n",
      "             'Wang, Y.; Broscheit, S.; and Gemulla, R. 2019. A Relational\\n'\n",
      "             'Tucker Decomposition for Multi-Relational Link Prediction.\\n'\n",
      "             'arXiv preprint. ArXiv:1902.00898.\\n'\n",
      "             'Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowl-\\n'\n",
      "             'edge graph embedding by translating on hyperplanes. In\\n'\n",
      "             'Proceedings of the AAAI Conference on Artiﬁcial Intelli-\\n'\n",
      "             'gence, volume 28.\\n'\n",
      "             'Wei, Y.; Huang, Q.; Zhang, Y.; and Kwok, J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In',\n",
      "  'combined_score': 0.37220213413238523,\n",
      "  'vector_score': 0.6203368902206421,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1194,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'ext-Aware Knowledge Graph Completion. In Wu,\\n'\n",
      "             'X.; Spiliopoulou, M.; Wang, C.; Kumar, V.; Cao, L.; Zhou,\\n'\n",
      "             'X.; Pang, G.; and Gama, J., eds., Data Science: Foundations\\n'\n",
      "             'and Applications, 3–15. Singapore: Springer Nature Singa-\\n'\n",
      "             'pore. ISBN 978-981-96-8298-0.\\n'\n",
      "             'Guo, L.; Sun, Z.; and Hu, W. 2019. Learning to Exploit\\n'\n",
      "             'Long-term Relational Dependencies in Knowledge Graphs.\\n'\n",
      "             'In International Conference on Machine Learning. PMLR.\\n'\n",
      "             'Ji, G.; He, S.; Xu, L.; Liu, K.; and Zhao, J. 2015. Knowledge\\n'\n",
      "             'graph embedding via dynamic mappin',\n",
      "  'combined_score': 0.36651785373687745,\n",
      "  'vector_score': 0.6108630895614624,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1189,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'Thank you for reading these instructions carefully. We look\\n'\n",
      "             'forward to receiving your electronic ﬁles!\\n'\n",
      "             'References\\n'\n",
      "             'Akrami, F.; Saeef, M. S.; Zhang, Q.; Hu, W.; and Li, C.\\n'\n",
      "             '2020. Realistic re-evaluation of knowledge graph comple-\\n'\n",
      "             'tion methods: An experimental study. In Proceedings of the\\n'\n",
      "             '2020 ACM SIGMOD International Conference on Manage-\\n'\n",
      "             'ment of Data, 1995–2010.\\n'\n",
      "             'Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor,\\n'\n",
      "             'J. 2008. Freebase: A collaboratively created graph database\\n'\n",
      "             'for structuring human kno',\n",
      "  'combined_score': 0.3556807994842529,\n",
      "  'vector_score': 0.5928013324737549,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'contextless speech processing'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    925    0.568    0.581    0.550    2508.15316v1.p     1         \n",
      "2    929    0.534    0.589    0.450    2508.15316v1.p     1         \n",
      "3    1000   0.358    0.597    0.000    2508.15316v1.p     7         \n",
      "4    1017   0.352    0.587    0.000    2508.15316v1.p     10        \n",
      "5    4898   0.328    0.547    0.000    2508.15418v1.p     15        \n",
      "6    927    0.327    0.545    0.000    2508.15316v1.p     1         \n",
      "\n",
      "[{'doc_idx': 925,\n",
      "  'filename': '2508.15316v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'CUPE: Contextless Universal Phoneme Encoder for '\n",
      "             'Language-Agnostic\\n'\n",
      "             'Speech Processing ∗\\n'\n",
      "             'Abdul Rehman\\n'\n",
      "             'Jian-Jun Zhang\\n'\n",
      "             'Bournemouth University\\n'\n",
      "             'Bournemouth, United Kingdom\\n'\n",
      "             'arehman, jjunzhang, xyang@bournemouth.ac.uk\\n'\n",
      "             'Xiaosong Yang\\n'\n",
      "             'Abstract\\n'\n",
      "             'Universal phoneme recognition typically re-\\n'\n",
      "             'quires analyzing long speech segments and\\n'\n",
      "             'language-specific patterns.\\n'\n",
      "             'Many speech\\n'\n",
      "             'processing tasks require pure phoneme rep-\\n'\n",
      "             'resentations free from contextual influence,\\n'\n",
      "             'which motivated our development of CUPE\\n'\n",
      "             '- a lightweight model that',\n",
      "  'combined_score': 0.5684243948184879,\n",
      "  'vector_score': 0.5810128450393677,\n",
      "  'keyword_score': 0.5495417194871683},\n",
      " {'doc_idx': 929,\n",
      "  'filename': '2508.15316v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 's of speech, incorporating\\n'\n",
      "             'extensive language-specific patterns and contex-\\n'\n",
      "             'tual dependencies. While effective for automatic\\n'\n",
      "             'speech recognition, this approach entangles pho-\\n'\n",
      "             'netic content with contextual information, making\\n'\n",
      "             'it extremely difficult to disentangle the acoustic\\n'\n",
      "             'properties that define individual speech sounds.\\n'\n",
      "             '0Accepted in: 8th International Conference on Natural\\n'\n",
      "             'Language and Speech Processing (ICNLSP 2025)\\n'\n",
      "             'The necessity for contextless processing emerges\\n'\n",
      "             'from two critical considerations: alignm',\n",
      "  'combined_score': 0.5337684481418697,\n",
      "  'vector_score': 0.5893085598945618,\n",
      "  'keyword_score': 0.4504582805128317},\n",
      " {'doc_idx': 1000,\n",
      "  'filename': '2508.15316v1.pdf',\n",
      "  'page': 7,\n",
      "  'content': 'h focused analysis of\\n'\n",
      "             'brief speech segments. These results provide com-\\n'\n",
      "             'pelling evidence that extensive temporal context\\n'\n",
      "             'is not a requirement for robust speech processing\\n'\n",
      "             'tasks. While our approach has some limitations,\\n'\n",
      "             'particularly with very long phonemes and limited\\n'\n",
      "             'phoneme inventory, it opens promising directions\\n'\n",
      "             'for lightweight, language-agnostic speech process-\\n'\n",
      "             'ing systems. CUPE’s effectiveness has significant\\n'\n",
      "             'implications for real-world applications, from low-\\n'\n",
      "             'latency speech recognition and ASR self-le',\n",
      "  'combined_score': 0.3583174109458923,\n",
      "  'vector_score': 0.5971956849098206,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1017,\n",
      "  'filename': '2508.15316v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'in contextless recognition,\\n'\n",
      "             'with clear probability peaks corresponding to ground truth '\n",
      "             'phonemes. Notable patterns include smooth transitions\\n'\n",
      "             'between phonemes within words and distinct silence regions (SIL) '\n",
      "             'between words, highlighting the model’s temporal\\n'\n",
      "             'resolution at 13ms.',\n",
      "  'combined_score': 0.35213820934295653,\n",
      "  'vector_score': 0.5868970155715942,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 4898,\n",
      "  'filename': '2508.15418v1.pdf',\n",
      "  'page': 15,\n",
      "  'content': 'sampled cases.\\n'\n",
      "             'In (II)(a) where both the instruction and input are\\n'\n",
      "             'delivered as audio, the model answers successfully\\n'\n",
      "             'classifying the object as non-living, demonstrating\\n'\n",
      "             'effective handling of its core modality. Nonethe-\\n'\n",
      "             'less, when presented with configurations outside\\n'\n",
      "             'this primary distribution, the model fails to execute\\n'\n",
      "             'the intended tasks. In the text plus audio modality\\n'\n",
      "             'format (II)(b), it is unable to infer the speaker’s\\n'\n",
      "             'aim from the speech and instead requests further\\n'\n",
      "             'contextual details. Under (II)(c) th',\n",
      "  'combined_score': 0.32805755138397213,\n",
      "  'vector_score': 0.5467625856399536,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 927,\n",
      "  'filename': '2508.15316v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ges. Our\\n'\n",
      "             'extensive evaluation through supervised and\\n'\n",
      "             'self-supervised training on diverse languages,\\n'\n",
      "             'including zero-shot tests on the UCLA Pho-\\n'\n",
      "             'netic Corpus, demonstrates strong cross-lingual\\n'\n",
      "             'generalization and reveals that effective univer-\\n'\n",
      "             'sal speech processing is possible through mod-\\n'\n",
      "             'eling basic acoustic patterns within phoneme-\\n'\n",
      "             'length windows.\\n'\n",
      "             '1\\n'\n",
      "             'Introduction\\n'\n",
      "             'Current speech processing systems depend heav-\\n'\n",
      "             'ily on contextual information, creating a double-\\n'\n",
      "             'edged sword for certain tasks. While extensive\\n'\n",
      "             'con',\n",
      "  'combined_score': 0.3271057248115539,\n",
      "  'vector_score': 0.5451762080192566,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Elastic Weight Consolidation algorithm'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2643   0.311    0.519    0.000    2508.15294v1.p     8         \n",
      "2    2560   0.280    0.467    0.000    2508.15294v1.p     1         \n",
      "3    7995   0.278    0.464    0.000    2508.15757v1.p     4         \n",
      "4    2446   0.271    0.452    0.000    2508.15464v1.p     5         \n",
      "5    8019   0.261    0.436    0.000    2508.15757v1.p     6         \n",
      "6    8028   0.259    0.431    0.000    2508.15757v1.p     7         \n",
      "\n",
      "[{'doc_idx': 2643,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'olidation in llm-based agents.\\n'\n",
      "             'In Ex-\\n'\n",
      "             'tended Abstracts of the CHI Conference on Human Factors\\n'\n",
      "             'in Computing Systems, 1–7.\\n'\n",
      "             'Hu, C.; Fu, J.; Du, C.; Luo, S.; Zhao, J.; and Zhao, H. 2023.\\n'\n",
      "             'Chatdb: Augmenting llms with databases as their symbolic\\n'\n",
      "             'memory. arXiv preprint arXiv:2306.03901.\\n'\n",
      "             'Husz´ar, F. 2018. Note on the quadratic penalties in elastic\\n'\n",
      "             'weight consolidation. Proceedings of the National Academy\\n'\n",
      "             'of Sciences, 115(11): E2496–E2497.\\n'\n",
      "             'Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii, '\n",
      "             'E.;\\n'\n",
      "             'Bang, Y. J.;',\n",
      "  'combined_score': 0.31127192974090573,\n",
      "  'vector_score': 0.5187865495681763,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2560,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ametrically, by\\n'\n",
      "             'augmenting LLMs with additional parameters, knowledge\\n'\n",
      "             'can be retained for future use (Wang et al. 2023). The Elas-\\n'\n",
      "             'tic Weight Consolidation algorithm (Husz´ar 2018) , devel-\\n'\n",
      "             'oped through collaboration between DeepMind and Imperial\\n'\n",
      "             'College London, enables neural networks to retain knowl-\\n'\n",
      "             'edge from previous tasks while learning new ones, miti-\\n'\n",
      "             'gating the ”catastrophic forgetting” problem and marking\\n'\n",
      "             'a significant step towards continuous learning in AI. How-\\n'\n",
      "             'ever, parametric memory is prone to ',\n",
      "  'combined_score': 0.28005189299583433,\n",
      "  'vector_score': 0.46675315499305725,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7995,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': ' optimization',\n",
      "  'combined_score': 0.2783568441867828,\n",
      "  'vector_score': 0.46392807364463806,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2446,\n",
      "  'filename': '2508.15464v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'nlike static reward\\n'\n",
      "             'averaging, SDW encourages more balanced learn-\\n'\n",
      "             'ing and improves robustness across diverse error\\n'\n",
      "             'types.\\n'\n",
      "             'Algorithm 1 Sub-score Dynamic Weighting\\n'\n",
      "             'Require: F1 scores, update interval M, temperature α\\n'\n",
      "             'Initialize wj ←1 for j = 1, . . . , K\\n'\n",
      "             'for each training step t = 1 to T do\\n'\n",
      "             'if t mod M = 0 then\\n'\n",
      "             'Calculate F1(j) score for each aspect j\\n'\n",
      "             'Compute average F1: ¯F1 ←\\n'\n",
      "             '1\\n'\n",
      "             'K\\n'\n",
      "             'PK\\n'\n",
      "             'j=1 F1(j)\\n'\n",
      "             'for each aspect j = 1 to K do\\n'\n",
      "             'Compute F1 gap: ∆j ←¯F1 −F1(j)\\n'\n",
      "             'end for\\n'\n",
      "             'Update weights with softmax:\\n'\n",
      "             'wj ←1 +\\n'\n",
      "             'exp(α · ∆j)\\n',\n",
      "  'combined_score': 0.27126837372779844,\n",
      "  'vector_score': 0.45211395621299744,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 8019,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'eature\\n'\n",
      "             '\\x00Engineering\\n'\n",
      "             'Hyper\\n'\n",
      "             '\\x00Parameter\\n'\n",
      "             'Iterations\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             'Epochs\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             'loss: cross entropy\\n'\n",
      "             '\\x00optimizer: adam\\n'\n",
      "             'filter1: 8 →16\\n'\n",
      "             '\\x00filter2: 16 →32\\n'\n",
      "             '\\x00Add kernal3\\n'\n",
      "             '\\x00dropout: 0.2 →0.4\\n'\n",
      "             'i = 1\\n'\n",
      "             't = 1\\n'\n",
      "             '/\\n'\n",
      "             'lr: 0.01\\n'\n",
      "             '\\x00weight decay: 0.0001\\n'\n",
      "             'loss: focal loss\\n'\n",
      "             '\\x00optimizer: adamw\\n'\n",
      "             'Flip\\n'\n",
      "             'i = 2\\n'\n",
      "             't = 3\\n'\n",
      "             '/\\n'\n",
      "             'lr: 0.02\\n'\n",
      "             '\\x00weight decay: 0.0005\\n'\n",
      "             '\\x00class_3_weight=1.2\\n'\n",
      "             'loss: cross entropy\\n'\n",
      "             'optimizer: adam\\n'\n",
      "             'filter1: 16 →32\\n'\n",
      "             '\\x00filter2: 32 →64\\n'\n",
      "             '\\x00filter3: 64 →128\\n'\n",
      "             '\\x00dropout: 0.4 →0.3\\n'\n",
      "             'Rotation\\n'\n",
      "             't = 7\\n'\n",
      "             'lr: 0.02\\n'\n",
      "             '\\x00weight_decay: 0.0005\\n'\n",
      "             '\\x00class_8_weight=0.95\\n'\n",
      "             'class_9_w',\n",
      "  'combined_score': 0.26147992014884947,\n",
      "  'vector_score': 0.43579986691474915,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 8028,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 7,\n",
      "  'content': 'on inverse class frequency (e.g., weight_class_i =\\n'\n",
      "             'total_samples / (num_classes * count_class_i)).\\n'\n",
      "             '\\x00- Monitor validation recall and ROC-AUC for improvements.\\n'\n",
      "             '\\x002. If Stagnation Persists:\\n'\n",
      "             '\\x00- Gradually increase weights for the worst-performing '\n",
      "             'classes (e.g., lowest recall).\\n'\n",
      "             '\\x00- Data augmentation or dropout to reduce overfitting (if '\n",
      "             'validation loss starts\\n'\n",
      "             'rising).\\n'\n",
      "             'Evaluator\\n'\n",
      "             'Advisor\\n'\n",
      "             'Optimizer\\n'\n",
      "             'Figure 4: Example agent outputs showing multi-agent inter-\\n'\n",
      "             'action. The Advisor provides specific configuration recom-\\n'\n",
      "             'mend',\n",
      "  'combined_score': 0.2588670372962952,\n",
      "  'vector_score': 0.43144506216049194,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Neural Ranking Models'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    6164   0.500    0.509    0.486    2508.15283v1.p     10        \n",
      "2    6158   0.488    0.505    0.462    2508.15283v1.p     10        \n",
      "3    6180   0.480    0.536    0.396    2508.15283v1.p     11        \n",
      "4    6113   0.335    0.558    0.000    2508.15283v1.p     5         \n",
      "5    6049   0.322    0.537    0.000    2508.15283v1.p     1         \n",
      "6    6162   0.317    0.529    0.000    2508.15283v1.p     10        \n",
      "\n",
      "[{'doc_idx': 6164,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': '23. Towards\\n'\n",
      "             'Imperceptible Document Manipulations against Neural Ranking '\n",
      "             'Models. arXiv\\n'\n",
      "             'preprint arXiv:2305.01860 (2023).\\n'\n",
      "             '[8] Charles L. A. Clarke, Maria Maistro, and Mark D. Smucker. '\n",
      "             '2021. Overview of\\n'\n",
      "             'the TREC 2021 Health Misinformation Track. In Proceedings of the '\n",
      "             'Thirtieth\\n'\n",
      "             'Text REtrieval Conference, TREC 2021, online, November 15-19, '\n",
      "             '2021 (NIST\\n'\n",
      "             'Special Publication), Ian Soboroff and Angela Ellis (Eds.), Vol. '\n",
      "             '500-335. National\\n'\n",
      "             'Institute of Standards and Technology (NIST). '\n",
      "             'https://trec.nist.gov/pubs/trec30/\\n',\n",
      "  'combined_score': 0.4997025374532821,\n",
      "  'vector_score': 0.5090404748916626,\n",
      "  'keyword_score': 0.4856956312957113},\n",
      " {'doc_idx': 6158,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'ul exemplars. Through\\n'\n",
      "             'rigorous evaluation on two high-stakes TREC datasets, two '\n",
      "             'distinct\\n'\n",
      "             'LLMs, and diverse NRMs, we showed that FSAPInterQ consistently\\n'\n",
      "             'achieves high attack effectiveness, strong stance alignment, and '\n",
      "             'high\\n'\n",
      "             'undetectability, hence demonstrating its viability as a '\n",
      "             'generalizable\\n'\n",
      "             'and transferable threat model.\\n'\n",
      "             'As future work, we are interested in expanding the current work\\n'\n",
      "             'in at least two directions:\\n'\n",
      "             '• Adversarial generalization theory in in neural ranking '\n",
      "             'models:\\n'\n",
      "             'We aim to develop a theoretical ',\n",
      "  'combined_score': 0.48759015148340507,\n",
      "  'vector_score': 0.5049782395362854,\n",
      "  'keyword_score': 0.46150801940408465},\n",
      " {'doc_idx': 6180,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': 'es of large language models.\\n'\n",
      "             'arXiv preprint arXiv:2311.08838 (2023).\\n'\n",
      "             '[37] Yumeng Wang, Lĳun Lyu, and Avishek Anand. 2022. BERT '\n",
      "             'rankers are brittle: a\\n'\n",
      "             'study using adversarial document perturbations. In Proceedings '\n",
      "             'of the 2022 ACM\\n'\n",
      "             'SIGIR International Conference on Theory of Information '\n",
      "             'Retrieval. 115–120.\\n'\n",
      "             '[38] Chen Wu, Ruqing Zhang, Jiafeng Guo, Maarten De Rĳke, Yixing '\n",
      "             'Fan, and Xueqi\\n'\n",
      "             'Cheng. 2023. Prada: practical black-box adversarial attacks '\n",
      "             'against neural ranking\\n'\n",
      "             'models. ACM Transactions on Information Syst',\n",
      "  'combined_score': 0.47996899060233494,\n",
      "  'vector_score': 0.536073625087738,\n",
      "  'keyword_score': 0.39581203887423033},\n",
      " {'doc_idx': 6113,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'apabilities despite its smaller size.\\n'\n",
      "             'Neural Ranking Models (NRMs). To compare LLM-generated\\n'\n",
      "             'harmful documents with their human-written helpful and harmful\\n'\n",
      "             'counterparts within a pool of documents, we leveraged four dif-\\n'\n",
      "             'ferent NRMs to rank these documents. Two of these NRMs are\\n'\n",
      "             'well-established supervised re-ranking models: MonoBERT [25] '\n",
      "             'and\\n'\n",
      "             'MonoT5 [25]. The other two NRMs are zero-shot ranking models\\n'\n",
      "             'built based on OpenAI embeddings: text-embedding-ada-002\\n'\n",
      "             'and text-3-embedding-small.\\n'\n",
      "             'For re-ranking purpose',\n",
      "  'combined_score': 0.3350022196769714,\n",
      "  'vector_score': 0.5583370327949524,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 6049,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'rial attacks in information retrieval, Neural ranking models,\\n'\n",
      "             'Large language models\\n'\n",
      "             '1\\n'\n",
      "             'INTRODUCTION\\n'\n",
      "             'Ensuring the integrity and accuracy of the results presented to\\n'\n",
      "             'searchers by Information Retrieval (IR) systems is crucial, '\n",
      "             'particularly\\n'\n",
      "             'in sensitive domains like health and politics. Despite recent '\n",
      "             'advances\\n'\n",
      "             'in Neural Ranking Models (NRMs), studies have shown that these\\n'\n",
      "             'methods still suffer from a lack of robustness and are '\n",
      "             'vulnerable\\n'\n",
      "             'to adversarial attacks [3, 7, 19, 20, 38]. These attacks, '\n",
      "             'commonly\\n'\n",
      "             'known as ',\n",
      "  'combined_score': 0.3220847725868225,\n",
      "  'vector_score': 0.5368079543113708,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 6162,\n",
      "  'filename': '2508.15283v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'ns (2024), 100545.\\n'\n",
      "             '[3] Amin Bigdeli, Negar Arabzadeh, Ebrahim Bagheri, and Charles '\n",
      "             'LA Clarke. 2024.\\n'\n",
      "             'EMPRA: Embedding Perturbation Rank Attack against Neural Ranking '\n",
      "             'Models.\\n'\n",
      "             'arXiv preprint arXiv:2412.16382 (2024).\\n'\n",
      "             '[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared '\n",
      "             'D Kaplan,\\n'\n",
      "             'Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish '\n",
      "             'Sastry, Amanda\\n'\n",
      "             'Askell, et al. 2020. Language models are few-shot learners. '\n",
      "             'Advances in neural\\n'\n",
      "             'information processing systems 33 (2020), 1877–1901.\\n'\n",
      "             '[5] Carlos Castil',\n",
      "  'combined_score': 0.3174514532089233,\n",
      "  'vector_score': 0.5290857553482056,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Contrastive Learning Based Fine Tuning'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    7474   0.593    0.494    0.742    2508.15471v1.p     2         \n",
      "2    7471   0.381    0.000    0.951    2508.15471v1.p     2         \n",
      "3    7473   0.375    0.543    0.124    2508.15471v1.p     2         \n",
      "4    7494   0.347    0.530    0.074    2508.15471v1.p     6         \n",
      "5    7465   0.334    0.000    0.834    2508.15471v1.p     1         \n",
      "6    744    0.322    0.537    0.000    2508.15392v1.p     11        \n",
      "\n",
      "[{'doc_idx': 7474,\n",
      "  'filename': '2508.15471v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': '94% certainty that LLM’s judgments align\\n'\n",
      "             'with human evaluations using the standard chi-square test.The '\n",
      "             'simulation re-\\n'\n",
      "             'sults indicate that contrastive loss-based fine-tuning achieves '\n",
      "             'approximately 17%\\n'\n",
      "             'improvement in the acceptance rate—defined as the ratio of '\n",
      "             'offers accepted to\\n'\n",
      "             'the total offers proposed - compared to the baseline approach.\\n'\n",
      "             'The remainder of this paper is organized as follows. Section 2 '\n",
      "             'reviews re-\\n'\n",
      "             'lated work on the application of Large Language Models (LLMs) '\n",
      "             'and contrastive\\n'\n",
      "             'learning. Section ',\n",
      "  'combined_score': 0.5934933772649057,\n",
      "  'vector_score': 0.49424222111701965,\n",
      "  'keyword_score': 0.7423701114867348},\n",
      " {'doc_idx': 7471,\n",
      "  'filename': '2508.15471v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': '2\\n'\n",
      "             'Veda et al.\\n'\n",
      "             'Groot, 2022; Tomczyk, Buhalis, Fan, & Williams, 2022)[7]. '\n",
      "             'According to Kotler\\n'\n",
      "             'and Keller (Marketing Management, 15th Edition), ’a marketing '\n",
      "             'offer is defined\\n'\n",
      "             'as a combination of products, services, information, or '\n",
      "             'experiences presented to\\n'\n",
      "             'a market to fulfill a specific need or want’. This paper '\n",
      "             'presents SLM4Offer, a Gen\\n'\n",
      "             'AI model, built by applying contrastive learning based '\n",
      "             'fine-tuning on Google’s\\n'\n",
      "             'T5, to create personalized marketing offers for a given customer '\n",
      "             'profile.\\n'\n",
      "             'This approach builds on ',\n",
      "  'combined_score': 0.3805235761886045,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.9513089404715112},\n",
      " {'doc_idx': 7473,\n",
      "  'filename': '2508.15471v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'ich are the rejected offers by a particular customer. To the '\n",
      "             'best\\n'\n",
      "             'of the author’s knowledge this is the first time that '\n",
      "             'contrastive fine-tuning of a\\n'\n",
      "             'Generative AI model is used to generate personalized marketing '\n",
      "             'offers.\\n'\n",
      "             'This paper compares the performance of contrastive '\n",
      "             'learning-based fine-tuning\\n'\n",
      "             'with a baseline approach that employs supervised fine-tuning on '\n",
      "             'the same Google\\n'\n",
      "             'T5 model. The authors report with 94% certainty that LLM’s '\n",
      "             'judgments align\\n'\n",
      "             'with human evaluations using the standard chi-square test.T',\n",
      "  'combined_score': 0.375174120570947,\n",
      "  'vector_score': 0.5425010323524475,\n",
      "  'keyword_score': 0.12418375289869618},\n",
      " {'doc_idx': 7494,\n",
      "  'filename': '2508.15471v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 's of accepted and rejected offers from the decoder’s hidden '\n",
      "             'states. Fig-\\n'\n",
      "             'ure 4 shows the contrastive learning-based fine-tuning process, '\n",
      "             'which uses the\\n'\n",
      "             'persona embedding, the generated accepted offer embedding, and '\n",
      "             'the generated\\n'\n",
      "             'rejected offer embedding. These embeddings are used to fine-tune '\n",
      "             'the T5 model\\n'\n",
      "             'weights through contrastive learning. Figure 5 illustrates the '\n",
      "             'use of traditional\\n'\n",
      "             'cross-entropy loss by comparing generated offers with ground '\n",
      "             'truth offers. This\\n'\n",
      "             'loss is used for supervised fine-tuning of ',\n",
      "  'combined_score': 0.3472404805362021,\n",
      "  'vector_score': 0.5295769572257996,\n",
      "  'keyword_score': 0.07373576550180584},\n",
      " {'doc_idx': 7465,\n",
      "  'filename': '2508.15471v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'SLM4Offer: Personalized Marketing Offer\\n'\n",
      "             'Generation Using Contrastive Learning Based\\n'\n",
      "             'Fine-Tuning\\n'\n",
      "             'Vedasamhitha Challapalli, Konduru Venkat Sai, Piyush Pratap '\n",
      "             'Singh, Rupesh\\n'\n",
      "             'Prasad, Arvind Maurya, and Atul Singh\\n'\n",
      "             'SPARC Research, HCLSoftware, Bengaluru\\n'\n",
      "             'Abstract. Personalized marketing has emerged as a pivotal '\n",
      "             'strategy\\n'\n",
      "             'for enhancing customer engagement and driving business growth. '\n",
      "             'Aca-\\n'\n",
      "             'demic and industry efforts have predominantly focused on '\n",
      "             'recommenda-\\n'\n",
      "             'tion systems and personalized advertisements. Nonetheless, th',\n",
      "  'combined_score': 0.33369779083526413,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.8342444770881603},\n",
      " {'doc_idx': 744,\n",
      "  'filename': '2508.15392v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': 'uctive fine-tuning from spectral perspective. In Proceedings of '\n",
      "             'the ACM Web\\n'\n",
      "             'Conference 2024 pages 4328–4339.\\n'\n",
      "             '11',\n",
      "  'combined_score': 0.3222042560577392,\n",
      "  'vector_score': 0.5370070934295654,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Conflict Aware Soft Prompting'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1544   0.537    0.511    0.578    2508.15253v1.p     2         \n",
      "2    1533   0.525    0.573    0.453    2508.15253v1.p     1         \n",
      "3    1534   0.423    0.516    0.284    2508.15253v1.p     1         \n",
      "4    1611   0.369    0.000    0.922    2508.15253v1.p     9         \n",
      "5    1540   0.328    0.546    0.000    2508.15253v1.p     1         \n",
      "6    148    0.310    0.517    0.000    2508.15396v1.p     6         \n",
      "\n",
      "[{'doc_idx': 1544,\n",
      "  'filename': '2508.15253v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'ation (CARE), comprising two\\n'\n",
      "             'components: a context assessor and a base LLM.\\n'\n",
      "             'The context assessor, instantiated from the base\\n'\n",
      "             'LLM itself, is designed to identify knowledge con-\\n'\n",
      "             'flicts. Inspired by soft prompting (Ge et al., 2024),\\n'\n",
      "             'the context assessor encodes external context into\\n'\n",
      "             'compact, trainable memory tokens, referred to as\\n'\n",
      "             'soft context embeddings.\\n'\n",
      "             'Specifically, the context assessor is trained using\\n'\n",
      "             'a conflict-aware training strategy. First, we perform\\n'\n",
      "             'reconstruction pre-training to enable the context\\n'\n",
      "             'a',\n",
      "  'combined_score': 0.5374115832521146,\n",
      "  'vector_score': 0.5106509923934937,\n",
      "  'keyword_score': 0.5775524695400459},\n",
      " {'doc_idx': 1533,\n",
      "  'filename': '2508.15253v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'Conflict-Aware Soft Prompting for Retrieval-Augmented '\n",
      "             'Generation\\n'\n",
      "             'Eunseong Choi, June Park, Hyeri Lee, Jongwuk Lee*\\n'\n",
      "             'Sungkyunkwan University, Republic of Korea\\n'\n",
      "             '{eunseong, pj00515, bluepig94, jongwuklee}@skku.edu\\n'\n",
      "             'Abstract\\n'\n",
      "             'Retrieval-augmented generation (RAG) en-\\n'\n",
      "             'hances the capabilities of large language mod-\\n'\n",
      "             'els (LLMs) by incorporating external knowl-\\n'\n",
      "             'edge into their input prompts. However, when\\n'\n",
      "             'the retrieved context contradicts the LLM’s\\n'\n",
      "             'parametric knowledge, it often fails to resolve\\n'\n",
      "             'the conflict between inc',\n",
      "  'combined_score': 0.5251242566106723,\n",
      "  'vector_score': 0.5731720924377441,\n",
      "  'keyword_score': 0.45305250287006443},\n",
      " {'doc_idx': 1534,\n",
      "  'filename': '2508.15253v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ntext contradicts the LLM’s\\n'\n",
      "             'parametric knowledge, it often fails to resolve\\n'\n",
      "             'the conflict between incorrect external context\\n'\n",
      "             'and correct parametric knowledge, known as\\n'\n",
      "             'context-memory conflict. To tackle this prob-\\n'\n",
      "             'lem, we introduce Conflict-Aware REtrieval-\\n'\n",
      "             'Augmented Generation (CARE), consisting of\\n'\n",
      "             'a context assessor and a base LLM. The context\\n'\n",
      "             'assessor encodes external context into compact\\n'\n",
      "             'memory embeddings. Through grounded/adver-\\n'\n",
      "             'sarial soft prompting, the context assessor is\\n'\n",
      "             'trained to discern unreliabl',\n",
      "  'combined_score': 0.42293598091061746,\n",
      "  'vector_score': 0.5157604217529297,\n",
      "  'keyword_score': 0.2836993196471491},\n",
      " {'doc_idx': 1611,\n",
      "  'filename': '2508.15253v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': 'ternal versus external knowledge. It is trained\\n'\n",
      "             'with grounded/adversarial soft prompting under\\n'\n",
      "             'conflict-aware supervision, which enables the con-\\n'\n",
      "             'text assessor to adjust the effective reasoning path\\n'\n",
      "             'for the base LLM. Experimental results demon-\\n'\n",
      "             'strate that CARE achieves state-of-the-art perfor-\\n'\n",
      "             'mance gains by up to 5.0% across diverse tasks by\\n'\n",
      "             'discerning conflicting knowledge and preserving\\n'\n",
      "             'the general-purpose ability of the base LLM.\\n'\n",
      "             '7\\n'\n",
      "             'Limitations\\n'\n",
      "             'We have thoroughly listed the limitations in CARE\\n'\n",
      "             'as follow',\n",
      "  'combined_score': 0.36883706706886443,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.922092667672161},\n",
      " {'doc_idx': 1540,\n",
      "  'filename': '2508.15253v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': ' external\\n'\n",
      "             'context before or after the answer generation. How-\\n'\n",
      "             'ever, due to the LLM’s limited capacity for conflict\\n'\n",
      "             'detection, it is susceptible to misleading contextual\\n'\n",
      "             'inputs that contradict the LLM’s encoded knowl-\\n'\n",
      "             'edge. Recently, robust training is equipped with the\\n'\n",
      "             'LLM for conflict detection (Asai et al., 2024; Wang\\n'\n",
      "             'et al., 2024). As shown in Figure 2(a), it enables\\n'\n",
      "             'the LLM to discern conflicts and assess the confi-\\n'\n",
      "             'dence of external contexts, i.e., whether to rely on\\n'\n",
      "             'them during generation. Although it',\n",
      "  'combined_score': 0.327767014503479,\n",
      "  'vector_score': 0.5462783575057983,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 148,\n",
      "  'filename': '2508.15396v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'and Kruschwitz, 2025; Xia et al., 2025). Chain-\\n'\n",
      "             'of-thought prompting is adopted in 11% of cases,\\n'\n",
      "             'typically to elicit intermediate reasoning steps that\\n'\n",
      "             'support stronger evidence attribution (Li et al.,\\n'\n",
      "             '2024c,e). In several studies, these prompting ap-\\n'\n",
      "             'proaches are combined, for example by pairing\\n'\n",
      "             'few-shot examples with chain-of-thought reason-\\n'\n",
      "             'ing (Shaier et al., 2024; Muller et al., 2023).\\n'\n",
      "             'Beyond state-of-the-art prompting approaches,\\n'\n",
      "             'a small number of papers introduce strategies\\n'\n",
      "             'specifically designed to im',\n",
      "  'combined_score': 0.31002330780029297,\n",
      "  'vector_score': 0.5167055130004883,\n",
      "  'keyword_score': 0.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    result = hybrid_search(query, 6)\n",
    "    print('\\r')\n",
    "    pprint.pprint(result, sort_dicts=False)\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93edeb",
   "metadata": {},
   "source": [
    "### 5) A FastAPI endpoint \"/hybrid-search\" has been implemented in hybrid_search.py. To test its API, run the following code and then test the API in a browser at 127.0.0.1/8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88811fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/home/ehan/evanhan_homework/evanhan_homework/class5']\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m1809280\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m1809332\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "FAISS index and documents files loaded\n",
      "Successfully opened the database\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m1809332\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m1809280\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "! python3 ./src/hybrid_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa2f0a",
   "metadata": {},
   "source": [
    "**Note:** The PDF files processed in this assignment had been downloaded in the last assignment by the get_latest_arxiv() function in documents_downloading.py. To perform this task again:\n",
    "\n",
    "from src.documents_downloading import get_latest_arxiv \n",
    "<br>\n",
    "get_latest_arxiv(query=\"cat:cs.CL\", max_results=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d531c97",
   "metadata": {},
   "source": [
    "### 6) Remarks\n",
    "\n",
    "Based on the calculated Recall@k metrics on following five queries (with chunk ids identified for the occurances of the searched terms, alpha=0.6), the hybrid method provided more accurate results than vector or keywork search alone, with Hitrate@6 always being 1 and overall better Recall@k rates. It performed much better than the vector-only search, but it didn't always perform better than the keywork-only search in terms of Recall@k rates. \n",
    "<br>\n",
    "The search algothrims and score-merging methods can be further adjusted and enhanced to make the hybrid search method perform better.\n",
    "\n",
    "    \"Normative LLMs Profiling\", # 1674, 1675, 1682\n",
    "    \"Automatic Mixed Precision\", # 2147, other chunk in same page\n",
    "    \"Sampling Number\", #7397, 7398\n",
    "    \"knowledge distillation\", # 1571, 1572, 2104, 2730, 3126, 6206, 6274, 6300, 7522, 7523, 7534, 7630, 8173, 8174  (13)\n",
    "    \"Knowledge Graph Completion Models\", # 1103/04, 1184, 1189, 1197, 1199, 1205/06, 3846/48 (7)  \n",
    "    \"contextless speech processing\", # 925, 929/930, 985, 1017 (4)\n",
    "    \"Elastic Weight Consolidation algorithm\", # 2560, 2643 (2)\n",
    "    \"Neural Ranking Models\", # 6044, 6047/48/49, 6070, 6072/73, 6084, 6099, 6112/13, 6016, 6125, 6128, 6131, 6139, 6146, 6158/59, 6162/3/4, 6171/2/3/5, 6180/81 (20) \n",
    "    \"Contrastive Learning Based Fine Tuning\", # 840, 4275, 6299, 7465, 7469/71/3/4/5, 7480, 7483/4, 7490-4, 7507/09, 7512/14/16/20 (15)\n",
    "    \"Conflict Aware Soft Prompting\" # 1533/34/35, 1544/45, 1568/69, 1611, (6)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55221e58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9c6d7e",
   "metadata": {},
   "source": [
    "| Query        | Recall@6 Vector | Recall@10 Vector | Recall@6 Keyword  | Recall@6 Hybrid |\n",
    "|--------------|-----------------|------------------|------------------------------|-------|\n",
    "| 1. \"Normative ..\"| 0.33| 0.33   |    1     |     0.33      |\n",
    "| 2. \"Automatic ..\"  | 0  | 0       |    1     |    0.5        |\n",
    "| 3. \"Sampling ..\"  | 1  | 1       |   1      |     1         |\n",
    "| 4. \"knowledge d..\"  | 0.23 | 0.46  |  0.38     |     0.38     |\n",
    "| 5. \"Knowledge G ..\"  | 0.62 | 1  |  0.37     |     0.62     |\n",
    "| 6. \"contextless ..\"  | 0.75 |  1 |  0.5    |     0.75     |\n",
    "| 7. \"Elastic ..\"  | 1 |  1 |  0   |     1     | \n",
    "| 8. \"Neural R ..\"  | 0.3 | 0.4 |  0.3   |    0.3   | \n",
    "| 9. \"Contrastive L ..\" | 0.26 | 0.4 | 0.4   |  0.4\n",
    "| 10. \"Conflict  ..\"  | 0.67 | 0.75 |  0.83   |    0.83   | "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8959c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_class4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
