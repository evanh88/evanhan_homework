{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88facc79",
   "metadata": {},
   "source": [
    "# Assignment for week 5 - Hybrid Search evaluation notebook\n",
    "\n",
    "This notebook presents the steps for evaluating the code of vector-only, keyword-only, and hybrid (Weighted summary) search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9c34",
   "metadata": {},
   "source": [
    "1) To extract and split the text from the PDF files stored at ./pdfs, build sqlite3 database and FAISS index for keyword/vector search, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f166146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehan/venv/venv_class4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf chunk file saved!\n",
      "Sqlite3 database file saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Build an absolute path from this notebook's src directory\n",
    "module_path = os.path.abspath('./src')\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if module_path not in os.sys.path:\n",
    "    os.sys.path.append(module_path)\n",
    "\n",
    "from build_sqlite3_db_and_faiss_index import build\n",
    "build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b11a8",
   "metadata": {},
   "source": [
    "2) To load the document chunks, FAISS index, then execute vector search on queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed369be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and documents files loaded\n",
      "query = \" Normative LLMs Profiling \"\n",
      "\n",
      "Vector Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    5434     0.565    2508.15361v1.pdf   25        \n",
      "2    1682     0.553    2508.15250v1.pdf   1         \n",
      "3    5542     0.543    2508.15361v1.pdf   34        \n",
      "4    5169     0.539    2508.15361v1.pdf   4         \n",
      "5    174      0.532    2508.15396v1.pdf   8         \n",
      "6    1775     0.530    2508.15250v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" semantic similarity \"\n",
      "\n",
      "Vector Search Results, for query: 'semantic similarity'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    319      0.602    2508.15396v1.pdf   22        \n",
      "2    5212     0.544    2508.15361v1.pdf   8         \n",
      "3    7934     0.525    2508.15370v1.pdf   17        \n",
      "4    175      0.522    2508.15396v1.pdf   8         \n",
      "5    2307     0.518    2508.15252v1.pdf   7         \n",
      "6    4378     0.517    2508.15746v1.pdf   33        \n",
      "\n",
      "\n",
      "query = \" recommender systems \"\n",
      "\n",
      "Vector Search Results, for query: 'recommender systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2394     0.547    2508.15252v1.pdf   12        \n",
      "2    2393     0.508    2508.15252v1.pdf   12        \n",
      "3    3571     0.502    2508.15721v1.pdf   9         \n",
      "4    2203     0.491    2508.15252v1.pdf   1         \n",
      "5    2387     0.489    2508.15252v1.pdf   12        \n",
      "6    2395     0.487    2508.15252v1.pdf   12        \n",
      "\n",
      "\n",
      "query = \" Extracting Temporal Commonsense from Text \"\n",
      "\n",
      "Vector Search Results, for query: 'Extracting Temporal Commonsense from Text'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2710     0.723    2508.15274v1.pdf   4         \n",
      "2    2669     0.719    2508.15274v1.pdf   2         \n",
      "3    2668     0.712    2508.15274v1.pdf   2         \n",
      "4    2711     0.709    2508.15274v1.pdf   5         \n",
      "5    2654     0.683    2508.15274v1.pdf   1         \n",
      "6    2683     0.683    2508.15274v1.pdf   3         \n",
      "\n",
      "\n",
      "query = \" Ambiguity Categories and Benchmarks \"\n",
      "\n",
      "Vector Search Results, for query: 'Ambiguity Categories and Benchmarks'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    4472     0.546    2508.15276v1.pdf   5         \n",
      "2    4476     0.534    2508.15276v1.pdf   6         \n",
      "3    4412     0.528    2508.15276v1.pdf   1         \n",
      "4    4425     0.526    2508.15276v1.pdf   2         \n",
      "5    4435     0.526    2508.15276v1.pdf   3         \n",
      "6    4454     0.525    2508.15276v1.pdf   4         \n",
      "\n",
      "\n",
      "query = \" knowledge graph embedding \"\n",
      "\n",
      "Vector Search Results, for query: 'knowledge graph embedding'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1190     0.667    2508.15357v1.pdf   8         \n",
      "2    1202     0.660    2508.15357v1.pdf   8         \n",
      "3    1201     0.644    2508.15357v1.pdf   8         \n",
      "4    1203     0.641    2508.15357v1.pdf   9         \n",
      "5    1199     0.624    2508.15357v1.pdf   8         \n",
      "6    1191     0.619    2508.15357v1.pdf   8         \n",
      "\n",
      "\n",
      "query = \" Elastic Weight Consolidation algorithm \"\n",
      "\n",
      "Vector Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2643     0.519    2508.15294v1.pdf   8         \n",
      "2    2560     0.467    2508.15294v1.pdf   1         \n",
      "3    7995     0.464    2508.15757v1.pdf   4         \n",
      "4    2446     0.452    2508.15464v1.pdf   5         \n",
      "5    8019     0.436    2508.15757v1.pdf   6         \n",
      "6    8028     0.431    2508.15757v1.pdf   7         \n",
      "\n",
      "\n",
      "query = \" Multiple Memory Systems \"\n",
      "\n",
      "Vector Search Results, for query: 'Multiple Memory Systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2635     0.538    2508.15294v1.pdf   7         \n",
      "2    2586     0.532    2508.15294v1.pdf   3         \n",
      "3    2571     0.532    2508.15294v1.pdf   2         \n",
      "4    2581     0.531    2508.15294v1.pdf   3         \n",
      "5    2553     0.524    2508.15294v1.pdf   1         \n",
      "6    2580     0.514    2508.15294v1.pdf   2         \n",
      "\n",
      "\n",
      "query = \" Knowledge Graph Completion Models \"\n",
      "\n",
      "Vector Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1103     0.706    2508.15357v1.pdf   1         \n",
      "2    1206     0.631    2508.15357v1.pdf   9         \n",
      "3    1205     0.620    2508.15357v1.pdf   9         \n",
      "4    1194     0.611    2508.15357v1.pdf   8         \n",
      "5    1189     0.593    2508.15357v1.pdf   8         \n",
      "6    1197     0.592    2508.15357v1.pdf   8         \n",
      "\n",
      "\n",
      "query = \" Speculative decoding \"\n",
      "\n",
      "Vector Search Results, for query: 'Speculative decoding'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    3075     0.696    2508.15371v1.pdf   6         \n",
      "2    3006     0.653    2508.15371v1.pdf   2         \n",
      "3    3125     0.647    2508.15371v1.pdf   9         \n",
      "4    2980     0.623    2508.15371v1.pdf   1         \n",
      "5    2989     0.613    2508.15371v1.pdf   1         \n",
      "6    2991     0.606    2508.15371v1.pdf   1         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from hybrid_search import connect_to_database, load_documents_and_faiss_index, sqlite_keyword_search, faiss_search, hybrid_search\n",
    "import pprint\n",
    "\n",
    "# Define a list of queries\n",
    "queries = [\n",
    "    \"Normative LLMs Profiling\",\n",
    "    \"semantic similarity\",\n",
    "    \"recommender systems\",\n",
    "    \"Extracting Temporal Commonsense from Text\",\n",
    "    \"Ambiguity Categories and Benchmarks\",\n",
    "    \"knowledge graph embedding\",\n",
    "    \"Elastic Weight Consolidation algorithm\",\n",
    "    \"Multiple Memory Systems\",\n",
    "    \"Knowledge Graph Completion Models\",\n",
    "    \"Speculative decoding\"\n",
    "]\n",
    "\n",
    "load_documents_and_faiss_index()\n",
    "\n",
    "for query in queries:\n",
    "    print(\"query = \\\"\", query, \"\\\"\")\n",
    "    result = faiss_search(query, 6, verbose=True)\n",
    "    print(\"\\n\")\n",
    "    # pprint.pprint(result, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05058930",
   "metadata": {},
   "source": [
    "3) To perform keywork search using Sqlite3 FTS for the queries, ran the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d2452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened the database\n",
      "\n",
      "Keyword Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1682     0.724      2508.15250v1.pdf   1         \n",
      "2    1674     0.673      2508.15250v1.pdf   1         \n",
      "3    1675     0.156      2508.15250v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'semantic similarity'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2703     0.577      2508.15274v1.pdf   4         \n",
      "2    187      0.504      2508.15396v1.pdf   9         \n",
      "3    2460     0.494      2508.15464v1.pdf   6         \n",
      "4    7177     0.494      2508.15658v1.pdf   7         \n",
      "5    759      0.465      2508.15392v1.pdf   14        \n",
      "6    2459     0.465      2508.15464v1.pdf   6         \n",
      "\n",
      "Keyword Search Results, for query: 'recommender systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    7297     0.608      2508.15658v1.pdf   19        \n",
      "2    2337     0.488      2508.15252v1.pdf   9         \n",
      "3    7303     0.488      2508.15658v1.pdf   19        \n",
      "4    2395     0.478      2508.15252v1.pdf   12        \n",
      "5    2401     0.468      2508.15252v1.pdf   13        \n",
      "6    2402     0.468      2508.15252v1.pdf   13        \n",
      "\n",
      "Keyword Search Results, for query: 'Extracting Temporal Commonsense from Text'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2656     0.965      2508.15274v1.pdf   1         \n",
      "2    2683     0.932      2508.15274v1.pdf   3         \n",
      "3    2652     0.822      2508.15274v1.pdf   1         \n",
      "4    2663     0.544      2508.15274v1.pdf   1         \n",
      "5    2711     0.041      2508.15274v1.pdf   5         \n",
      "6    2668     0.011      2508.15274v1.pdf   2         \n",
      "\n",
      "Keyword Search Results, for query: 'Ambiguity Categories and Benchmarks'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    4416     0.500      2508.15276v1.pdf   2         \n",
      "\n",
      "Keyword Search Results, for query: 'knowledge graph embedding'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1195     0.631      2508.15357v1.pdf   8         \n",
      "2    3590     0.631      2508.15721v1.pdf   11        \n",
      "3    3589     0.581      2508.15721v1.pdf   11        \n",
      "4    1121     0.471      2508.15357v1.pdf   2         \n",
      "5    1192     0.350      2508.15357v1.pdf   8         \n",
      "6    1197     0.339      2508.15357v1.pdf   8         \n",
      "\n",
      "Keyword Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "\n",
      "Keyword Search Results, for query: 'Multiple Memory Systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2552     0.870      2508.15294v1.pdf   1         \n",
      "2    2570     0.693      2508.15294v1.pdf   2         \n",
      "3    2583     0.590      2508.15294v1.pdf   3         \n",
      "4    2571     0.263      2508.15294v1.pdf   2         \n",
      "5    2568     0.114      2508.15294v1.pdf   2         \n",
      "\n",
      "Keyword Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1184     0.784      2508.15357v1.pdf   7         \n",
      "2    1197     0.732      2508.15357v1.pdf   8         \n",
      "3    1103     0.092      2508.15357v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'Speculative decoding'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    3110     0.687      2508.15371v1.pdf   9         \n",
      "2    3033     0.500      2508.15371v1.pdf   4         \n",
      "3    3056     0.490      2508.15371v1.pdf   5         \n",
      "4    3063     0.449      2508.15371v1.pdf   5         \n",
      "5    3080     0.438      2508.15371v1.pdf   7         \n",
      "6    3036     0.428      2508.15371v1.pdf   4         \n"
     ]
    }
   ],
   "source": [
    "connect_to_database()\n",
    "\n",
    "for query in queries:\n",
    "    result = sqlite_keyword_search(query, 6, verbose=True)\n",
    "    # pprint.pprint(result, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea8bf1",
   "metadata": {},
   "source": [
    "4) Execute hybrid search (vector + keyword) for the queries, apply the weight-summary merge logic and get the top 3 matches.\n",
    "\n",
    "The search results show that the hrbrid method yields more accurate results over using vector or keyword method alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87980fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Search Results for query: 'Normative LLMs Profiling'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1682   0.621    0.553    0.724    2508.15250v1.p     1         \n",
      "2    5434   0.339    0.565    0.000    2508.15361v1.p     25        \n",
      "3    5542   0.326    0.543    0.000    2508.15361v1.p     34        \n",
      "\n",
      "[{'doc_idx': 1682,\n",
      "  'filename': '2508.15250v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 't measurements often focus solely on eth-\\n'\n",
      "             'ical judgments, without considering how factors\\n'\n",
      "             'like professional background, language environ-\\n'\n",
      "             'ment (Changjiang et al., 2024), and model param-\\n'\n",
      "             'eters (Achiam et al., 2023) interact. To fill this gap,\\n'\n",
      "             'we propose the EMNLP (Educator-role Moral and\\n'\n",
      "             'Normative LLMs Profiling) framework for compre-\\n'\n",
      "             'hensive testing and analysis of LLMs’ personality\\n'\n",
      "             'traits and ethical risks in educational contexts.\\n'\n",
      "             'Our EMNLP framework conducts a moral and\\n'\n",
      "             'ethical evaluation of LLMs in the ',\n",
      "  'combined_score': 0.6210238823608489,\n",
      "  'vector_score': 0.5525643229484558,\n",
      "  'keyword_score': 0.7237132214794385},\n",
      " {'doc_idx': 5434,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 25,\n",
      "  'content': ' outputs, adversarial susceptibility, and\\n'\n",
      "             'privacy violations are no longer theoretical, they have tangible '\n",
      "             'consequences for users, organizations,\\n'\n",
      "             'and society at large.\\n'\n",
      "             'Consequently, Risk & Reliability assessment has evolved into a '\n",
      "             'central pillar of modern LLM\\n'\n",
      "             'benchmarking frameworks, rather than a peripheral addition. Its '\n",
      "             'core motivations are:\\n'\n",
      "             '1. Identification and Quantification: To systematically probe '\n",
      "             'LLMs for various negative impact\\n'\n",
      "             'patterns (e.g., generating harmful content[317], hallucinating '\n",
      "             'facts[31',\n",
      "  'combined_score': 0.33929035663604734,\n",
      "  'vector_score': 0.5654839277267456,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5542,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 34,\n",
      "  'content': 'ssessments risk over-specialization;\\n'\n",
      "             'and target-specific metrics struggle to balance technical rigor '\n",
      "             'with real-world relevance. These\\n'\n",
      "             'challenges intensify as LLMs operate in dynamic, multi-agent, '\n",
      "             'high-stakes environments, where\\n'\n",
      "             'static datasets and single-turn metrics fail to capture emergent '\n",
      "             'behaviors or societal impacts. As\\n'\n",
      "             'LLMs integrate into sociotechnical systems, evaluation must '\n",
      "             'shift from measuring \"what models can\\n'\n",
      "             'do\" to \"how they should perform responsibly.\" Future benchmarks '\n",
      "             'require dynamism (to ma',\n",
      "  'combined_score': 0.3256558656692505,\n",
      "  'vector_score': 0.5427597761154175,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'semantic similarity'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    319    0.361    0.602    0.000    2508.15396v1.p     22        \n",
      "2    5212   0.327    0.544    0.000    2508.15361v1.p     8         \n",
      "3    7934   0.315    0.525    0.000    2508.15370v1.p     17        \n",
      "\n",
      "[{'doc_idx': 319,\n",
      "  'filename': '2508.15396v1.pdf',\n",
      "  'page': 22,\n",
      "  'content': 'emantic similarity-based (SB).',\n",
      "  'combined_score': 0.3611157417297363,\n",
      "  'vector_score': 0.6018595695495605,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5212,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'With the rise of generative models, metrics based on n-gram '\n",
      "             'overlap like BLEU [48] and ROUGE\\n'\n",
      "             '[47] proved inadequate, as they fail to capture semantic '\n",
      "             'equivalence. The field responded with a\\n'\n",
      "             'new class of semantic-aware metrics. BERTScore [42] leveraged '\n",
      "             'contextual embeddings to measure\\n'\n",
      "             'semantic similarity, while BLEURT [44] trained a regression '\n",
      "             'model on 6.5M synthetically perturbed\\n'\n",
      "             'sentence pairs to better align with human judgments of quality. '\n",
      "             'Bartscore [43] reframed evaluation\\n'\n",
      "             'as a conditional language mode',\n",
      "  'combined_score': 0.3265631675720215,\n",
      "  'vector_score': 0.5442719459533691,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7934,\n",
      "  'filename': '2508.15370v1.pdf',\n",
      "  'page': 17,\n",
      "  'content': 'iu, Qi Qian,\\n'\n",
      "             'Ji Zhang, Fei Huang, and Jingren Zhou. mplug-owl2: '\n",
      "             'Revolutionizing\\n'\n",
      "             'multi-modal large language model with modality collaboration. '\n",
      "             'arXiv\\n'\n",
      "             'preprint arXiv:2311.04257, 2023.\\n'\n",
      "             '[85] Peter Young, Alice Lai, Micah Hodosh, and Julia '\n",
      "             'Hockenmaier. From\\n'\n",
      "             'image descriptions to visual denotations: New similarity metrics '\n",
      "             'for\\n'\n",
      "             'semantic inference over event descriptions. Transactions of the '\n",
      "             'Asso-\\n'\n",
      "             'ciation for Computational Linguistics, 2:67–78, 2014.\\n'\n",
      "             '[86] Tianyu Yu, Yuan Yao, Haoye Zhang, Taiwen He, Yifeng Han, '\n",
      "             'Ganqu',\n",
      "  'combined_score': 0.31519768238067625,\n",
      "  'vector_score': 0.5253294706344604,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'recommender systems'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2395   0.483    0.487    0.478    2508.15252v1.p     12        \n",
      "2    2394   0.328    0.547    0.000    2508.15252v1.p     12        \n",
      "3    2393   0.305    0.508    0.000    2508.15252v1.p     12        \n",
      "\n",
      "[{'doc_idx': 2395,\n",
      "  'filename': '2508.15252v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'k, and C. Williams, “Toward trustwor-\\n'\n",
      "             'thy recommender systems: An analysis of attack models and '\n",
      "             'algorithm\\n'\n",
      "             'robustness,” TOIT, 2007.\\n'\n",
      "             '[35] X. He, L. Liao, H. Zhang, L. Nie, X. Hu, and T.-S. Chua, '\n",
      "             '“Neural\\n'\n",
      "             'collaborative filtering,” in WWW, 2017.\\n'\n",
      "             '[36] X. He, K. Deng, X. Wang, Y. Li, Y. Zhang, and M. Wang, '\n",
      "             '“Lightgcn:\\n'\n",
      "             'Simplifying and powering graph convolution network for '\n",
      "             'recommenda-\\n'\n",
      "             'tion,” in SIGIR, 2020.\\n'\n",
      "             '[37] Z. Xu, H. Zeng, and Q. Ai, “Understanding the effectiveness '\n",
      "             'of reviews\\n'\n",
      "             'in e-commerce top-n recommendation',\n",
      "  'combined_score': 0.4831403267907714,\n",
      "  'vector_score': 0.48654285073280334,\n",
      "  'keyword_score': 0.4780365408777234},\n",
      " {'doc_idx': 2394,\n",
      "  'filename': '2508.15252v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'ed collaborative\\n'\n",
      "             'filtering,” in SIGKDD Workshop.\\n'\n",
      "             'sn, 2007, pp. 7–14.\\n'\n",
      "             '[32] C.-H. Lee, Y.-H. Kim, and P.-K. Rhee, “Web personalization '\n",
      "             'expert with\\n'\n",
      "             'combining collaborative filtering and association rule mining '\n",
      "             'technique,”\\n'\n",
      "             'Expert Systems with Applications, 2001.\\n'\n",
      "             '[33] Y. Koren, R. Bell, and C. Volinsky, “Matrix factorization '\n",
      "             'techniques for\\n'\n",
      "             'recommender systems,” Computer, 2009.\\n'\n",
      "             '[34] B. Mobasher, R. Burke, R. Bhaumik, and C. Williams, “Toward '\n",
      "             'trustwor-\\n'\n",
      "             'thy recommender systems: An analysis of attack models and algo',\n",
      "  'combined_score': 0.32818386554718015,\n",
      "  'vector_score': 0.5469731092453003,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2393,\n",
      "  'filename': '2508.15252v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'arXiv:2401.11624, 2024.\\n'\n",
      "             '[29] Z. Zhao, W. Fan, J. Li, Y. Liu, X. Mei, Y. Wang, Z. Wen, F. '\n",
      "             'Wang,\\n'\n",
      "             'X. Zhao, J. Tang et al., “Recommender systems in the era of '\n",
      "             'large\\n'\n",
      "             'language models (llms),” TKDE, 2024.\\n'\n",
      "             '[30] Z. Wang, M. Gao, J. Yu, H. Ma, H. Yin, and S. Sadiq, '\n",
      "             '“Poison-\\n'\n",
      "             'ing attacks against recommender systems: A survey,” arXiv '\n",
      "             'preprint\\n'\n",
      "             'arXiv:2401.01527, 2024.\\n'\n",
      "             '[31] R. M. Bell and Y. Koren, “Improved neighborhood-based '\n",
      "             'collaborative\\n'\n",
      "             'filtering,” in SIGKDD Workshop.\\n'\n",
      "             'sn, 2007, pp. 7–14.\\n'\n",
      "             '[32] C.-H. Lee, Y.-H. Kim, and ',\n",
      "  'combined_score': 0.3046918988227844,\n",
      "  'vector_score': 0.5078198313713074,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Extracting Temporal Commonsense from Text'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2683   0.782    0.683    0.932    2508.15274v1.p     3         \n",
      "2    2711   0.441    0.709    0.041    2508.15274v1.p     5         \n",
      "3    2710   0.434    0.723    0.000    2508.15274v1.p     4         \n",
      "\n",
      "[{'doc_idx': 2683,\n",
      "  'filename': '2508.15274v1.pdf',\n",
      "  'page': 3,\n",
      "  'content': 'TComQA: Extracting Temporal Commonsense from Text\\n'\n",
      "             'IR-RAG@SIGIR’25, July 13–17, 2025, Padua, Italy\\n'\n",
      "             'Short \\n'\n",
      "             'Context\\n'\n",
      "             'Temporal \\n'\n",
      "             'Property\\n'\n",
      "             'Validity \\n'\n",
      "             'Checker\\n'\n",
      "             'Question Q\\n'\n",
      "             'Valid Q\\n'\n",
      "             'Answer A\\n'\n",
      "             'Short \\n'\n",
      "             'Context\\n'\n",
      "             'Answer A\\n'\n",
      "             'Figure 1: Overview of extraction of TComQA\\n'\n",
      "             'To create TComQA Dataset, we consider the SAMsum dataset [5],\\n'\n",
      "             'a chat summarization dataset of 14K contexts with an average\\n'\n",
      "             'of 20.6 tokens per context, and the RealNews dataset [25] of 5K\\n'\n",
      "             'contexts with an average of 31.22 tokens per context.\\n'\n",
      "             '3.2\\n'\n",
      "             'Experimental setup\\n'\n",
      "             '3.2',\n",
      "  'combined_score': 0.7824288392461805,\n",
      "  'vector_score': 0.6829695701599121,\n",
      "  'keyword_score': 0.9316177428755827},\n",
      " {'doc_idx': 2711,\n",
      "  'filename': '2508.15274v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'TComQA: Extracting Temporal Commonsense from Text\\n'\n",
      "             'IR-RAG@SIGIR’25, July 13–17, 2025, Padua, Italy\\n'\n",
      "             'commonsense QA dataset, TcomQA, from two distinct real-world\\n'\n",
      "             'datasets. Our approach eliminates the dependency on manual '\n",
      "             'anno-\\n'\n",
      "             'tation, enabling large-scale, consistent, and efficient '\n",
      "             'generation of\\n'\n",
      "             'temporal Automatically generated TComQA dataset overcomes the\\n'\n",
      "             'scaling issue in commonsense dataset generation. The evaluation\\n'\n",
      "             'of TcomQA demonstrated that our extraction pipeline '\n",
      "             'successfully\\n'\n",
      "             'captures temporal commonsen',\n",
      "  'combined_score': 0.4413794848147215,\n",
      "  'vector_score': 0.7085244655609131,\n",
      "  'keyword_score': 0.04066201369543413},\n",
      " {'doc_idx': 2710,\n",
      "  'filename': '2508.15274v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': '\\n'\n",
      "             'the power of LLMs with the prompts about temporal property.\\n'\n",
      "             '5\\n'\n",
      "             'CONCLUSION\\n'\n",
      "             'We developed a temporal commonsense extraction pipeline using\\n'\n",
      "             'different large language models (LLMs). The framework '\n",
      "             'identifies\\n'\n",
      "             'the temporal event and provides appropriate questions for a '\n",
      "             'tem-\\n'\n",
      "             'poral property along with along with the plausible answers for\\n'\n",
      "             'the temporal event. With this framework, we created temporal',\n",
      "  'combined_score': 0.43362175226211547,\n",
      "  'vector_score': 0.7227029204368591,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Ambiguity Categories and Benchmarks'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    4472   0.327    0.546    0.000    2508.15276v1.p     5         \n",
      "2    4476   0.320    0.534    0.000    2508.15276v1.p     6         \n",
      "3    4412   0.317    0.528    0.000    2508.15276v1.p     1         \n",
      "\n",
      "[{'doc_idx': 4472,\n",
      "  'filename': '2508.15276v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'ghtforward ambiguous queries.\\n'\n",
      "             'Ambiguity Detection Performance. We further report the\\n'\n",
      "             'ambiguity detection and classification accuracy of AmbiSQL. As '\n",
      "             'pre-\\n'\n",
      "             'sented in Table 2, AmbiSQL achieves an overall precision of '\n",
      "             '87.2%,\\n'\n",
      "             'recall of 89.1%, and an F1-score of 88.2%, indicating the '\n",
      "             'effectiveness\\n'\n",
      "             'of ambiguity detection of AmbiSQL based on our taxonomy.\\n'\n",
      "             'Further evaluation across different ambiguity dimensions '\n",
      "             'reveals\\n'\n",
      "             'that, for the DB-related ambiguity, the model achieves higher '\n",
      "             'recall\\n'\n",
      "             'but comparatively lower preci',\n",
      "  'combined_score': 0.3274715423583984,\n",
      "  'vector_score': 0.5457859039306641,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 4476,\n",
      "  'filename': '2508.15276v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'ent reasoning context\\n'\n",
      "             '66.7%\\n'\n",
      "             '100.0%\\n'\n",
      "             '80.0%\\n'\n",
      "             'Conflicting knowledge\\n'\n",
      "             '100.0%\\n'\n",
      "             '100.0%\\n'\n",
      "             '100.0%\\n'\n",
      "             'Ambiguous temporal/spatial scope\\n'\n",
      "             '100.0%\\n'\n",
      "             '81.8%\\n'\n",
      "             '90.0%\\n'\n",
      "             'Among subcategories, \"unclear schema reference\" emerges as\\n'\n",
      "             'the most prevalent across the dataset. Our analysis reveals '\n",
      "             'that\\n'\n",
      "             'errors caused by this kind of ambiguity mainly stem from vague '\n",
      "             'or\\n'\n",
      "             'incomplete descriptions in the database metadata. Notably, some\\n'\n",
      "             'subcategories achieve perfect coverage (F1-score = 100%), '\n",
      "             'indicating\\n'\n",
      "             'that the ambiguity taxonomy has been effectively inte',\n",
      "  'combined_score': 0.32034727334976193,\n",
      "  'vector_score': 0.5339121222496033,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 4412,\n",
      "  'filename': '2508.15276v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'emporal interpretation of \"end of the Vietnam War\" in\\n'\n",
      "             'our previous example.\\n'\n",
      "             '(2) Efficiency and Generalization Concerns. Several studies [8, '\n",
      "             '17]\\n'\n",
      "             'resolve ambiguity by generating extensive candidate '\n",
      "             'interpretations\\n'\n",
      "             '(e.g., alternative SQLs), the majority of which prove irrelevant '\n",
      "             'to the\\n'\n",
      "             'actual user intent. This approach incurs significant '\n",
      "             'computational\\n'\n",
      "             'overhead and limits practical scalability. Additionally, '\n",
      "             'methods\\n'\n",
      "             'relying on pre-trained ambiguity detection models [4, 17] '\n",
      "             'require\\n'\n",
      "             'extensive annotated datasets a',\n",
      "  'combined_score': 0.3167710304260254,\n",
      "  'vector_score': 0.527951717376709,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'knowledge graph embedding'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1190   0.400    0.667    0.000    2508.15357v1.p     8         \n",
      "2    1202   0.396    0.660    0.000    2508.15357v1.p     8         \n",
      "3    1201   0.386    0.644    0.000    2508.15357v1.p     8         \n",
      "\n",
      "[{'doc_idx': 1190,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': '.; and Taylor,\\n'\n",
      "             'J. 2008. Freebase: A collaboratively created graph database\\n'\n",
      "             'for structuring human knowledge. In Proc. of ACM SIG-\\n'\n",
      "             'MOD, 1247–1250.\\n'\n",
      "             'Bordes, A.; Usunier, N.; Garcia-Duran, A.; Weston, J.; and\\n'\n",
      "             'Yakhnenko, O. 2013. Translating embeddings for modeling\\n'\n",
      "             'multi-relational data. Advances in neural information pro-\\n'\n",
      "             'cessing systems, 26.\\n'\n",
      "             'Dettmers, T.; Minervini, P.; Stenetorp, P.; and Riedel, S.\\n'\n",
      "             '2018. Convolutional 2D knowledge graph embeddings. In\\n'\n",
      "             'Proc. of AAAI.\\n'\n",
      "             'Devlin, J.; Chang, M.-W.; Lee, K.; and Touta',\n",
      "  'combined_score': 0.4000117778778076,\n",
      "  'vector_score': 0.6666862964630127,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1202,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 't, S.; and Gemulla, R. 2020. You can\\n'\n",
      "             'teach an old dog new tricks! on training knowledge graph\\n'\n",
      "             'embeddings.\\n'\n",
      "             'Shu, D.; Chen, T.; Jin, M.; Zhang, C.; Du, M.; and Zhang,\\n'\n",
      "             'Y. 2024. Knowledge Graph Large Language Model (KG-\\n'\n",
      "             'LLM) for Link Prediction:(ACML).\\n'\n",
      "             'Proceedings of Ma-\\n'\n",
      "             'chine Learning Research, 260(1): 143.',\n",
      "  'combined_score': 0.3958444118499756,\n",
      "  'vector_score': 0.659740686416626,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1201,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'glish.\\n'\n",
      "             'Communications of the ACM, 38(11).\\n'\n",
      "             'Rossi, A.; Barbosa, D.; Firmani, D.; Matinata, A.; and Meri-\\n'\n",
      "             'aldo, P. 2021a. Knowledge graph embedding for link pre-\\n'\n",
      "             'diction: A comparative analysis. TKDD.\\n'\n",
      "             'Rossi, A.; Barbosa, D.; Firmani, D.; Matinata, A.; and Meri-\\n'\n",
      "             'aldo, P. 2021b. Knowledge Graph Embedding for Link Pre-\\n'\n",
      "             'diction: A Comparative Analysis. ACM Trans. Knowl. Dis-\\n'\n",
      "             'cov. Data, 15(2).\\n'\n",
      "             'Rufﬁnelli, D.; Broscheit, S.; and Gemulla, R. 2020. You can\\n'\n",
      "             'teach an old dog new tricks! on training knowledge graph\\n'\n",
      "             'embedd',\n",
      "  'combined_score': 0.3861005902290344,\n",
      "  'vector_score': 0.6435009837150574,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Elastic Weight Consolidation algorithm'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2643   0.311    0.519    0.000    2508.15294v1.p     8         \n",
      "2    2560   0.280    0.467    0.000    2508.15294v1.p     1         \n",
      "3    7995   0.278    0.464    0.000    2508.15757v1.p     4         \n",
      "\n",
      "[{'doc_idx': 2643,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'olidation in llm-based agents.\\n'\n",
      "             'In Ex-\\n'\n",
      "             'tended Abstracts of the CHI Conference on Human Factors\\n'\n",
      "             'in Computing Systems, 1–7.\\n'\n",
      "             'Hu, C.; Fu, J.; Du, C.; Luo, S.; Zhao, J.; and Zhao, H. 2023.\\n'\n",
      "             'Chatdb: Augmenting llms with databases as their symbolic\\n'\n",
      "             'memory. arXiv preprint arXiv:2306.03901.\\n'\n",
      "             'Husz´ar, F. 2018. Note on the quadratic penalties in elastic\\n'\n",
      "             'weight consolidation. Proceedings of the National Academy\\n'\n",
      "             'of Sciences, 115(11): E2496–E2497.\\n'\n",
      "             'Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii, '\n",
      "             'E.;\\n'\n",
      "             'Bang, Y. J.;',\n",
      "  'combined_score': 0.31127192974090573,\n",
      "  'vector_score': 0.5187865495681763,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2560,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ametrically, by\\n'\n",
      "             'augmenting LLMs with additional parameters, knowledge\\n'\n",
      "             'can be retained for future use (Wang et al. 2023). The Elas-\\n'\n",
      "             'tic Weight Consolidation algorithm (Husz´ar 2018) , devel-\\n'\n",
      "             'oped through collaboration between DeepMind and Imperial\\n'\n",
      "             'College London, enables neural networks to retain knowl-\\n'\n",
      "             'edge from previous tasks while learning new ones, miti-\\n'\n",
      "             'gating the ”catastrophic forgetting” problem and marking\\n'\n",
      "             'a significant step towards continuous learning in AI. How-\\n'\n",
      "             'ever, parametric memory is prone to ',\n",
      "  'combined_score': 0.28005189299583433,\n",
      "  'vector_score': 0.46675315499305725,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7995,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': ' optimization',\n",
      "  'combined_score': 0.2783568441867828,\n",
      "  'vector_score': 0.46392807364463806,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Multiple Memory Systems'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2571   0.424    0.532    0.263    2508.15294v1.p     2         \n",
      "2    2552   0.348    0.000    0.870    2508.15294v1.p     1         \n",
      "3    2635   0.323    0.538    0.000    2508.15294v1.p     7         \n",
      "\n",
      "[{'doc_idx': 2571,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'logy\\n'\n",
      "             'The theory of multiple memory systems (Tulving 1985)\\n'\n",
      "             'posits that memory is not processed by a single system, but\\n'\n",
      "             'rather consists of multiple subsystems that are functionally\\n'\n",
      "             'independent and have different structural foundations. These\\n'\n",
      "             'systems are responsible for different types of information\\n'\n",
      "             'processing and storage, with specific neural bases and be-\\n'\n",
      "             'havioral characteristics. Endel Tulving (Tulving et al. 1972)\\n'\n",
      "             'proposed a three-category classification model in 1985, in-\\n'\n",
      "             'cluding: Procedural Memory: invo',\n",
      "  'combined_score': 0.4242785113346009,\n",
      "  'vector_score': 0.5317948460578918,\n",
      "  'keyword_score': 0.26300400924966444},\n",
      " {'doc_idx': 2552,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'Multiple Memory Systems for Enhancing the Long-term Memory of '\n",
      "             'Agent\\n'\n",
      "             'Gaoke Zhang1, Bo Wang1*, Yunlong Ma1, Dongming Zhao2, Zifei Yu3\\n'\n",
      "             '1College of Intelligence and Computing, Tianjin University\\n'\n",
      "             '2AI Lab, China Mobile Communication Group Tianjin Co., Ltd\\n'\n",
      "             '3Huizhi Xingyuan Information Technology Co., Ltd\\n'\n",
      "             '{zhanggaoke, bo wang}@tju.edu.cn\\n'\n",
      "             'Abstract\\n'\n",
      "             'An agent powered by large language models have achieved\\n'\n",
      "             'impressive results, but effectively handling the vast amounts\\n'\n",
      "             'of historical data generated during interactions rema',\n",
      "  'combined_score': 0.34811350845779776,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.8702837711444943},\n",
      " {'doc_idx': 2635,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 7,\n",
      "  'content': 'nd of\\n'\n",
      "             'low quality, resulting in poor performance. Conversely, our\\n'\n",
      "             'method generates a larger volume of high-quality memory\\n'\n",
      "             'content despite the increased overhead, with only a mini-\\n'\n",
      "             'mal latency increase that barely affects user experience. Our\\n'\n",
      "             'method holds practical value.\\n'\n",
      "             'Conclusion\\n'\n",
      "             'This paper creates a multi-memory system by integrat-\\n'\n",
      "             'ing with cognitive psychology to build effective long-term\\n'\n",
      "             'memory, boosting recall and generation quality. Multiple\\n'\n",
      "             'memory theory suggests human memory comes in many\\n'\n",
      "             'forms. Cu',\n",
      "  'combined_score': 0.3225078463554382,\n",
      "  'vector_score': 0.5375130772590637,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Knowledge Graph Completion Models'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1197   0.648    0.592    0.732    2508.15357v1.p     8         \n",
      "2    1103   0.460    0.706    0.092    2508.15357v1.p     1         \n",
      "3    1206   0.379    0.631    0.000    2508.15357v1.p     9         \n",
      "\n",
      "[{'doc_idx': 1197,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'emi, S. M.; and Poole, D. 2018. Simple Embedding for\\n'\n",
      "             'Link Prediction in Knowledge Graphs. In Advances in Neu-\\n'\n",
      "             'ral Information Processing Systems, volume 31.\\n'\n",
      "             'Kim, B.; Hong, T.; Ko, Y.; and Seo, J. 2020.\\n'\n",
      "             'Multi-\\n'\n",
      "             'Task Learning for Knowledge Graph Completion with Pre-\\n'\n",
      "             'trained Language Models. In Scott, D.; Bel, N.; and Zong,\\n'\n",
      "             'C., eds., Proceedings of the 28th International Conference\\n'\n",
      "             'on Computational Linguistics, 1737–1743.Barcelona, Spain\\n'\n",
      "             '(Online): International Committee on Computational Lin-\\n'\n",
      "             'guistics.\\n'\n",
      "             'Lin, X.;',\n",
      "  'combined_score': 0.6480273692011436,\n",
      "  'vector_score': 0.5918718576431274,\n",
      "  'keyword_score': 0.7322606365381678},\n",
      " {'doc_idx': 1103,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph\\n'\n",
      "             'Completion Models\\n'\n",
      "             'Haji Gul1, Abul Ghani Naim1, Ajaz Ahmad Bhat1 ∗\\n'\n",
      "             '1School of Digital Science, Universiti Brunei Darussalam\\n'\n",
      "             '(23h1710, ghani.naim, ajaz.bhat∗)@ubd.edu.bn\\n'\n",
      "             'Abstract\\n'\n",
      "             'Knowledge Graphs (KGs) enable applications in various do-\\n'\n",
      "             'mains such as semantic search, recommendation systems,\\n'\n",
      "             'and natural language processing. KGs are often incomplete,\\n'\n",
      "             'missing entities and relations, an issue addressed by Knowl-\\n'\n",
      "             'edge Graph Completion (KGC) methods th',\n",
      "  'combined_score': 0.46009505576096776,\n",
      "  'vector_score': 0.7056922316551208,\n",
      "  'keyword_score': 0.09169929191973826},\n",
      " {'doc_idx': 1206,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ', J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In Bouamor, H.; Pino, J.;\\n'\n",
      "             'and Bali, K., eds., Findings of the Association for Compu-\\n'\n",
      "             'tational Linguistics: EMNLP 2023, 8667–8683. Singapore:\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2015.\\n'\n",
      "             'Embedding entities and relations for learning and inference\\n'\n",
      "             'in knowledge bases. arXiv preprint arXiv:1412.6575.\\n'\n",
      "             'Zhang, W.; Paudel, B.; Zhang, W.; Bernstein, A.; and Chen,\\n'\n",
      "             'H',\n",
      "  'combined_score': 0.37882543802261354,\n",
      "  'vector_score': 0.6313757300376892,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Speculative decoding'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    3075   0.418    0.696    0.000    2508.15371v1.p     6         \n",
      "2    3006   0.392    0.653    0.000    2508.15371v1.p     2         \n",
      "3    3125   0.388    0.647    0.000    2508.15371v1.p     9         \n",
      "\n",
      "[{'doc_idx': 3075,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'fidence-\\n'\n",
      "             'Modulated Adaptive Speculative Decoding (CM-ASD) framework',\n",
      "  'combined_score': 0.4176655411720276,\n",
      "  'vector_score': 0.6961092352867126,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 3006,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': ' speculative \\n'\n",
      "             'decoding as a heuristic acceleration technique and a \\n'\n",
      "             'principled, learning-informed system guided by model \\n'\n",
      "             'introspection. By enabling the decoder to reason about its own \\n'\n",
      "             'confidence during inference, the proposed framework \\n'\n",
      "             'introduces a level of adaptivity that has been largely absent '\n",
      "             'in \\n'\n",
      "             'prior decoding strategies. The result is a system that not '\n",
      "             'only \\n'\n",
      "             'accelerates inference substantially but does so in a more \\n'\n",
      "             'intelligent and context-aware manner. \\n'\n",
      "             'The remainder of the paper is organized as f',\n",
      "  'combined_score': 0.3915829539299011,\n",
      "  'vector_score': 0.6526382565498352,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 3125,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ' language model decoding with speculative \\n'\n",
      "             'sampling,” arXiv:2302.01318 [cs.CL], 2023.',\n",
      "  'combined_score': 0.38842320442199707,\n",
      "  'vector_score': 0.6473720073699951,\n",
      "  'keyword_score': 0.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    result = hybrid_search(query, 3)\n",
    "    print('\\r')\n",
    "    pprint.pprint(result, sort_dicts=False)\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93edeb",
   "metadata": {},
   "source": [
    "5) A FastAPI endpoint \"/hybrid-search\" has been implemented in hybrid_search.py. To test its API, run the following code and then test the API in a browser at 127.0.0.1/8000:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a88811fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/home/ehan/evanhan_homework/evanhan_homework/class5']\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m1705942\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m1706006\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "FAISS index and documents files loaded\n",
      "Successfully opened the database\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:57564 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:57564 - \"\u001b[1mGET /favicon.ico HTTP/1.1\u001b[0m\" \u001b[31m404 Not Found\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:57580 - \"\u001b[1mGET /docs HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:57580 - \"\u001b[1mGET /openapi.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     127.0.0.1:58076 - \"\u001b[1mPOST /hybrid-search/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m1706006\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m1705942\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "! python3 hybrid_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa2f0a",
   "metadata": {},
   "source": [
    "Note: The PDF files processed in this assignment had been downloaded in the last assignment by the get_latest_arxiv() function in documents_downloading.py. To perform this task again:\n",
    "\n",
    "from documents_downloading import get_latest_arxiv\n",
    "get_latest_arxiv(query=\"cat:cs.CL\", max_results=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8959c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_class4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
