{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88facc79",
   "metadata": {},
   "source": [
    "# Assignment for week 5 - Hybrid Search evaluation notebook\n",
    "\n",
    "This notebook presents the steps for evaluating the code of vector-only, keyword-only, and hybrid (Weighted summary) search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28344524",
   "metadata": {},
   "source": [
    "### *) To install necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6386709d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fitz in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 1)) (0.0.1.dev2)\n",
      "Requirement already satisfied: langchain_core in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 2)) (0.3.74)\n",
      "Requirement already satisfied: sentence_transformers in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 3)) (5.1.0)\n",
      "Requirement already satisfied: fastapi in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 4)) (0.116.1)\n",
      "Requirement already satisfied: pydantic in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 5)) (2.11.7)\n",
      "Requirement already satisfied: uvicorn in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from -r ./src/requirements.txt (line 6)) (0.35.0)\n",
      "Requirement already satisfied: configobj in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (5.0.9)\n",
      "Requirement already satisfied: configparser in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (0.30.0)\n",
      "Requirement already satisfied: nibabel in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (5.3.2)\n",
      "Requirement already satisfied: nipype in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.10.0)\n",
      "Requirement already satisfied: numpy in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (2.3.2)\n",
      "Requirement already satisfied: pandas in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (2.3.1)\n",
      "Requirement already satisfied: pyxnat in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: scipy in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fitz->-r ./src/requirements.txt (line 1)) (1.16.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langchain_core->-r ./src/requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (4.55.2)\n",
      "Requirement already satisfied: tqdm in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sentence_transformers->-r ./src/requirements.txt (line 3)) (11.3.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from fastapi->-r ./src/requirements.txt (line 4)) (0.47.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pydantic->-r ./src/requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from uvicorn->-r ./src/requirements.txt (line 6)) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from uvicorn->-r ./src/requirements.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: filelock in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2025.7.0)\n",
      "Requirement already satisfied: requests in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.1.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain_core->-r ./src/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (0.24.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (4.10.0)\n",
      "Requirement already satisfied: setuptools in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httplib2->fitz->-r ./src/requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: prov>=1.5.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (7.0.2)\n",
      "Requirement already satisfied: acres in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: puremagic in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from nipype->fitz->-r ./src/requirements.txt (line 1)) (1.30)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pandas->fitz->-r ./src/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pandas->fitz->-r ./src/requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pyxnat->fitz->-r ./src/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: pathlib>=1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from pyxnat->fitz->-r ./src/requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from scikit-learn->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->-r ./src/requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from etelemetry>=0.3.1->nipype->fitz->-r ./src/requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: certifi in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain_core->-r ./src/requirements.txt (line 2)) (1.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from python-dateutil>=2.2->nipype->fitz->-r ./src/requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ehan/venv/venv_class4/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers->-r ./src/requirements.txt (line 3)) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r ./src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f9c34",
   "metadata": {},
   "source": [
    "### 1) To extract and split the text from the PDF files stored at ./pdfs, build sqlite3 database and FAISS index for keyword/vector search, run the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f166146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehan/venv/venv_class4/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pdf chunk file saved!\n",
      "Sqlite3 database file saved!\n",
      "Number of vectors in the FAISS index: 8390\n",
      "FAISS index created, populated, and saved!\n"
     ]
    }
   ],
   "source": [
    "from src.build_sqlite3_db_and_faiss_index import build\n",
    "build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b11a8",
   "metadata": {},
   "source": [
    "### 2) To load the document chunks, FAISS index, then execute vector search on queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed369be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index and documents files loaded\n",
      "query = \" Normative LLMs Profiling \"\n",
      "\n",
      "Vector Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    5434     0.565    2508.15361v1.pdf   25        \n",
      "2    1682     0.553    2508.15250v1.pdf   1         \n",
      "3    5542     0.543    2508.15361v1.pdf   34        \n",
      "4    5169     0.539    2508.15361v1.pdf   4         \n",
      "5    174      0.532    2508.15396v1.pdf   8         \n",
      "6    1775     0.530    2508.15250v1.pdf   10        \n",
      "7    1691     0.530    2508.15250v1.pdf   2         \n",
      "8    6183     0.529    2508.15283v1.pdf   11        \n",
      "9    4215     0.528    2508.15746v1.pdf   14        \n",
      "10   7347     0.526    2508.15648v1.pdf   3         \n",
      "\n",
      "\n",
      "query = \" Automatic Mixed Precision \"\n",
      "\n",
      "Vector Search Results, for query: 'Automatic Mixed Precision'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1417     0.485    2508.15637v1.pdf   31        \n",
      "2    5697     0.482    2508.15361v1.pdf   48        \n",
      "3    5448     0.476    2508.15361v1.pdf   26        \n",
      "4    4851     0.469    2508.15418v1.pdf   11        \n",
      "5    1313     0.465    2508.15637v1.pdf   15        \n",
      "6    5298     0.458    2508.15361v1.pdf   15        \n",
      "7    5297     0.457    2508.15361v1.pdf   15        \n",
      "8    274      0.456    2508.15396v1.pdf   18        \n",
      "9    7091     0.456    2508.15229v1.pdf   7         \n",
      "10   4181     0.455    2508.15746v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" Sampling Number \"\n",
      "\n",
      "Vector Search Results, for query: 'Sampling Number'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    7398     0.469    2508.15648v1.pdf   8         \n",
      "2    7397     0.448    2508.15648v1.pdf   8         \n",
      "3    8238     0.441    2508.15475v1.pdf   23        \n",
      "4    3977     0.440    2508.15483v1.pdf   2         \n",
      "5    3976     0.437    2508.15483v1.pdf   2         \n",
      "6    1333     0.429    2508.15637v1.pdf   18        \n",
      "7    5976     0.427    2508.15760v1.pdf   6         \n",
      "8    944      0.425    2508.15316v1.pdf   2         \n",
      "9    3216     0.420    2508.15411v1.pdf   6         \n",
      "10   2942     0.420    2508.15754v1.pdf   15        \n",
      "\n",
      "\n",
      "query = \" knowledge distillation \"\n",
      "\n",
      "Vector Search Results, for query: 'knowledge distillation'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2105     0.633    2508.15617v1.pdf   1         \n",
      "2    2104     0.544    2508.15617v1.pdf   1         \n",
      "3    7551     0.540    2508.15709v1.pdf   3         \n",
      "4    7534     0.521    2508.15709v1.pdf   2         \n",
      "5    7552     0.519    2508.15709v1.pdf   3         \n",
      "6    1575     0.511    2508.15253v1.pdf   5         \n",
      "7    8174     0.500    2508.15475v1.pdf   11        \n",
      "8    1201     0.498    2508.15357v1.pdf   8         \n",
      "9    6300     0.496    2508.15478v1.pdf   12        \n",
      "10   7631     0.495    2508.15709v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" Knowledge Graph Completion Models \"\n",
      "\n",
      "Vector Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1103     0.706    2508.15357v1.pdf   1         \n",
      "2    1206     0.631    2508.15357v1.pdf   9         \n",
      "3    1205     0.620    2508.15357v1.pdf   9         \n",
      "4    1194     0.611    2508.15357v1.pdf   8         \n",
      "5    1189     0.593    2508.15357v1.pdf   8         \n",
      "6    1197     0.592    2508.15357v1.pdf   8         \n",
      "7    1204     0.583    2508.15357v1.pdf   9         \n",
      "8    1199     0.580    2508.15357v1.pdf   8         \n",
      "9    1104     0.566    2508.15357v1.pdf   1         \n",
      "10   3848     0.563    2508.15291v1.pdf   8         \n",
      "\n",
      "\n",
      "query = \" small language models \"\n",
      "\n",
      "Vector Search Results, for query: 'small language models'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    5708     0.634    2508.15361v1.pdf   49        \n",
      "2    7108     0.618    2508.15229v1.pdf   8         \n",
      "3    6273     0.604    2508.15478v1.pdf   10        \n",
      "4    222      0.602    2508.15396v1.pdf   12        \n",
      "5    7026     0.593    2508.15229v1.pdf   2         \n",
      "6    2143     0.591    2508.15617v1.pdf   4         \n",
      "7    2115     0.591    2508.15617v1.pdf   2         \n",
      "8    4729     0.590    2508.15418v1.pdf   1         \n",
      "9    7481     0.589    2508.15471v1.pdf   3         \n",
      "10   6282     0.586    2508.15478v1.pdf   10        \n",
      "\n",
      "\n",
      "query = \" knowledge graph embedding \"\n",
      "\n",
      "Vector Search Results, for query: 'knowledge graph embedding'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1190     0.667    2508.15357v1.pdf   8         \n",
      "2    1202     0.660    2508.15357v1.pdf   8         \n",
      "3    1201     0.644    2508.15357v1.pdf   8         \n",
      "4    1203     0.641    2508.15357v1.pdf   9         \n",
      "5    1199     0.624    2508.15357v1.pdf   8         \n",
      "6    1191     0.619    2508.15357v1.pdf   8         \n",
      "7    1194     0.615    2508.15357v1.pdf   8         \n",
      "8    3590     0.595    2508.15721v1.pdf   11        \n",
      "9    1206     0.595    2508.15357v1.pdf   9         \n",
      "10   1195     0.591    2508.15357v1.pdf   8         \n",
      "\n",
      "\n",
      "query = \" Elastic Weight Consolidation algorithm \"\n",
      "\n",
      "Vector Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2643     0.519    2508.15294v1.pdf   8         \n",
      "2    2560     0.467    2508.15294v1.pdf   1         \n",
      "3    7995     0.464    2508.15757v1.pdf   4         \n",
      "4    2446     0.452    2508.15464v1.pdf   5         \n",
      "5    8019     0.436    2508.15757v1.pdf   6         \n",
      "6    8028     0.431    2508.15757v1.pdf   7         \n",
      "7    2444     0.430    2508.15464v1.pdf   5         \n",
      "8    2943     0.430    2508.15754v1.pdf   16        \n",
      "9    6625     0.429    2508.15763v1.pdf   29        \n",
      "10   2964     0.427    2508.15754v1.pdf   17        \n",
      "\n",
      "\n",
      "query = \" Multiple Memory Systems \"\n",
      "\n",
      "Vector Search Results, for query: 'Multiple Memory Systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2635     0.538    2508.15294v1.pdf   7         \n",
      "2    2586     0.532    2508.15294v1.pdf   3         \n",
      "3    2571     0.532    2508.15294v1.pdf   2         \n",
      "4    2581     0.531    2508.15294v1.pdf   3         \n",
      "5    2553     0.524    2508.15294v1.pdf   1         \n",
      "6    2580     0.514    2508.15294v1.pdf   2         \n",
      "7    2588     0.511    2508.15294v1.pdf   3         \n",
      "8    2587     0.502    2508.15294v1.pdf   3         \n",
      "9    2568     0.499    2508.15294v1.pdf   2         \n",
      "10   2554     0.498    2508.15294v1.pdf   1         \n",
      "\n",
      "\n",
      "query = \" Speculative decoding \"\n",
      "\n",
      "Vector Search Results, for query: 'Speculative decoding'\n",
      "============================================================\n",
      "Rank Trunk-ID Nor-dist Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    3075     0.696    2508.15371v1.pdf   6         \n",
      "2    3006     0.653    2508.15371v1.pdf   2         \n",
      "3    3125     0.647    2508.15371v1.pdf   9         \n",
      "4    2980     0.623    2508.15371v1.pdf   1         \n",
      "5    2989     0.613    2508.15371v1.pdf   1         \n",
      "6    2991     0.606    2508.15371v1.pdf   1         \n",
      "7    3031     0.600    2508.15371v1.pdf   4         \n",
      "8    3129     0.599    2508.15371v1.pdf   10        \n",
      "9    3011     0.594    2508.15371v1.pdf   2         \n",
      "10   3030     0.594    2508.15371v1.pdf   3         \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.hybrid_search import connect_to_database, load_documents_and_faiss_index, sqlite_keyword_search, faiss_search, hybrid_search\n",
    "import pprint\n",
    "\n",
    "# Define a list of queries\n",
    "queries = [\n",
    "    \"Normative LLMs Profiling\", # 1674, 1675, 1682\n",
    "    \"Automatic Mixed Precision\", # 2147, other chunk in same page\n",
    "    \"Sampling Number\", #7397, 7398\n",
    "    \"knowledge distillation\", # 1571, 1572, 2104, 2730, 3126, 6206, 6274, 6300, 7522, 7523, 7534, 7630, 8173, 8174  (13)\n",
    "    \"Knowledge Graph Completion Models\", # 1103/04, 1184, 1189, 1197, 1199, 1205/06, 3846/48 (7)  \n",
    "    \"small language models\",\n",
    "    \"knowledge graph embedding\",\n",
    "    \"Elastic Weight Consolidation algorithm\",\n",
    "    \"Multiple Memory Systems\",\n",
    "    \"Speculative decoding\"\n",
    "]\n",
    "\n",
    "load_documents_and_faiss_index()\n",
    "\n",
    "for query in queries:\n",
    "    print(\"query = \\\"\", query, \"\\\"\")\n",
    "    result = faiss_search(query, 10, verbose=True)\n",
    "    print(\"\\n\")\n",
    "    # pprint.pprint(result, sort_dicts=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05058930",
   "metadata": {},
   "source": [
    "### 3) To perform keywork search using Sqlite3 FTS for the queries, ran the following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9d2452e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully opened the database\n",
      "\n",
      "Keyword Search Results, for query: 'Normative LLMs Profiling'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1682     0.724      2508.15250v1.pdf   1         \n",
      "2    1674     0.673      2508.15250v1.pdf   1         \n",
      "3    1675     0.156      2508.15250v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'Automatic Mixed Precision'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2153     0.740      2508.15617v1.pdf   5         \n",
      "2    2147     0.260      2508.15617v1.pdf   5         \n",
      "\n",
      "Keyword Search Results, for query: 'Sampling Number'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    8294     0.797      2508.15244v1.pdf   6         \n",
      "2    8270     0.720      2508.15244v1.pdf   4         \n",
      "3    3015     0.701      2508.15371v1.pdf   3         \n",
      "4    7398     0.173      2508.15648v1.pdf   8         \n",
      "5    7397     0.168      2508.15648v1.pdf   8         \n",
      "\n",
      "Keyword Search Results, for query: 'knowledge distillation'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    6206     0.546      2508.15478v1.pdf   3         \n",
      "2    1572     0.526      2508.15253v1.pdf   5         \n",
      "3    3126     0.506      2508.15371v1.pdf   10        \n",
      "4    4195     0.495      2508.15746v1.pdf   12        \n",
      "5    6300     0.474      2508.15478v1.pdf   12        \n",
      "6    2730     0.453      2508.15274v1.pdf   5         \n",
      "\n",
      "Keyword Search Results, for query: 'Knowledge Graph Completion Models'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1184     0.784      2508.15357v1.pdf   7         \n",
      "2    1197     0.732      2508.15357v1.pdf   8         \n",
      "3    1103     0.092      2508.15357v1.pdf   1         \n",
      "\n",
      "Keyword Search Results, for query: 'small language models'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1948     0.540      2508.15456v1.pdf   7         \n",
      "2    2055     0.502      2508.15456v1.pdf   17        \n",
      "3    7111     0.502      2508.15229v1.pdf   9         \n",
      "4    2145     0.494      2508.15617v1.pdf   4         \n",
      "5    7014     0.486      2508.15229v1.pdf   1         \n",
      "6    456      0.478      2508.15474v1.pdf   13        \n",
      "\n",
      "Keyword Search Results, for query: 'knowledge graph embedding'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    1195     0.631      2508.15357v1.pdf   8         \n",
      "2    3590     0.631      2508.15721v1.pdf   11        \n",
      "3    3589     0.581      2508.15721v1.pdf   11        \n",
      "4    1121     0.471      2508.15357v1.pdf   2         \n",
      "5    1192     0.350      2508.15357v1.pdf   8         \n",
      "6    1197     0.339      2508.15357v1.pdf   8         \n",
      "\n",
      "Keyword Search Results, for query: 'Elastic Weight Consolidation algorithm'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "\n",
      "Keyword Search Results, for query: 'Multiple Memory Systems'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    2552     0.870      2508.15294v1.pdf   1         \n",
      "2    2570     0.693      2508.15294v1.pdf   2         \n",
      "3    2583     0.590      2508.15294v1.pdf   3         \n",
      "4    2571     0.263      2508.15294v1.pdf   2         \n",
      "5    2568     0.114      2508.15294v1.pdf   2         \n",
      "\n",
      "Keyword Search Results, for query: 'Speculative decoding'\n",
      "============================================================\n",
      "Rank Trunk-ID Norm-score Filename           page      \n",
      "------------------------------------------------------------\n",
      "1    3110     0.687      2508.15371v1.pdf   9         \n",
      "2    3033     0.500      2508.15371v1.pdf   4         \n",
      "3    3056     0.490      2508.15371v1.pdf   5         \n",
      "4    3063     0.449      2508.15371v1.pdf   5         \n",
      "5    3080     0.438      2508.15371v1.pdf   7         \n",
      "6    3036     0.428      2508.15371v1.pdf   4         \n"
     ]
    }
   ],
   "source": [
    "connect_to_database()\n",
    "\n",
    "for query in queries:\n",
    "    result = sqlite_keyword_search(query, 6, verbose=True)\n",
    "    # pprint.pprint(result, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea8bf1",
   "metadata": {},
   "source": [
    "### 4) Execute hybrid search (vector + keyword) for the queries, apply the weight-summary merge logic and get the top 3 matches\n",
    "\n",
    "The search results show that the hrbrid method yields more accurate results over using vector or keyword method alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87980fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid Search Results for query: 'Normative LLMs Profiling'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1682   0.621    0.553    0.724    2508.15250v1.p     1         \n",
      "2    5434   0.339    0.565    0.000    2508.15361v1.p     25        \n",
      "3    5542   0.326    0.543    0.000    2508.15361v1.p     34        \n",
      "4    5169   0.323    0.539    0.000    2508.15361v1.p     4         \n",
      "5    174    0.319    0.532    0.000    2508.15396v1.p     8         \n",
      "6    1775   0.318    0.530    0.000    2508.15250v1.p     10        \n",
      "\n",
      "[{'doc_idx': 1682,\n",
      "  'filename': '2508.15250v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 't measurements often focus solely on eth-\\n'\n",
      "             'ical judgments, without considering how factors\\n'\n",
      "             'like professional background, language environ-\\n'\n",
      "             'ment (Changjiang et al., 2024), and model param-\\n'\n",
      "             'eters (Achiam et al., 2023) interact. To fill this gap,\\n'\n",
      "             'we propose the EMNLP (Educator-role Moral and\\n'\n",
      "             'Normative LLMs Profiling) framework for compre-\\n'\n",
      "             'hensive testing and analysis of LLMs’ personality\\n'\n",
      "             'traits and ethical risks in educational contexts.\\n'\n",
      "             'Our EMNLP framework conducts a moral and\\n'\n",
      "             'ethical evaluation of LLMs in the ',\n",
      "  'combined_score': 0.6210238823608489,\n",
      "  'vector_score': 0.5525643229484558,\n",
      "  'keyword_score': 0.7237132214794385},\n",
      " {'doc_idx': 5434,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 25,\n",
      "  'content': ' outputs, adversarial susceptibility, and\\n'\n",
      "             'privacy violations are no longer theoretical, they have tangible '\n",
      "             'consequences for users, organizations,\\n'\n",
      "             'and society at large.\\n'\n",
      "             'Consequently, Risk & Reliability assessment has evolved into a '\n",
      "             'central pillar of modern LLM\\n'\n",
      "             'benchmarking frameworks, rather than a peripheral addition. Its '\n",
      "             'core motivations are:\\n'\n",
      "             '1. Identification and Quantification: To systematically probe '\n",
      "             'LLMs for various negative impact\\n'\n",
      "             'patterns (e.g., generating harmful content[317], hallucinating '\n",
      "             'facts[31',\n",
      "  'combined_score': 0.33929035663604734,\n",
      "  'vector_score': 0.5654839277267456,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5542,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 34,\n",
      "  'content': 'ssessments risk over-specialization;\\n'\n",
      "             'and target-specific metrics struggle to balance technical rigor '\n",
      "             'with real-world relevance. These\\n'\n",
      "             'challenges intensify as LLMs operate in dynamic, multi-agent, '\n",
      "             'high-stakes environments, where\\n'\n",
      "             'static datasets and single-turn metrics fail to capture emergent '\n",
      "             'behaviors or societal impacts. As\\n'\n",
      "             'LLMs integrate into sociotechnical systems, evaluation must '\n",
      "             'shift from measuring \"what models can\\n'\n",
      "             'do\" to \"how they should perform responsibly.\" Future benchmarks '\n",
      "             'require dynamism (to ma',\n",
      "  'combined_score': 0.3256558656692505,\n",
      "  'vector_score': 0.5427597761154175,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5169,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': 'pabilities of LLMs, and key requirements such as detection\\n'\n",
      "             'of bias and security loopholes and systematic evaluation of '\n",
      "             'instruction compliance have not yet\\n'\n",
      "             'been effectively met. In addition, the high cost of arithmetic '\n",
      "             'and manpower required for large-scale\\n'\n",
      "             'evaluation, and the difficulty of task design to cover the '\n",
      "             'complexity of the real world are serious\\n'\n",
      "             'constraints to the healthy development of LLMs. Figure 1 shows a '\n",
      "             'timeline of representative LLM\\n'\n",
      "             'benchmarks, illustrating this rapid evolution.\\n'\n",
      "             '4',\n",
      "  'combined_score': 0.32333550453186033,\n",
      "  'vector_score': 0.5388925075531006,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 174,\n",
      "  'filename': '2508.15396v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'e (ground truth). LLM-as-a-judge metrics\\n'\n",
      "             'use LLMs to automatically evaluate the quality\\n'\n",
      "             'of texts generated by other LLMs, thereby elim-\\n'\n",
      "             'inating the need for human judges. Typically, the\\n'\n",
      "             'LLM acting as a judge produces numerical scores,\\n'\n",
      "             'often normalized to a 0–1 scale. Retrieval-based\\n'\n",
      "             'metrics quantitatively evaluate how effectively an\\n'\n",
      "             'approach incorporates relevant evidence by com-\\n'\n",
      "             'paring the retrieved or integrated evidence with\\n'\n",
      "             'a ground truth. This method is commonly used\\n'\n",
      "             'to assess whether the correct sourc',\n",
      "  'combined_score': 0.319476056098938,\n",
      "  'vector_score': 0.53246009349823,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1775,\n",
      "  'filename': '2508.15250v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'g moral beliefs\\n'\n",
      "             'across llms through a pluralistic framework. In Find-\\n'\n",
      "             'ings of the Association for Computational Linguistics:\\n'\n",
      "             'EMNLP 2024, pages 4740–4760.\\n'\n",
      "             'Giovanni Marraffini, Andrés Cotton, Noe Hsueh, Axel\\n'\n",
      "             'Fridman, Juan Wisznia, and Luciano Corro. 2024. The\\n'\n",
      "             'greatest good benchmark: Measuring llms’ alignment\\n'\n",
      "             'with utilitarian moral dilemmas. In Proceedings of the\\n'\n",
      "             '2024 Conference on Empirical Methods in Natural Lan-\\n'\n",
      "             'guage Processing, pages 21950–21959.\\n'\n",
      "             'Lennart Meincke and Andrew Carton. 2024. Beyond\\n'\n",
      "             'multiple c',\n",
      "  'combined_score': 0.3180772304534912,\n",
      "  'vector_score': 0.5301287174224854,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Automatic Mixed Precision'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2153   0.296    0.000    0.740    2508.15617v1.p     5         \n",
      "2    1417   0.291    0.485    0.000    2508.15637v1.p     31        \n",
      "3    5697   0.289    0.482    0.000    2508.15361v1.p     48        \n",
      "4    5448   0.286    0.476    0.000    2508.15361v1.p     26        \n",
      "5    4851   0.281    0.469    0.000    2508.15418v1.p     11        \n",
      "6    1313   0.279    0.465    0.000    2508.15637v1.p     15        \n",
      "\n",
      "[{'doc_idx': 2153,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'compared to our\\n'\n",
      "             'LoRA approach.\\n'\n",
      "             'Memory Optimization Techniques\\n'\n",
      "             'Due to the memory constraints from updating all parameters\\n'\n",
      "             'in full fine-tuning, we employed several advanced techniques:\\n'\n",
      "             '• Automatic\\n'\n",
      "             'Mixed\\n'\n",
      "             'Precision\\n'\n",
      "             '(AMP):\\n'\n",
      "             'Utilizing\\n'\n",
      "             'FP16/BF16\\n'\n",
      "             '(Micikevicius\\n'\n",
      "             'et\\n'\n",
      "             'al.,\\n'\n",
      "             '2017)\\n'\n",
      "             'to\\n'\n",
      "             'reduce\\n'\n",
      "             'memory consumption and accelerate training.\\n'\n",
      "             '• Gradient Checkpointing: Recomputing activations dur-\\n'\n",
      "             'ing the backward pass to reduce memory footprint (Chen\\n'\n",
      "             'et al., 2016).\\n'\n",
      "             '• ZeRO Sharding: Employed for our larger 14B param-\\n'\n",
      "             'eter models to ',\n",
      "  'combined_score': 0.2961242451252006,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7403106128130015},\n",
      " {'doc_idx': 1417,\n",
      "  'filename': '2508.15637v1.pdf',\n",
      "  'page': 31,\n",
      "  'content': ' optimal balance of recall and precision might depend on\\n'\n",
      "             'the task at hand, and the relative harm of false positive versus '\n",
      "             'false negatives (Silva Filho\\n'\n",
      "             'et al., 2023). We suggest that computer scientists allow the '\n",
      "             'users of their algorithms to\\n'\n",
      "             're-adjust the recall/precision trade-off according to their '\n",
      "             'need, based on the confidence\\n'\n",
      "             'scores of the predictions14. More interestingly, confidence '\n",
      "             'scores15 could also be used\\n'\n",
      "             'as covariates in our calibration model, reducing the uncertainty '\n",
      "             'in posterior statistical\\n'\n",
      "             'est',\n",
      "  'combined_score': 0.29081872701644895,\n",
      "  'vector_score': 0.4846978783607483,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5697,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 48,\n",
      "  'content': 'er, and Hannaneh Hajishirzi. Factscore: Fine-grained atomic '\n",
      "             'evaluation of factual precision in\\n'\n",
      "             'long form text generation, 2023.\\n'\n",
      "             '48',\n",
      "  'combined_score': 0.28918608427047726,\n",
      "  'vector_score': 0.48197680711746216,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 5448,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 26,\n",
      "  'content': 'ng the highest accuracy.\\n26',\n",
      "  'combined_score': 0.2858834981918335,\n",
      "  'vector_score': 0.47647249698638916,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 4851,\n",
      "  'filename': '2508.15418v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': ' to 127. Specifically, our extraction\\n'\n",
      "             'function sequentially attempts integer conversion,\\n'\n",
      "             'rounded float conversion, and finally, averaging\\n'\n",
      "             'numeric ranges. Strings containing pitch-related\\n'\n",
      "             'keywords (e.g., \"midi\", \"pitch\", \"hz\") but lacking\\n'\n",
      "             'numeric values are marked as invalid predictions.\\n'\n",
      "             'Only predictions within the MIDI range of 0 to 127\\n'\n",
      "             'are considered valid for metric computation. In all\\n'\n",
      "             'cases, if a valid numeric value cannot be extracted\\n'\n",
      "             'from either the model’s prediction, that instance\\n'\n",
      "             'is omitted from the',\n",
      "  'combined_score': 0.28140015006065366,\n",
      "  'vector_score': 0.4690002501010895,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1313,\n",
      "  'filename': '2508.15637v1.pdf',\n",
      "  'page': 15,\n",
      "  'content': 'e algorithms is highly stochastic (i.e., confusion rates may\\n'\n",
      "             'vary a lot across recordings). We also found that the '\n",
      "             'calibration procedure improved the\\n'\n",
      "             '8The\\n'\n",
      "             'F-score\\n'\n",
      "             'is\\n'\n",
      "             'the\\n'\n",
      "             'harmonic\\n'\n",
      "             'mean\\n'\n",
      "             'of\\n'\n",
      "             'precision\\n'\n",
      "             '(\\n'\n",
      "             'true positives\\n'\n",
      "             'true positives+false positives)\\n'\n",
      "             'and\\n'\n",
      "             'recall\\n'\n",
      "             '(\\n'\n",
      "             'true positives\\n'\n",
      "             'true positives+false negatives).\\n'\n",
      "             '9These results correspond to frame-level accuracy metrics, which '\n",
      "             'depend also on the annotators’\\n'\n",
      "             'ability to precisely locate the onset/offset of a vocalization. '\n",
      "             'This is a more difficult task compared to\\n'\n",
      "             'mer',\n",
      "  'combined_score': 0.2792592108249664,\n",
      "  'vector_score': 0.4654320180416107,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Sampling Number'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    7398   0.351    0.469    0.173    2508.15648v1.p     8         \n",
      "2    7397   0.336    0.448    0.168    2508.15648v1.p     8         \n",
      "3    8294   0.319    0.000    0.797    2508.15244v1.p     6         \n",
      "4    8270   0.288    0.000    0.720    2508.15244v1.p     4         \n",
      "5    3015   0.280    0.000    0.701    2508.15371v1.p     3         \n",
      "6    8238   0.265    0.441    0.000    2508.15475v1.p     23        \n",
      "\n",
      "[{'doc_idx': 7398,\n",
      "  'filename': '2508.15648v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': ' prompt\\n'\n",
      "             'We\\n'\n",
      "             'analyze the effect of the number of responses sam-\\n'\n",
      "             'pled for each prompt. Our choice of sampling num-\\n'\n",
      "             'ber is based on balancing diversity and efficiency,\\n'\n",
      "             'optimizing the policy model by generating multi-\\n'\n",
      "             'ple completions and calculating their rewards. We\\n'\n",
      "             'select four different sampling numbers: 2, 4, 8, 16,\\n'\n",
      "             'each paired with different temperature parameters,\\n'\n",
      "             'detailed in Table 6. As shown in Figure 4, sampling\\n'\n",
      "             'reaches a plateau at 8, with further increases not\\n'\n",
      "             'leading to improvements in performance.\\n'\n",
      "             'Im',\n",
      "  'combined_score': 0.3505808699439198,\n",
      "  'vector_score': 0.4688315987586975,\n",
      "  'keyword_score': 0.17320477672175333},\n",
      " {'doc_idx': 7397,\n",
      "  'filename': '2508.15648v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'sults in Figure 4 (left) show that the\\n'\n",
      "             'model reaches a relatively low safety gap by the\\n'\n",
      "             'third step, with the gap decreasing progressively\\n'\n",
      "             'over the three rounds. This also demonstrates the\\n'\n",
      "             'effectiveness of SDGO’s online data sampling, al-\\n'\n",
      "             'lowing the model to iteratively update itself on its\\n'\n",
      "             'own generated data to achieve a new balance be-\\n'\n",
      "             'tween discrimination and generation safety.\\n'\n",
      "             'Impact of Sampling Number per prompt\\n'\n",
      "             'We\\n'\n",
      "             'analyze the effect of the number of responses sam-\\n'\n",
      "             'pled for each prompt. Our choice of sa',\n",
      "  'combined_score': 0.3358257712587238,\n",
      "  'vector_score': 0.4479081332683563,\n",
      "  'keyword_score': 0.16770222824427516},\n",
      " {'doc_idx': 8294,\n",
      "  'filename': '2508.15244v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'h the matrix language in italics and code-switched\\n'\n",
      "             '(or embedded language) segments highlighted in red.\\n'\n",
      "             '4.3\\n'\n",
      "             'Source Mixing\\n'\n",
      "             'In Sec. 3.2.2, we demonstrated that UniCoM can\\n'\n",
      "             'substitute various POS and adjust the number of\\n'\n",
      "             'word pairs as needed. However, excessive word\\n'\n",
      "             'substitution can lead to unnatural results, deviating\\n'\n",
      "             'from real-world CS scenarios. To maintain natu-\\n'\n",
      "             'ralness and ensure the generated speech reflects\\n'\n",
      "             'authentic CS patterns, we limited sampling to a\\n'\n",
      "             'maximum of three word pairs and restricted POS\\n'\n",
      "             'cate',\n",
      "  'combined_score': 0.31890004075124245,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7972501018781061},\n",
      " {'doc_idx': 8270,\n",
      "  'filename': '2508.15244v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': 'meaning. We thus adopted word- or POS-level sub-\\n'\n",
      "             'stitutions with a flexible number of substitutions,\\n'\n",
      "             'allowing natural CS sentence generation while pre-\\n'\n",
      "             'serving semantics and syntactic structure.\\n'\n",
      "             '3.2.2\\n'\n",
      "             'SWORDS Algorithm\\n'\n",
      "             'In this context, we propose the Substituting\\n'\n",
      "             'WORDs with Synonym (SWORDS) algorithm.\\n'\n",
      "             'SWORDS is composed of four steps: (1) Sampling\\n'\n",
      "             'of equivalent sentence pairs, (2) Wordpair mapping\\n'\n",
      "             'generation, (3) Segmentation using forced align-\\n'\n",
      "             'ment, (4) Completion through recombination.\\n'\n",
      "             'This approach intro',\n",
      "  'combined_score': 0.2879062728703903,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7197656821759757},\n",
      " {'doc_idx': 3015,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 3,\n",
      "  'content': 'y on a fixed number of drafted \\n'\n",
      "             'tokens per iteration and a strict binary verification scheme. \\n'\n",
      "             'While effective in reducing latency, its dependence on a \\n'\n",
      "             'model size hierarchy introduces additional memory overhead \\n'\n",
      "             'during inference. Moreover, the method does not incorporate \\n'\n",
      "             'entropy-based or token-based confidence signals, thus lacking \\n'\n",
      "             'the adaptivity necessary for optimizing decoding in variable \\n'\n",
      "             'or uncertain generation contexts.    \\n'\n",
      "             'Chen et al. introduced speculative sampling for large \\n'\n",
      "             'models like Chinchil',\n",
      "  'combined_score': 0.2804438957484629,\n",
      "  'vector_score': 0.0,\n",
      "  'keyword_score': 0.7011097393711572},\n",
      " {'doc_idx': 8238,\n",
      "  'filename': '2508.15475v1.pdf',\n",
      "  'page': 23,\n",
      "  'content': 'aluation set by sampling the\\n'\n",
      "             '100M word 2024 BabyLM dataset (D2024 is the 10M version; Choshen '\n",
      "             'et al., 2024). |Deval| = 0.05 · |D2024|.\\n'\n",
      "             '23',\n",
      "  'combined_score': 0.2647353708744049,\n",
      "  'vector_score': 0.4412256181240082,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'knowledge distillation'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    6300   0.503    0.496    0.515    2508.15478v1.p     12        \n",
      "2    2730   0.491    0.489    0.493    2508.15274v1.p     5         \n",
      "3    7631   0.481    0.495    0.460    2508.15709v1.p     10        \n",
      "4    8174   0.479    0.500    0.449    2508.15475v1.p     11        \n",
      "5    2105   0.380    0.633    0.000    2508.15617v1.p     1         \n",
      "6    2104   0.327    0.544    0.000    2508.15617v1.p     1         \n",
      "\n",
      "[{'doc_idx': 6300,\n",
      "  'filename': '2508.15478v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'e on Neu-\\n'\n",
      "             'ral Information Processing (ICONIP), pages 27–38.\\n'\n",
      "             'Songming Zhang, Xue Zhang, Zengkui Sun, Yufeng\\n'\n",
      "             'Chen, and Jinan Xu. 2024a. Dual-space knowledge\\n'\n",
      "             'distillation for large language models. In Proceed-\\n'\n",
      "             'ings of the Conference on Empirical Methods in Nat-\\n'\n",
      "             'ural Language Processing (EMNLP), pages 18164–\\n'\n",
      "             '18181.\\n'\n",
      "             'Yingtao Zhang, Haoli Bai, Haokun Lin, Jialin Zhao,\\n'\n",
      "             'Lu Hou, and Carlo Vittorio Cannistraci. 2024b.\\n'\n",
      "             'Plug-and-play: An efficient post-training pruning\\n'\n",
      "             'method for large language models. In Proceedings\\n'\n",
      "             'of',\n",
      "  'combined_score': 0.5033888432528759,\n",
      "  'vector_score': 0.4959339201450348,\n",
      "  'keyword_score': 0.5145712279146375},\n",
      " {'doc_idx': 2730,\n",
      "  'filename': '2508.15274v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': '321–324.\\n'\n",
      "             '[20] Niket Tandon, Gerard de Melo, and Gerhard Weikum. 2017. '\n",
      "             'WebChild 2.0 : Fine-\\n'\n",
      "             'Grained Commonsense Knowledge Distillation. In Proceedings of '\n",
      "             'the 55th Annual\\n'\n",
      "             'Meeting of the Association for Computational Linguistics, ACL '\n",
      "             '2017, Vancouver,\\n'\n",
      "             'Canada, July 30 - August 4, System Demonstrations, Mohit Bansal '\n",
      "             'and Heng Ji\\n'\n",
      "             '(Eds.). Association for Computational Linguistics, 115–120.\\n'\n",
      "             '[21] Hugo Touvron et al. 2023. Llama 2: Open Foundation and '\n",
      "             'Fine-Tuned Chat\\n'\n",
      "             'Models. CoRR abs/2307.09288 (2023).\\n'\n",
      "             '[22] Alakananda ',\n",
      "  'combined_score': 0.49061670252132805,\n",
      "  'vector_score': 0.4890536367893219,\n",
      "  'keyword_score': 0.4929613011193372},\n",
      " {'doc_idx': 7631,\n",
      "  'filename': '2508.15709v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': ' Rush. 2016. Sequence-\\n'\n",
      "             'level knowledge distillation.\\n'\n",
      "             'Solomon Kullback and Richard A. Leibler. 1951. On\\n'\n",
      "             'information and sufficiency. Annals of Mathematical\\n'\n",
      "             'Statistics, 22(1):79–86.\\n'\n",
      "             'Yuri Kuratov, Aydar Bulatov, Petr Anokhin, Ivan Rod-\\n'\n",
      "             'kin, Dmitry Igorevich Sorokin, Artyom Sorokin, and\\n'\n",
      "             'Mikhail Burtsev. 2024.\\n'\n",
      "             'BABILong: Testing the\\n'\n",
      "             'limits of LLMs with long context reasoning-in-a-\\n'\n",
      "             'haystack. In The Thirty-eight Conference on Neural\\n'\n",
      "             'Information Processing Systems Datasets and Bench-\\n'\n",
      "             'marks Track.\\n'\n",
      "             'Tom Kwiatkowski, Je',\n",
      "  'combined_score': 0.48084253897093465,\n",
      "  'vector_score': 0.4948987364768982,\n",
      "  'keyword_score': 0.4597582427119894},\n",
      " {'doc_idx': 8174,\n",
      "  'filename': '2508.15475v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': 'ryasov and Jean-Loup Tastet. 2023. Baby\\n'\n",
      "             'Llama: knowledge distillation from an ensemble of\\n'\n",
      "             'teachers trained on a small dataset with no perfor-\\n'\n",
      "             'mance penalty. In Proceedings of the BabyLM Chal-\\n'\n",
      "             'lenge at the 27th Conference on Computational Nat-\\n'\n",
      "             'ural Language Learning, pages 279–289, Singapore.\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\\n'\n",
      "             'Martinet, Marie-Anne Lachaux, Timothée Lacroix,\\n'\n",
      "             'Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal\\n'\n",
      "             'Azhar, Aurelien Rodrigu',\n",
      "  'combined_score': 0.47944915158689216,\n",
      "  'vector_score': 0.5000695586204529,\n",
      "  'keyword_score': 0.44851854103655114},\n",
      " {'doc_idx': 2105,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'nowledge distillation (Hinton et al., 2015)[4]. Tra-\\n'\n",
      "             'ditional distillation is a difficult process that attempts to '\n",
      "             'project\\n'\n",
      "             'a “teacher” model’s whole knowledge base onto a “student”\\n'\n",
      "             'model. This is typically done by training the student to mimic\\n'\n",
      "             'the teacher’s internal output probability distributions (the '\n",
      "             '“soft\\n'\n",
      "             'targets” or logits) over the entire vocabulary. The goal is to\\n'\n",
      "             'compress the student’s internal computational process into a\\n'\n",
      "             'compact representation of the teacher’s. Our “Trained Minia-\\n'\n",
      "             'tures” method, i',\n",
      "  'combined_score': 0.37967580556869507,\n",
      "  'vector_score': 0.6327930092811584,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2104,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'here domain experts curate and refine the outputs,\\n'\n",
      "             'filtering for strategic relevance, quality, and precision. This\\n'\n",
      "             'results in a “gold standard” training dataset of thousands of\\n'\n",
      "             'flawless input-output pairs. This refined dataset is then used '\n",
      "             'to\\n'\n",
      "             'fine-tune an order-of-magnitude smaller, more efficient open-\\n'\n",
      "             'source Small Language Model (SLM).\\n'\n",
      "             'It is essential to make a clear technical distinction from\\n'\n",
      "             'traditional knowledge distillation (Hinton et al., 2015)[4]. '\n",
      "             'Tra-\\n'\n",
      "             'ditional distillation is a difficult process th',\n",
      "  'combined_score': 0.32662507295608517,\n",
      "  'vector_score': 0.5443751215934753,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Knowledge Graph Completion Models'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    1197   0.648    0.592    0.732    2508.15357v1.p     8         \n",
      "2    1103   0.460    0.706    0.092    2508.15357v1.p     1         \n",
      "3    1206   0.379    0.631    0.000    2508.15357v1.p     9         \n",
      "4    1205   0.372    0.620    0.000    2508.15357v1.p     9         \n",
      "5    1194   0.367    0.611    0.000    2508.15357v1.p     8         \n",
      "6    1189   0.356    0.593    0.000    2508.15357v1.p     8         \n",
      "\n",
      "[{'doc_idx': 1197,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'emi, S. M.; and Poole, D. 2018. Simple Embedding for\\n'\n",
      "             'Link Prediction in Knowledge Graphs. In Advances in Neu-\\n'\n",
      "             'ral Information Processing Systems, volume 31.\\n'\n",
      "             'Kim, B.; Hong, T.; Ko, Y.; and Seo, J. 2020.\\n'\n",
      "             'Multi-\\n'\n",
      "             'Task Learning for Knowledge Graph Completion with Pre-\\n'\n",
      "             'trained Language Models. In Scott, D.; Bel, N.; and Zong,\\n'\n",
      "             'C., eds., Proceedings of the 28th International Conference\\n'\n",
      "             'on Computational Linguistics, 1737–1743.Barcelona, Spain\\n'\n",
      "             '(Online): International Committee on Computational Lin-\\n'\n",
      "             'guistics.\\n'\n",
      "             'Lin, X.;',\n",
      "  'combined_score': 0.6480273692011436,\n",
      "  'vector_score': 0.5918718576431274,\n",
      "  'keyword_score': 0.7322606365381678},\n",
      " {'doc_idx': 1103,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'KG-EDAS: A Meta-Metric Framework for Evaluating Knowledge Graph\\n'\n",
      "             'Completion Models\\n'\n",
      "             'Haji Gul1, Abul Ghani Naim1, Ajaz Ahmad Bhat1 ∗\\n'\n",
      "             '1School of Digital Science, Universiti Brunei Darussalam\\n'\n",
      "             '(23h1710, ghani.naim, ajaz.bhat∗)@ubd.edu.bn\\n'\n",
      "             'Abstract\\n'\n",
      "             'Knowledge Graphs (KGs) enable applications in various do-\\n'\n",
      "             'mains such as semantic search, recommendation systems,\\n'\n",
      "             'and natural language processing. KGs are often incomplete,\\n'\n",
      "             'missing entities and relations, an issue addressed by Knowl-\\n'\n",
      "             'edge Graph Completion (KGC) methods th',\n",
      "  'combined_score': 0.46009505576096776,\n",
      "  'vector_score': 0.7056922316551208,\n",
      "  'keyword_score': 0.09169929191973826},\n",
      " {'doc_idx': 1206,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ', J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In Bouamor, H.; Pino, J.;\\n'\n",
      "             'and Bali, K., eds., Findings of the Association for Compu-\\n'\n",
      "             'tational Linguistics: EMNLP 2023, 8667–8683. Singapore:\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2015.\\n'\n",
      "             'Embedding entities and relations for learning and inference\\n'\n",
      "             'in knowledge bases. arXiv preprint arXiv:1412.6575.\\n'\n",
      "             'Zhang, W.; Paudel, B.; Zhang, W.; Bernstein, A.; and Chen,\\n'\n",
      "             'H',\n",
      "  'combined_score': 0.37882543802261354,\n",
      "  'vector_score': 0.6313757300376892,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1205,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': 'guage Mod-\\n'\n",
      "             'els. In Proc. of ACL.\\n'\n",
      "             'Wang, Y.; Broscheit, S.; and Gemulla, R. 2019. A Relational\\n'\n",
      "             'Tucker Decomposition for Multi-Relational Link Prediction.\\n'\n",
      "             'arXiv preprint. ArXiv:1902.00898.\\n'\n",
      "             'Wang, Z.; Zhang, J.; Feng, J.; and Chen, Z. 2014. Knowl-\\n'\n",
      "             'edge graph embedding by translating on hyperplanes. In\\n'\n",
      "             'Proceedings of the AAAI Conference on Artiﬁcial Intelli-\\n'\n",
      "             'gence, volume 28.\\n'\n",
      "             'Wei, Y.; Huang, Q.; Zhang, Y.; and Kwok, J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In',\n",
      "  'combined_score': 0.37220213413238523,\n",
      "  'vector_score': 0.6203368902206421,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1194,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'ext-Aware Knowledge Graph Completion. In Wu,\\n'\n",
      "             'X.; Spiliopoulou, M.; Wang, C.; Kumar, V.; Cao, L.; Zhou,\\n'\n",
      "             'X.; Pang, G.; and Gama, J., eds., Data Science: Foundations\\n'\n",
      "             'and Applications, 3–15. Singapore: Springer Nature Singa-\\n'\n",
      "             'pore. ISBN 978-981-96-8298-0.\\n'\n",
      "             'Guo, L.; Sun, Z.; and Hu, W. 2019. Learning to Exploit\\n'\n",
      "             'Long-term Relational Dependencies in Knowledge Graphs.\\n'\n",
      "             'In International Conference on Machine Learning. PMLR.\\n'\n",
      "             'Ji, G.; He, S.; Xu, L.; Liu, K.; and Zhao, J. 2015. Knowledge\\n'\n",
      "             'graph embedding via dynamic mappin',\n",
      "  'combined_score': 0.36651785373687745,\n",
      "  'vector_score': 0.6108630895614624,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 1189,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'Thank you for reading these instructions carefully. We look\\n'\n",
      "             'forward to receiving your electronic ﬁles!\\n'\n",
      "             'References\\n'\n",
      "             'Akrami, F.; Saeef, M. S.; Zhang, Q.; Hu, W.; and Li, C.\\n'\n",
      "             '2020. Realistic re-evaluation of knowledge graph comple-\\n'\n",
      "             'tion methods: An experimental study. In Proceedings of the\\n'\n",
      "             '2020 ACM SIGMOD International Conference on Manage-\\n'\n",
      "             'ment of Data, 1995–2010.\\n'\n",
      "             'Bollacker, K.; Evans, C.; Paritosh, P.; Sturge, T.; and Taylor,\\n'\n",
      "             'J. 2008. Freebase: A collaboratively created graph database\\n'\n",
      "             'for structuring human kno',\n",
      "  'combined_score': 0.3556807994842529,\n",
      "  'vector_score': 0.5928013324737549,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'small language models'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2143   0.553    0.591    0.494    2508.15617v1.p     4         \n",
      "2    5708   0.380    0.634    0.000    2508.15361v1.p     49        \n",
      "3    7108   0.371    0.618    0.000    2508.15229v1.p     8         \n",
      "4    6273   0.362    0.604    0.000    2508.15478v1.p     10        \n",
      "5    222    0.361    0.602    0.000    2508.15396v1.p     12        \n",
      "6    7026   0.356    0.593    0.000    2508.15229v1.p     2         \n",
      "\n",
      "[{'doc_idx': 2143,\n",
      "  'filename': '2508.15617v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': ' context)\\n'\n",
      "             'This selection allowed us to cover a significant number of mod-\\n'\n",
      "             'els, with varying architectures and parameter spaces ranging\\n'\n",
      "             'from 1B to 12B and context length ranging from 8k tokens to\\n'\n",
      "             '32 tokens.\\n'\n",
      "             'B. Fine-tuning\\n'\n",
      "             'To investigate the abilities and limits of Small Language\\n'\n",
      "             'Models (SLMs), we used two different adaptation methods\\n'\n",
      "             'for each model. The first method was a complete fine-tuning\\n'\n",
      "             'process, where we updated all model parameters. The second\\n'\n",
      "             'method used Parameter-Efficient Fine-Tuning (PEFT), specif',\n",
      "  'combined_score': 0.5525445593953514,\n",
      "  'vector_score': 0.5913794040679932,\n",
      "  'keyword_score': 0.4942922923863888},\n",
      " {'doc_idx': 5708,\n",
      "  'filename': '2508.15361v1.pdf',\n",
      "  'page': 49,\n",
      "  'content': 'data from large language models, 2023.\\n49',\n",
      "  'combined_score': 0.3801627516746521,\n",
      "  'vector_score': 0.6336045861244202,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7108,\n",
      "  'filename': '2508.15229v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 's (Volume 1: Long Papers), 1715–1725. Berlin, Germany:\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Sinha, N.; Jain, V.; and Chadha, A. 2024.\\n'\n",
      "             'Are Small\\n'\n",
      "             'Language Models Ready to Compete with Large Lan-\\n'\n",
      "             'guage Models for Practical Applications?\\n'\n",
      "             'arXiv preprint\\n'\n",
      "             'arXiv:2406.11402.',\n",
      "  'combined_score': 0.3707545280456543,\n",
      "  'vector_score': 0.6179242134094238,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 6273,\n",
      "  'filename': '2508.15478v1.pdf',\n",
      "  'page': 10,\n",
      "  'content': 'Ahmad Faiz, Sotaro Kaneda, Ruhan Wang, Rita Chuk-\\n'\n",
      "             'wunyere Osi, Prateek Sharma, Fan Chen, and Lei\\n'\n",
      "             'Jiang. 2024. Llmcarbon: Modeling the end-to-end\\n'\n",
      "             'carbon footprint of large language models. In Pro-\\n'\n",
      "             'ceedings of the International Conference on Learn-\\n'\n",
      "             'ing Representations (ICLR).\\n'\n",
      "             'Ze-Feng Gao, Kun Zhou, Peiyu Liu, Wayne Xin Zhao,\\n'\n",
      "             'and Ji-Rong Wen. 2023. Small pre-trained language\\n'\n",
      "             'models can be fine-tuned as large models via over-\\n'\n",
      "             'parameterization. In Proceedings of the Annual\\n'\n",
      "             'Meeting of the Association for Computat',\n",
      "  'combined_score': 0.36237984895706177,\n",
      "  'vector_score': 0.6039664149284363,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 222,\n",
      "  'filename': '2508.15396v1.pdf',\n",
      "  'page': 12,\n",
      "  'content': 'ion and modeling for attributed\\n'\n",
      "             'large language models.\\n'\n",
      "             'Tom Brown,\\n'\n",
      "             'Benjamin Mann,\\n'\n",
      "             'Nick Ryder,\\n'\n",
      "             'Melanie Subbiah, Jared D Kaplan, Prafulla\\n'\n",
      "             'Dhariwal, Arvind Neelakantan, Pranav Shyam,',\n",
      "  'combined_score': 0.3609574556350708,\n",
      "  'vector_score': 0.6015957593917847,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7026,\n",
      "  'filename': '2508.15229v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'on, informa-\\n'\n",
      "             'tion extraction, and math problem solving—VocabTailor\\n'\n",
      "             'reduces memory usage of vocabulary-related compo-\\n'\n",
      "             'nents by up to 99%, significantly lowers memory usage\\n'\n",
      "             'with minimal or no performance degradation.\\n'\n",
      "             '2\\n'\n",
      "             'Related Work\\n'\n",
      "             '2.1\\n'\n",
      "             'Small Language Model\\n'\n",
      "             'Small language models (SLMs) are compact alternatives\\n'\n",
      "             'to large language models (LLMs), which are designed\\n'\n",
      "             'for efficiency, lower computational costs, and deployment\\n'\n",
      "             'on resource-constrained devices. While LLMs like GPT-4\\n'\n",
      "             '(Achiam et al. 2023), LLaMA (Touvron e',\n",
      "  'combined_score': 0.3560593843460083,\n",
      "  'vector_score': 0.5934323072433472,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'knowledge graph embedding'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    3590   0.663    0.595    0.765    2508.15721v1.p     11        \n",
      "2    1195   0.661    0.591    0.765    2508.15357v1.p     8         \n",
      "3    1121   0.606    0.591    0.629    2508.15357v1.p     2         \n",
      "4    1203   0.559    0.641    0.437    2508.15357v1.p     9         \n",
      "5    1206   0.513    0.595    0.390    2508.15357v1.p     9         \n",
      "6    1191   0.467    0.619    0.239    2508.15357v1.p     8         \n",
      "\n",
      "[{'doc_idx': 3590,\n",
      "  'filename': '2508.15721v1.pdf',\n",
      "  'page': 11,\n",
      "  'content': 'Sushant Ku-\\n'\n",
      "             'mar, and Kannan Achan. 2020. Product knowledge\\n'\n",
      "             'graph embedding for e-commerce. In Proceedings of\\n'\n",
      "             'the 13th international conference on web search and\\n'\n",
      "             'data mining, pages 672–680.\\n'\n",
      "             'Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng,\\n'\n",
      "             'Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang,\\n'\n",
      "             'Weiming Ren, Yuxuan Sun, and 1 others. 2024.\\n'\n",
      "             'Mmmu: A massive multi-discipline multimodal un-\\n'\n",
      "             'derstanding and reasoning benchmark for expert agi.\\n'\n",
      "             'In Proceedings of the IEEE/CVF Conference on Com-\\n'\n",
      "             'puter Vision and Pattern Re',\n",
      "  'combined_score': 0.6631259779862533,\n",
      "  'vector_score': 0.5949219465255737,\n",
      "  'keyword_score': 0.7654320251772728},\n",
      " {'doc_idx': 1195,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'LR.\\n'\n",
      "             'Ji, G.; He, S.; Xu, L.; Liu, K.; and Zhao, J. 2015. Knowledge\\n'\n",
      "             'graph embedding via dynamic mapping matrix. Proceedings\\n'\n",
      "             'of the 53rd Annual Meeting of the Association for Computa-\\n'\n",
      "             'tional Linguistics and the 7th International Joint Conference\\n'\n",
      "             'on Natural Language Processing (Volume 1: Long Papers),\\n'\n",
      "             '687–696.\\n'\n",
      "             'Jiang, X.; Wang, Q.; and Wang, B. 2019. Adaptive Convo-\\n'\n",
      "             'lution for Multi-relational Learning. In Proceedings of the\\n'\n",
      "             '2019 Conference of the North American Chapter of the As-\\n'\n",
      "             'sociation for Computational Lin',\n",
      "  'combined_score': 0.6608774642876755,\n",
      "  'vector_score': 0.5911744236946106,\n",
      "  'keyword_score': 0.7654320251772728},\n",
      " {'doc_idx': 1121,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': ' fragmented approach complicates model comparison\\n'\n",
      "             'and hinders progress in the ﬁeld, as researchers must man-\\n'\n",
      "             'ually weigh conﬂicting metric outcomes to make informed\\n'\n",
      "             'decisions.\\n'\n",
      "             'In response to these challenges, recent studies have ex-\\n'\n",
      "             'plored alternative strategies for evaluating KGC models.\\n'\n",
      "             'Rufﬁnelli et al. (Rufﬁnelli, Broscheit, and Gemulla 2020)\\n'\n",
      "             'conducted an extensive empirical review of knowledge\\n'\n",
      "             'graph embedding (KGE) models, highlighting inconsisten-\\n'\n",
      "             'cies in metric usage and calling for more standardized\\n',\n",
      "  'combined_score': 0.6060595643790959,\n",
      "  'vector_score': 0.5908136367797852,\n",
      "  'keyword_score': 0.6289284557780621},\n",
      " {'doc_idx': 1203,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': 'Sun, Z.; Deng, Z.; Nie, J.; and Tang, J. 2019. RotatE: Knowl-\\n'\n",
      "             'edge Graph Embedding by Relational Rotation in Complex\\n'\n",
      "             'Space. In Proc. of ICLR.\\n'\n",
      "             'Sun, Z.; Zhang, Q.; Hu, W.; Wang, C.; Chen, M.; Akrami,\\n'\n",
      "             'F.; and Li, C. 2020. A benchmarking study of embedding-\\n'\n",
      "             'based entity alignment for knowledge graphs. arXiv preprint\\n'\n",
      "             'arXiv:2003.07743.\\n'\n",
      "             'Trouillon, T.; Welbl, J.; Riedel, S.; Gaussier, ´E.; and\\n'\n",
      "             'Bouchard, G. 2016. Complex embeddings for simple link\\n'\n",
      "             'prediction. In International Conference on Machine Learn-\\n'\n",
      "             'ing, 2071–2',\n",
      "  'combined_score': 0.5591954780083105,\n",
      "  'vector_score': 0.6408169269561768,\n",
      "  'keyword_score': 0.43676330458651114},\n",
      " {'doc_idx': 1206,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ', J. 2023. KICGPT:\\n'\n",
      "             'Large Language Model with Knowledge in Context for\\n'\n",
      "             'Knowledge Graph Completion. In Bouamor, H.; Pino, J.;\\n'\n",
      "             'and Bali, K., eds., Findings of the Association for Compu-\\n'\n",
      "             'tational Linguistics: EMNLP 2023, 8667–8683. Singapore:\\n'\n",
      "             'Association for Computational Linguistics.\\n'\n",
      "             'Yang, B.; Yih, W.-t.; He, X.; Gao, J.; and Deng, L. 2015.\\n'\n",
      "             'Embedding entities and relations for learning and inference\\n'\n",
      "             'in knowledge bases. arXiv preprint arXiv:1412.6575.\\n'\n",
      "             'Zhang, W.; Paudel, B.; Zhang, W.; Bernstein, A.; and Chen,\\n'\n",
      "             'H',\n",
      "  'combined_score': 0.5129531147654538,\n",
      "  'vector_score': 0.5948155522346497,\n",
      "  'keyword_score': 0.39015945856166007},\n",
      " {'doc_idx': 1191,\n",
      "  'filename': '2508.15357v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'tional 2D knowledge graph embeddings. In\\n'\n",
      "             'Proc. of AAAI.\\n'\n",
      "             'Devlin, J.; Chang, M.-W.; Lee, K.; and Toutanova, K. 2019.\\n'\n",
      "             'Bert: Pre-training of deep bidirectional transformers for lan-\\n'\n",
      "             'guage understanding. In Proceedings of the 2019 conference\\n'\n",
      "             'of the North American chapter of the association for compu-\\n'\n",
      "             'tational linguistics: human language technologies, volume 1\\n'\n",
      "             '(long and short papers), volume 1, 4171–4186.\\n'\n",
      "             'Ebisu, T.; and Ichise, R. 2018. Toruse: Knowledge Graph\\n'\n",
      "             'Embedding on a Lie Group. In Proceedings of the AAAI\\n',\n",
      "  'combined_score': 0.4669973065390911,\n",
      "  'vector_score': 0.619101881980896,\n",
      "  'keyword_score': 0.23884044337638374}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Elastic Weight Consolidation algorithm'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2643   0.311    0.519    0.000    2508.15294v1.p     8         \n",
      "2    2560   0.280    0.467    0.000    2508.15294v1.p     1         \n",
      "3    7995   0.278    0.464    0.000    2508.15757v1.p     4         \n",
      "4    2446   0.271    0.452    0.000    2508.15464v1.p     5         \n",
      "5    8019   0.261    0.436    0.000    2508.15757v1.p     6         \n",
      "6    8028   0.259    0.431    0.000    2508.15757v1.p     7         \n",
      "\n",
      "[{'doc_idx': 2643,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 8,\n",
      "  'content': 'olidation in llm-based agents.\\n'\n",
      "             'In Ex-\\n'\n",
      "             'tended Abstracts of the CHI Conference on Human Factors\\n'\n",
      "             'in Computing Systems, 1–7.\\n'\n",
      "             'Hu, C.; Fu, J.; Du, C.; Luo, S.; Zhao, J.; and Zhao, H. 2023.\\n'\n",
      "             'Chatdb: Augmenting llms with databases as their symbolic\\n'\n",
      "             'memory. arXiv preprint arXiv:2306.03901.\\n'\n",
      "             'Husz´ar, F. 2018. Note on the quadratic penalties in elastic\\n'\n",
      "             'weight consolidation. Proceedings of the National Academy\\n'\n",
      "             'of Sciences, 115(11): E2496–E2497.\\n'\n",
      "             'Ji, Z.; Lee, N.; Frieske, R.; Yu, T.; Su, D.; Xu, Y.; Ishii, '\n",
      "             'E.;\\n'\n",
      "             'Bang, Y. J.;',\n",
      "  'combined_score': 0.31127192974090573,\n",
      "  'vector_score': 0.5187865495681763,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2560,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ametrically, by\\n'\n",
      "             'augmenting LLMs with additional parameters, knowledge\\n'\n",
      "             'can be retained for future use (Wang et al. 2023). The Elas-\\n'\n",
      "             'tic Weight Consolidation algorithm (Husz´ar 2018) , devel-\\n'\n",
      "             'oped through collaboration between DeepMind and Imperial\\n'\n",
      "             'College London, enables neural networks to retain knowl-\\n'\n",
      "             'edge from previous tasks while learning new ones, miti-\\n'\n",
      "             'gating the ”catastrophic forgetting” problem and marking\\n'\n",
      "             'a significant step towards continuous learning in AI. How-\\n'\n",
      "             'ever, parametric memory is prone to ',\n",
      "  'combined_score': 0.28005189299583433,\n",
      "  'vector_score': 0.46675315499305725,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 7995,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 4,\n",
      "  'content': ' optimization',\n",
      "  'combined_score': 0.2783568441867828,\n",
      "  'vector_score': 0.46392807364463806,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2446,\n",
      "  'filename': '2508.15464v1.pdf',\n",
      "  'page': 5,\n",
      "  'content': 'nlike static reward\\n'\n",
      "             'averaging, SDW encourages more balanced learn-\\n'\n",
      "             'ing and improves robustness across diverse error\\n'\n",
      "             'types.\\n'\n",
      "             'Algorithm 1 Sub-score Dynamic Weighting\\n'\n",
      "             'Require: F1 scores, update interval M, temperature α\\n'\n",
      "             'Initialize wj ←1 for j = 1, . . . , K\\n'\n",
      "             'for each training step t = 1 to T do\\n'\n",
      "             'if t mod M = 0 then\\n'\n",
      "             'Calculate F1(j) score for each aspect j\\n'\n",
      "             'Compute average F1: ¯F1 ←\\n'\n",
      "             '1\\n'\n",
      "             'K\\n'\n",
      "             'PK\\n'\n",
      "             'j=1 F1(j)\\n'\n",
      "             'for each aspect j = 1 to K do\\n'\n",
      "             'Compute F1 gap: ∆j ←¯F1 −F1(j)\\n'\n",
      "             'end for\\n'\n",
      "             'Update weights with softmax:\\n'\n",
      "             'wj ←1 +\\n'\n",
      "             'exp(α · ∆j)\\n',\n",
      "  'combined_score': 0.27126837372779844,\n",
      "  'vector_score': 0.45211395621299744,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 8019,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'eature\\n'\n",
      "             '\\x00Engineering\\n'\n",
      "             'Hyper\\n'\n",
      "             '\\x00Parameter\\n'\n",
      "             'Iterations\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             'Epochs\\n'\n",
      "             '···\\n'\n",
      "             '···\\n'\n",
      "             'loss: cross entropy\\n'\n",
      "             '\\x00optimizer: adam\\n'\n",
      "             'filter1: 8 →16\\n'\n",
      "             '\\x00filter2: 16 →32\\n'\n",
      "             '\\x00Add kernal3\\n'\n",
      "             '\\x00dropout: 0.2 →0.4\\n'\n",
      "             'i = 1\\n'\n",
      "             't = 1\\n'\n",
      "             '/\\n'\n",
      "             'lr: 0.01\\n'\n",
      "             '\\x00weight decay: 0.0001\\n'\n",
      "             'loss: focal loss\\n'\n",
      "             '\\x00optimizer: adamw\\n'\n",
      "             'Flip\\n'\n",
      "             'i = 2\\n'\n",
      "             't = 3\\n'\n",
      "             '/\\n'\n",
      "             'lr: 0.02\\n'\n",
      "             '\\x00weight decay: 0.0005\\n'\n",
      "             '\\x00class_3_weight=1.2\\n'\n",
      "             'loss: cross entropy\\n'\n",
      "             'optimizer: adam\\n'\n",
      "             'filter1: 16 →32\\n'\n",
      "             '\\x00filter2: 32 →64\\n'\n",
      "             '\\x00filter3: 64 →128\\n'\n",
      "             '\\x00dropout: 0.4 →0.3\\n'\n",
      "             'Rotation\\n'\n",
      "             't = 7\\n'\n",
      "             'lr: 0.02\\n'\n",
      "             '\\x00weight_decay: 0.0005\\n'\n",
      "             '\\x00class_8_weight=0.95\\n'\n",
      "             'class_9_w',\n",
      "  'combined_score': 0.26147992014884947,\n",
      "  'vector_score': 0.43579986691474915,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 8028,\n",
      "  'filename': '2508.15757v1.pdf',\n",
      "  'page': 7,\n",
      "  'content': 'on inverse class frequency (e.g., weight_class_i =\\n'\n",
      "             'total_samples / (num_classes * count_class_i)).\\n'\n",
      "             '\\x00- Monitor validation recall and ROC-AUC for improvements.\\n'\n",
      "             '\\x002. If Stagnation Persists:\\n'\n",
      "             '\\x00- Gradually increase weights for the worst-performing '\n",
      "             'classes (e.g., lowest recall).\\n'\n",
      "             '\\x00- Data augmentation or dropout to reduce overfitting (if '\n",
      "             'validation loss starts\\n'\n",
      "             'rising).\\n'\n",
      "             'Evaluator\\n'\n",
      "             'Advisor\\n'\n",
      "             'Optimizer\\n'\n",
      "             'Figure 4: Example agent outputs showing multi-agent inter-\\n'\n",
      "             'action. The Advisor provides specific configuration recom-\\n'\n",
      "             'mend',\n",
      "  'combined_score': 0.2588670372962952,\n",
      "  'vector_score': 0.43144506216049194,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Multiple Memory Systems'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    2552   0.642    0.491    0.870    2508.15294v1.p     1         \n",
      "2    2571   0.424    0.532    0.263    2508.15294v1.p     2         \n",
      "3    2568   0.345    0.499    0.114    2508.15294v1.p     2         \n",
      "4    2635   0.323    0.538    0.000    2508.15294v1.p     7         \n",
      "5    2586   0.319    0.532    0.000    2508.15294v1.p     3         \n",
      "6    2581   0.318    0.531    0.000    2508.15294v1.p     3         \n",
      "\n",
      "[{'doc_idx': 2552,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'Multiple Memory Systems for Enhancing the Long-term Memory of '\n",
      "             'Agent\\n'\n",
      "             'Gaoke Zhang1, Bo Wang1*, Yunlong Ma1, Dongming Zhao2, Zifei Yu3\\n'\n",
      "             '1College of Intelligence and Computing, Tianjin University\\n'\n",
      "             '2AI Lab, China Mobile Communication Group Tianjin Co., Ltd\\n'\n",
      "             '3Huizhi Xingyuan Information Technology Co., Ltd\\n'\n",
      "             '{zhanggaoke, bo wang}@tju.edu.cn\\n'\n",
      "             'Abstract\\n'\n",
      "             'An agent powered by large language models have achieved\\n'\n",
      "             'impressive results, but effectively handling the vast amounts\\n'\n",
      "             'of historical data generated during interactions rema',\n",
      "  'combined_score': 0.6424790635057867,\n",
      "  'vector_score': 0.4906092584133148,\n",
      "  'keyword_score': 0.8702837711444943},\n",
      " {'doc_idx': 2571,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'logy\\n'\n",
      "             'The theory of multiple memory systems (Tulving 1985)\\n'\n",
      "             'posits that memory is not processed by a single system, but\\n'\n",
      "             'rather consists of multiple subsystems that are functionally\\n'\n",
      "             'independent and have different structural foundations. These\\n'\n",
      "             'systems are responsible for different types of information\\n'\n",
      "             'processing and storage, with specific neural bases and be-\\n'\n",
      "             'havioral characteristics. Endel Tulving (Tulving et al. 1972)\\n'\n",
      "             'proposed a three-category classification model in 1985, in-\\n'\n",
      "             'cluding: Procedural Memory: invo',\n",
      "  'combined_score': 0.4242785113346009,\n",
      "  'vector_score': 0.5317948460578918,\n",
      "  'keyword_score': 0.26300400924966444},\n",
      " {'doc_idx': 2568,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': 'em based on cognitive psychology theory to generate high-\\n'\n",
      "             'quality long-term memory.\\n'\n",
      "             'Our contributions are as follows:\\n'\n",
      "             '(1) Current research rarely considers memory content\\n'\n",
      "             'quality, leading to its poor state. To address the issue of\\n'\n",
      "             'low-quality memory content in current memory systems, we\\n'\n",
      "             'are inspired by multiple memory systems theory, encoding\\n'\n",
      "             'specificity principle, and levels of processing theory to pro-\\n'\n",
      "             'pose a multiple memory system to enhance the long-term\\n'\n",
      "             'memory capabilities of agents. The memory system ',\n",
      "  'combined_score': 0.344988950218806,\n",
      "  'vector_score': 0.49916186928749084,\n",
      "  'keyword_score': 0.11372957161577883},\n",
      " {'doc_idx': 2635,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 7,\n",
      "  'content': 'nd of\\n'\n",
      "             'low quality, resulting in poor performance. Conversely, our\\n'\n",
      "             'method generates a larger volume of high-quality memory\\n'\n",
      "             'content despite the increased overhead, with only a mini-\\n'\n",
      "             'mal latency increase that barely affects user experience. Our\\n'\n",
      "             'method holds practical value.\\n'\n",
      "             'Conclusion\\n'\n",
      "             'This paper creates a multi-memory system by integrat-\\n'\n",
      "             'ing with cognitive psychology to build effective long-term\\n'\n",
      "             'memory, boosting recall and generation quality. Multiple\\n'\n",
      "             'memory theory suggests human memory comes in many\\n'\n",
      "             'forms. Cu',\n",
      "  'combined_score': 0.3225078463554382,\n",
      "  'vector_score': 0.5375130772590637,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2586,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 3,\n",
      "  'content': 's Mcog, episodic memory Mepi, and\\n'\n",
      "             'semantic memory Msem. Then, these memory fragments are\\n'\n",
      "             'used to construct retrieval memory units MUret and con-\\n'\n",
      "             'textual memory units MUcont, which are used for memory\\n'\n",
      "             'retrieval and memory use, respectively.\\n'\n",
      "             'Our multi-memory fragment system involves three pro-\\n'\n",
      "             'cesses: the construction of long-term memory units, the re-\\n'\n",
      "             'trieval of long-term memory units, and the use of contextual\\n'\n",
      "             'memory units. The process of the system processing short-\\n'\n",
      "             'term memory into long-term memory is sho',\n",
      "  'combined_score': 0.31937445402145387,\n",
      "  'vector_score': 0.5322907567024231,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2581,\n",
      "  'filename': '2508.15294v1.pdf',\n",
      "  'page': 3,\n",
      "  'content': 'Figure 1: Schematic of multi-memory system process: After '\n",
      "             'acquiring short-term memory, MMS processes it into memory\\n'\n",
      "             'fragments and constructs retrieval units and contextual memory '\n",
      "             'units. During retrieval, the k most relevant retrieval units '\n",
      "             'are\\n'\n",
      "             'matched to the query, and their corresponding contextual units '\n",
      "             'are then used as context input for the agent’s response.\\n'\n",
      "             'such as usage frequency and temporal proximity. ChatDB\\n'\n",
      "             '(Hu et al. 2023) employs a database as the symbolic memory\\n'\n",
      "             'for LLMs. Its approach involves st',\n",
      "  'combined_score': 0.31848778724670407,\n",
      "  'vector_score': 0.5308129787445068,\n",
      "  'keyword_score': 0.0}]\n",
      "\n",
      "\n",
      "Hybrid Search Results for query: 'Speculative decoding'\n",
      "alpha=0.6\n",
      "============================================================\n",
      "Rank Doc ID Combined Vector   Keyword  Filename           Page      \n",
      "------------------------------------------------------------\n",
      "1    3075   0.418    0.696    0.000    2508.15371v1.p     6         \n",
      "2    3006   0.392    0.653    0.000    2508.15371v1.p     2         \n",
      "3    3125   0.388    0.647    0.000    2508.15371v1.p     9         \n",
      "4    2980   0.374    0.623    0.000    2508.15371v1.p     1         \n",
      "5    2989   0.368    0.613    0.000    2508.15371v1.p     1         \n",
      "6    2991   0.364    0.606    0.000    2508.15371v1.p     1         \n",
      "\n",
      "[{'doc_idx': 3075,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 6,\n",
      "  'content': 'fidence-\\n'\n",
      "             'Modulated Adaptive Speculative Decoding (CM-ASD) framework',\n",
      "  'combined_score': 0.4176655411720276,\n",
      "  'vector_score': 0.6961092352867126,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 3006,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 2,\n",
      "  'content': ' speculative \\n'\n",
      "             'decoding as a heuristic acceleration technique and a \\n'\n",
      "             'principled, learning-informed system guided by model \\n'\n",
      "             'introspection. By enabling the decoder to reason about its own \\n'\n",
      "             'confidence during inference, the proposed framework \\n'\n",
      "             'introduces a level of adaptivity that has been largely absent '\n",
      "             'in \\n'\n",
      "             'prior decoding strategies. The result is a system that not '\n",
      "             'only \\n'\n",
      "             'accelerates inference substantially but does so in a more \\n'\n",
      "             'intelligent and context-aware manner. \\n'\n",
      "             'The remainder of the paper is organized as f',\n",
      "  'combined_score': 0.3915829539299011,\n",
      "  'vector_score': 0.6526382565498352,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 3125,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 9,\n",
      "  'content': ' language model decoding with speculative \\n'\n",
      "             'sampling,” arXiv:2302.01318 [cs.CL], 2023.',\n",
      "  'combined_score': 0.38842320442199707,\n",
      "  'vector_score': 0.6473720073699951,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2980,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'Confidence-Modulated Speculative Decoding for \\n'\n",
      "             'Large Language Models \\n'\n",
      "             ' \\n'\n",
      "             'Jaydip Sen                             \\n'\n",
      "             'Department of Data Science         \\n'\n",
      "             'Praxis Business School              \\n'\n",
      "             'Kolkata, INDIA                             \\n'\n",
      "             'email: jaydip.sen@acm.org \\n'\n",
      "             'Subhasis Dasgupta                \\n'\n",
      "             'Department of Data Science          \\n'\n",
      "             'Praxis Business School               \\n'\n",
      "             'Kokata, INDIA                              \\n'\n",
      "             'email: subhasisdasgupta1@acm.org \\n'\n",
      "             'Hetvi Waghela                      \\n'\n",
      "             'Department of Data Science       ',\n",
      "  'combined_score': 0.37398741245269773,\n",
      "  'vector_score': 0.6233123540878296,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2989,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'ificing the generation quality achieved by \\n'\n",
      "             'autoregressive methods. \\n'\n",
      "             'One promising line of work addressing this challenge is \\n'\n",
      "             'the draft-then-verify paradigm, which has recently gained \\n'\n",
      "             'renewed attention under the framework of speculative \\n'\n",
      "             'decoding [4]. The central idea in speculative decoding is to \\n'\n",
      "             'introduce a parallel drafting mechanism that predicts multiple \\n'\n",
      "             'future tokens simultaneously, followed by a verification step \\n'\n",
      "             'that checks the drafted tokens against the output of the '\n",
      "             'original \\n'\n",
      "             'autoregressive mo',\n",
      "  'combined_score': 0.36806473731994627,\n",
      "  'vector_score': 0.6134412288665771,\n",
      "  'keyword_score': 0.0},\n",
      " {'doc_idx': 2991,\n",
      "  'filename': '2508.15371v1.pdf',\n",
      "  'page': 1,\n",
      "  'content': 'd improvements in inference \\n'\n",
      "             'speed over conventional autoregressive decoding while \\n'\n",
      "             'maintaining comparable output quality. \\n'\n",
      "             'Despite the efficiency gains observed in speculative \\n'\n",
      "             'decoding, the method still faces several under-explored \\n'\n",
      "             'challenges that limit its full potential. One notable issue is '\n",
      "             'the \\n'\n",
      "             'fixed nature of the drafting window size, often denoted as k, \\n'\n",
      "             'which specifies how many tokens the drafter attempts to \\n'\n",
      "             'generate in a single iteration. Most implementations of \\n'\n",
      "             'speculative decoding use a const',\n",
      "  'combined_score': 0.36353015899658203,\n",
      "  'vector_score': 0.6058835983276367,\n",
      "  'keyword_score': 0.0}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for query in queries:\n",
    "    result = hybrid_search(query, 6)\n",
    "    print('\\r')\n",
    "    pprint.pprint(result, sort_dicts=False)\n",
    "    print('\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d93edeb",
   "metadata": {},
   "source": [
    "### 5) A FastAPI endpoint \"/hybrid-search\" has been implemented in hybrid_search.py. To test its API, run the following code and then test the API in a browser at 127.0.0.1/8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a88811fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/home/ehan/evanhan_homework/evanhan_homework/class5']\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
      "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m1809280\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m1809332\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "FAISS index and documents files loaded\n",
      "Successfully opened the database\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "^C\n",
      "\u001b[32mINFO\u001b[0m:     Shutting down\n",
      "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m1809332\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m1809280\u001b[0m]\n"
     ]
    }
   ],
   "source": [
    "! python3 ./src/hybrid_search.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa2f0a",
   "metadata": {},
   "source": [
    "**Note:** The PDF files processed in this assignment had been downloaded in the last assignment by the get_latest_arxiv() function in documents_downloading.py. To perform this task again:\n",
    "\n",
    "from src.documents_downloading import get_latest_arxiv \n",
    "<br>\n",
    "get_latest_arxiv(query=\"cat:cs.CL\", max_results=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d531c97",
   "metadata": {},
   "source": [
    "### 6) Remarks\n",
    "\n",
    "Based on the calculated Recall@k metrics on following five queries (with chunk ids identified for the occurances of the searched terms), the hybrid method performed better than the vector-only search, but it didn't perform much better than the keywork-only search. The value of alpha was 0.6 on the tests. \n",
    "\n",
    "    \"Normative LLMs Profiling\", # chunk_id: 1674, 1675, 1682 (total 3)\n",
    "    \"Automatic Mixed Precision\", # chunk_id: 2147, other chunk in same page (total 2)\n",
    "    \"Sampling Number\", # chunk_id: 7397, 7398 (total 2)\n",
    "    \"knowledge distillation\", # chunk_id: 1571, 1572, 2104, 2730, 3126, 6206, 6274, 6300, 7522, 7523, 7534, 7630, 8173, 8174  (total 13)\n",
    "    \"Knowledge Graph Completion Models\", # 1103/04, 1184, 1189, 1197, 1199, 1205/06, 3846/48 (8)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55221e58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9c6d7e",
   "metadata": {},
   "source": [
    "| Query        | Recall@6 Vector | Recall@10 Vector | Recall@6 Keyword  | Recall@6 Hybrid |\n",
    "|--------------|-----------------|------------------|------------------------------|-------|\n",
    "| 1. \"Normative ..\"| 0.33| 0.33   |    1     |     0.33      |\n",
    "| 2. \"Automatic ..\"  | 0  | 0       |    1     |    0.5        |\n",
    "| 3. \"Sampling ..\"  | 1  | 1       |   1      |     1         |\n",
    "| 4. \"knowledge d..\"  | 0.23 | 0.46  |  0.38     |     0.38     |\n",
    "| 5. \"Knowledge G ..\"  | 0.62 | 1  |  0.37     |     0.62     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e8959c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_class4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
